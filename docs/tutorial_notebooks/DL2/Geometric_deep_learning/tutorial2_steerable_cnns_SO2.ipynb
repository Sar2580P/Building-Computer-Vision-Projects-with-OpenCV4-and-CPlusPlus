{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sar2580P/Building-Computer-Vision-Projects-with-OpenCV4-and-CPlusPlus/blob/master/docs/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial2_steerable_cnns_SO2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1GrTyqmLcQLM"
      },
      "source": [
        "# GDL - Steerable CNNs\n",
        "\n",
        "**Filled notebook:**\n",
        "[![View on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial2_steerable_cnns.ipynb)\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial2_steerable_cnns.ipynb)  \n",
        "**Empty notebook:**\n",
        "[![View on Github Unanswered](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial2_steerable_cnns_unanswered.ipynb)\n",
        "[![Open In Collab Unanswered](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial2_steerable_cnns_unanswered.ipynb)  \n",
        "**Authors:** Gabriele Cesa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfCFymZvcQLS"
      },
      "source": [
        "During the lectures, you have learnt that the symmetries of a machine learning task can be modelled with **groups**.\n",
        "In the previous tutorial, you have also studied the framework of *Group-Convolutional Neural Networks* (**GCNNs**), which describes a neural architecture design equivariant to general groups.\n",
        "\n",
        "The feature maps of a GCNN are functions over the elements of the group.\n",
        "A naive implementation of group-convolution requires computing and storing a response for each group element.\n",
        "For this reason, the GCNN framework is not particularly convenient to implement networks equivariant to groups with infinite elements.\n",
        "\n",
        "Steerable CNNs are a more general framework which solves this issue.\n",
        "The key idea is that, instead of storing the value of a feature map on each group element, the model stores the *Fourier transform* of this feature map, up to a finite number of frequencies.\n",
        "\n",
        "In this tutorial, we will first introduce some Representation theory and Fourier theory (*non-commutative harmonic analysis*) and, then, we will explore how this idea is used in practice to implement Steerable CNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbSmJU4LcQLT"
      },
      "source": [
        "## Prerequisite Knowledge\n",
        "Throughout this tutorial, we will assume you are already familiar with some concepts of **group theory**, such as *groups*, *group actions* (in particular *on functions*), *semi-direct product* and *order of a group*, as well as basic **linear algebra**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qriE3g7cQLP"
      },
      "source": [
        "We start by importing the necessary packages.\n",
        "You can run the following command to install all the requirements:\n",
        "\n",
        "`> pip install torch torchvision numpy matplotlib git+https://github.com/AMLab-Amsterdam/lie_learn escnn scipy`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy matplotlib git+https://github.com/AMLab-Amsterdam/lie_learn escnn scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3JMV4OvXSam",
        "outputId": "a936524c-89c2-4d9f-bb3e-b57dfebb9006"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AMLab-Amsterdam/lie_learn\n",
            "  Cloning https://github.com/AMLab-Amsterdam/lie_learn to /tmp/pip-req-build-hihbjl7l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AMLab-Amsterdam/lie_learn /tmp/pip-req-build-hihbjl7l\n",
            "  Resolved https://github.com/AMLab-Amsterdam/lie_learn to commit e7060c097514228e0df8b5bd99a3f4d493756e92\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Collecting escnn\n",
            "  Downloading escnn-1.0.11-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lie_learn==0.0.2) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from escnn) (1.4.2)\n",
            "Collecting pymanopt (from escnn)\n",
            "  Downloading pymanopt-2.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from escnn) (1.7.0)\n",
            "Collecting py3nj (from escnn)\n",
            "  Downloading py3nj-0.2.1.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.2) (2024.12.14)\n",
            "Downloading escnn-1.0.11-py3-none-any.whl (373 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.9/373.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymanopt-2.2.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lie_learn, py3nj\n",
            "  Building wheel for lie_learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lie_learn: filename=lie_learn-0.0.2-cp310-cp310-linux_x86_64.whl size=16179046 sha256=f21a2d31cf9f6d6e301b11fbfa1d1b1891133ebeae551ca0d1ac69752835bf20\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-weictvx_/wheels/3f/33/85/b8725ee77011bc42d77e4e35aeca2088482c3094f5c0a650a6\n",
            "  Building wheel for py3nj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py3nj: filename=py3nj-0.2.1-cp310-cp310-linux_x86_64.whl size=44764 sha256=fdeca4c56c6493e5dce9449ea3efe4d664b769e2aae974f4f89a1bd95a7cce9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/e9/70/30a34ed6dbc8b54ce93f25c091be4cf7a24319e27d953a882b\n",
            "Successfully built lie_learn py3nj\n",
            "Installing collected packages: py3nj, pymanopt, lie_learn, escnn\n",
            "Successfully installed escnn-1.0.11 lie_learn-0.0.2 py3nj-0.2.1 pymanopt-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DeUGG1ycQLQ",
        "outputId": "6cfe90c5-5c55-4231-fbea-19c17bab68e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-433ef526a958>:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=10000, threshold=100000)\n",
        "\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# If the fonts in the plots are incorrectly rendered, comment out the next two lines\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "CHECKPOINT_PATH = \"../../saved_models/DL2/GDL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_VZKFFfy5ROh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b7b1fc-0cae-4035-f6a6-fcd11626c1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/DL2/GDL/steerable_c4-pretrained.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/DL2/GDL/steerable_so2-pretrained.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/DL2/GDL/steerable_c4-accuracies.npy...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/DL2/GDL/steerable_so2-accuracies.npy...\n"
          ]
        }
      ],
      "source": [
        "# Create checkpoint path if it doesn't exist yet\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "# Files to download\n",
        "pretrained_files = [\n",
        "    \"steerable_c4-pretrained.ckpt\",\n",
        "    \"steerable_so2-pretrained.ckpt\",\n",
        "    \"steerable_c4-accuracies.npy\",\n",
        "    \"steerable_so2-accuracies.npy\",\n",
        "]\n",
        "\n",
        "# Github URL where saved models are stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/DL2/GDL/\"\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\"Something went wrong. Please contact the author with the full output including the following error:\\n\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YajlOyducQLT"
      },
      "source": [
        "## 1. Representation Theory and Harmonic Analysis of Compact Groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXn7VD9hcQLU"
      },
      "source": [
        "We will make use of the `escnn` [library](https://github.com/QUVA-Lab/escnn) throughout this tutorial.\n",
        "You can also find its documentation [here](https://quva-lab.github.io/escnn/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RLFz1jngcQLV"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from escnn.group import *\n",
        "except ModuleNotFoundError: # Google Colab does not have escnn installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet git+https://github.com/AMLab-Amsterdam/lie_learn escnn\n",
        "    from escnn.group import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC9uzWK9cQLV"
      },
      "source": [
        "First, let's create a group.\n",
        "We will use the *Cyclic Group* $G=C_8$ as an example.\n",
        "This group contains the $8$ planar rotations by multiples of $\\frac{2\\pi}{8}$.\n",
        "In `escnn`, a groups are instances of the abstract class `escnn.group.Group`, which provides some useful functionalities.\n",
        "We instantiate groups via a *factory method*.\n",
        "To build the cyclic group of order $8$, we use this factory method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VADpbshZcQLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd3f9fa-d445-43e8-b7fd-f1b6d02a7bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "order: 8\n",
            "['N', 'PARAM', 'PARAMETRIZATIONS', '__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_build_quotient_representations', '_build_representations', '_cached_group_instances', '_change_param', '_clebsh_gordan_coeff', '_combine', '_combine_subgroups', '_decode_subgroup_id_pickleable', '_elements', '_encode_subgroup_id_pickleable', '_equal', '_generator', '_hash_element', '_homspaces', '_identity', '_induced_from_irrep', '_inverse', '_irreps', '_is_element', '_keys', '_process_subgroup_id', '_repr_element', '_representations', '_restrict_irrep', '_subgroup', '_subgroups', '_tensor_product', '_tensor_product_irreps', 'abelian', 'bl_irreps', 'continuous', 'element', 'elements', 'generators', 'get_irrep_id', 'grid', 'homspace', 'identity', 'induced_representation', 'irrep', 'irreps', 'name', 'order', 'quotient_representation', 'regular_representation', 'representations', 'restrict_representation', 'rotation_order', 'sample', 'spectral_quotient_representation', 'spectral_regular_representation', 'subgroup', 'subgroup_self_id', 'subgroup_trivial_id', 'testing_elements', 'trivial_representation']\n"
          ]
        }
      ],
      "source": [
        "G = cyclic_group(N=8)\n",
        "\n",
        "# We can verify that the order of this group is 8:\n",
        "print(f\"order: {G.order()}\")\n",
        "print(dir(G))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcc8utD-cQLY"
      },
      "source": [
        "A group is a collection of group elements together with a binary operation to combine them.\n",
        "This is implemented in the class `escnn.group.GroupElement`.\n",
        "We can access the *identity* element $e \\in G$ as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IOb24vqTcQLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888e7b3d-e357-46ac-f76c-b570bd392ad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0[2pi/8]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "G.identity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6carpwC_cQLY"
      },
      "source": [
        "or sample a random element as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GuCA2K3mcQLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21aa2e8-61bf-4802-83a1-811835ea5ccd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2[2pi/8]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "G.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgsIZ5iOcQLZ"
      },
      "source": [
        "Group elements can be combined via the binary operator `@`; we can also take the inverse of an element using `~`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ePYpcV2hcQLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4206d2-aad8-4971-a008-1e3673455bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4[2pi/8]\n",
            "1[2pi/8]\n",
            "5[2pi/8]\n",
            "4[2pi/8]\n"
          ]
        }
      ],
      "source": [
        "a = G.sample()\n",
        "b = G.sample()\n",
        "print(a)\n",
        "print(b)\n",
        "print(a @ b)\n",
        "print(~a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_7H2r85cQLa"
      },
      "source": [
        "Representation theory is a fundamental element in Steerable CNNs and to construct a Fourier theory over groups.\n",
        "In this first section, we will introduce the essential concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAbvGihgcQLa"
      },
      "source": [
        "### 1.1 Group Representation\n",
        "\n",
        "A **linear group representation** $\\rho$ of a compact group $G$ on a vector space (called *representation space*) $\\mathbb{R}^d$ is a *group homomorphism* from $G$ to the general linear group $GL(\\mathbb{R}^d)$, i.e. it is a map $\\rho : G \\to \\mathbb{R}^{d \\times d}$ such that:\n",
        "$$\\rho(g_1 g_2) = \\rho(g1) \\rho(g2) \\quad \\forall g_1,g_2 \\in G \\ .$$\n",
        "\n",
        "In other words, $\\rho(g)$ is a $d \\times d$ *invertible* matrix.\n",
        "We refer to $d$ as the *size* of the representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dja71IKcQLb"
      },
      "source": [
        "#### Example: the Trivial Representation\n",
        "The simplest example of *group representation* is the **trivial representation** which maps every element to $1 \\in \\mathbb{R}$, i.e. $\\rho: g \\mapsto 1$.\n",
        "One can verify that it satisfies the condition above.\n",
        "We can construct this representation as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r0EUX2NPcQLb"
      },
      "outputs": [],
      "source": [
        "rho = G.trivial_representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls4_jiufcQLb"
      },
      "source": [
        "`rho` is an instance of `escnn.group.Representation`. This class provides some functionalities to work with group representations. We can also use it as a callable function to compute the representation of a group element; this will return a squared matrix as a `numpy.array`.\n",
        "Let verify that the trivial representation does indeed verify the condition above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t8Ub_tjUcQLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c6a106-5cc8-4044-e26b-3ce0abc363db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]]\n",
            "[[1.]]\n"
          ]
        }
      ],
      "source": [
        "g1 = G.sample()\n",
        "g2 = G.sample()\n",
        "print(rho(g1) @ rho(g2))\n",
        "print(rho(g1 @ g2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg53mBIkcQLc"
      },
      "source": [
        "Note that the trivial representation has size $1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f2AqadBpcQLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c82d80a9-6452-42ae-e9fc-e2596b93d512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "rho.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaV4gjdpcQLc"
      },
      "source": [
        "#### Example: rotations\n",
        "\n",
        "Another common example of group representations is given by 2D rotations.\n",
        "Let $SO(2)$ be the group of all planar rotations; note that we can identify each rotation by an angle $\\theta \\in [0, 2\\pi)$.\n",
        "Then, the standard representation of planar rotations as $2\\times 2$ rotation matrices is a representation of $SO(2)$:\n",
        "\n",
        "$$\n",
        "    \\rho: r_{\\theta} \\mapsto \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where $r_\\theta \\in SO(2)$ is a counter-clockwise rotation by $\\theta$.\n",
        "Let's try to build this group and, then, verify that this is a representation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZJpxDUGacQLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c49e12-61be-46d2-82e0-dc301b9189ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g1=0.9081145676352065, g2=5.643044377043492, g1 * g2 = 0.2679736374991126\n",
            "\n",
            "rho(g1) @ rho(g2)\n",
            "[[ 0.964 -0.265]\n",
            " [ 0.265  0.964]]\n",
            "\n",
            "rho(g1 * g2)\n",
            "[[ 0.964 -0.265]\n",
            " [ 0.265  0.964]]\n"
          ]
        }
      ],
      "source": [
        "G = so2_group()\n",
        "rho = G.standard_representation()\n",
        "\n",
        "g1 = G.sample()\n",
        "g2 = G.sample()\n",
        "print(f'g1={g1}, g2={g2}, g1 * g2 = {g1 @ g2}')\n",
        "print()\n",
        "print('rho(g1) @ rho(g2)')\n",
        "print(rho(g1) @ rho(g2))\n",
        "print()\n",
        "print('rho(g1 * g2)')\n",
        "print(rho(g1 @ g2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwjnsXvngH56"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 1\n",
        "Show that any representation $\\rho: G \\to \\mathbb{R}^{d \\times d}$ also satisfies the following two properties:\n",
        "\n",
        "- let $e \\in G$ be the identity element. Then, $\\rho(e)$ is the identity matrix of size $d$.\n",
        "\n",
        "- let $g \\in G$ and $g^{-1}$ be its inverse (i.e. $g \\cdot g^{-1} = e$). Then, $\\rho(g^{-1}) = \\rho(g)^{-1}$.\n",
        "\n",
        "\n",
        "#### ANSWER 1\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT8HQUFGcQLd"
      },
      "source": [
        "#### Direct Sum\n",
        "We can combine representations to build a larger representation via the **direct sum**.\n",
        "\n",
        "Given representations $\\rho_1 : G \\to \\mathbb{R}^{d_1 \\times d_1}$ and $\\rho_2 : G \\to \\mathbb{R}^{d_2 \\times d_2}$, their *direct sum* $\\rho_1 \\oplus \\rho_2: G \\to \\mathbb{R}^{(d_1 + d_2) \\times (d_1 + d_2)}$ is defined as\n",
        "\n",
        "$$\n",
        "    (\\rho_1 \\oplus \\rho_2)(g) = \\begin{bmatrix}\\rho_1(g) & 0 \\\\ 0 & \\rho_2(g) \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Its action is therefore given by the independent actions of $\\rho_1$ and $\\rho_2$ on the orthogonal subspaces $\\mathbb{R}^{d_1}$ and $\\mathbb{R}^{d_2}$  of $\\mathbb{R}^{d_1 + d_2}$.\n",
        "\n",
        "Let's see an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3bKiV8VMcQLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8418924c-1d08-4dce-f52d-d380b220f945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group : 6.049303413724406\n",
            "[[ 0.973  0.232]\n",
            " [-0.232  0.973]]\n",
            "\n",
            "[[ 0.973  0.232  0.     0.   ]\n",
            " [-0.232  0.973  0.     0.   ]\n",
            " [ 0.     0.     0.973  0.232]\n",
            " [ 0.     0.    -0.232  0.973]]\n"
          ]
        }
      ],
      "source": [
        "rho_sum = rho + rho\n",
        "\n",
        "g = G.sample()\n",
        "print(f\"group : {g}\")\n",
        "print(rho(g))\n",
        "print()\n",
        "print(rho_sum(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klWR11lpcQLe"
      },
      "source": [
        "Note that the direct sum of two representations has size equal to the sum of their sizes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SoDMk5gdcQLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f72cb96-c2ea-47f2-b508-94141a18c429"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "rho.size, rho_sum.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhe9hZ_zcQLe"
      },
      "source": [
        "We can combine arbitrary many representations in this way, e.g. $\\rho \\oplus \\rho \\oplus \\rho \\oplus \\rho$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f5w0GppScQLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba313ee7-2e03-43bc-f1c7-145608133e01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "rho_sum = rho + rho + rho + rho\n",
        "\n",
        "# or, more simply:\n",
        "rho_sum = directsum([rho, rho, rho, rho])\n",
        "rho_sum.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNMR5pQGcQLf"
      },
      "source": [
        "#### The Regular Representation\n",
        "\n",
        "Another important representation is the **regular representation**.\n",
        "The regular representation describes the action of a group $G$ on the vector space of functions over the group $G$.\n",
        "Assume for the moment that the group $G$ is *finite*, i.e. $|G| < \\infty$.\n",
        "\n",
        "The set of functions over $G$ is equivalent to the vector space $\\mathbb{R}^{|G|}$.\n",
        "We can indeed interpret a vector $\\mathbf{f} \\in \\mathbb{R}^{|G|}$ as a function over $G$, where the $i$-th entry of $\\mathbf{f}$ is interpreted as the value of the function on the $i$-th element $g_i \\in G$.\n",
        "\n",
        "The **regular representation** of $G$ is a $|G|$ dimensional representation.\n",
        "Recall the left action of $G$ on a function $f: G \\to \\mathbb{R}$:\n",
        "\n",
        "$$\n",
        "[g.f](h) := f(g^{-1} h)\n",
        "$$\n",
        "\n",
        "The new function $g.f$ is still a function over $G$ and belongs to the same vector space.\n",
        "If we represent the function $f$ as a vector $\\mathbf{f}$, the vector representing the function $g.f$ will have permuted entries with respect to $\\mathbf{f}$.\n",
        "This permutation is the regular representation of $g \\in G$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9JtxVcgcQLf"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 2\n",
        "Show that the space of functions over $G$ is a vector space.\n",
        "To do so, show that functions satisfy the properties of a vector space; see [here](https://en.wikipedia.org/wiki/Vector_space#Notation_and_definition).\n",
        "\n",
        "#### ANSWER 2\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oStwiCwNcQLf"
      },
      "source": [
        "For finite groups, we can generate this representation.\n",
        "We assume that the $i$-th entry is associated with the element of $G=C_8$ corresponing to a rotation by $i \\frac{2\\pi}{8}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "URb5ggAXcQLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5e9c91-1893-4d21-de5c-0564bfdf064c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C8|[regular]:8"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "G = cyclic_group(8)\n",
        "rho = G.regular_representation\n",
        "rho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QrBDn90GcQLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118e3c87-bf1e-4ba8-c0bb-b942240899ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# note that the size of the representation is equal to the group's order |G|\n",
        "rho.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cArJXaecQLg"
      },
      "source": [
        "the identity element maps a function to itself, so the entries are not permuted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dkyjqK2GcQLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1483bb71-02fa-4b89-9f24-7e0943e797a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  0., -0., -0., -0., -0.,  0., -0.],\n",
              "       [ 0.,  1.,  0., -0., -0., -0., -0., -0.],\n",
              "       [-0.,  0.,  1., -0., -0.,  0., -0.,  0.],\n",
              "       [-0., -0., -0.,  1.,  0., -0., -0., -0.],\n",
              "       [-0., -0., -0.,  0.,  1.,  0., -0., -0.],\n",
              "       [-0., -0.,  0., -0.,  0.,  1., -0.,  0.],\n",
              "       [ 0., -0., -0., -0., -0., -0.,  1., -0.],\n",
              "       [-0., -0.,  0., -0., -0.,  0., -0.,  1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "rho(G.identity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfNZQhHycQLg"
      },
      "source": [
        "The regular representation of the rotation by $1\\frac{2\\pi}{8}$ just cyclically shifts each entry to the next position since $r_{1\\frac{2\\pi}{8}}^{-1} r_{i\\frac{2\\pi}{8}} = r_{(i-1)\\frac{2\\pi}{8}}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zbTrUzKZcQLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b150e37d-e036-4fea-eb01-10694c10ed92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -0.,  0., -0., -0.,  0., -0.,  1.],\n",
              "       [ 1.,  0., -0., -0., -0., -0.,  0., -0.],\n",
              "       [ 0.,  1.,  0., -0.,  0., -0., -0., -0.],\n",
              "       [-0.,  0.,  1., -0., -0.,  0., -0.,  0.],\n",
              "       [-0., -0., -0.,  1.,  0., -0.,  0., -0.],\n",
              "       [-0.,  0., -0.,  0.,  1.,  0.,  0., -0.],\n",
              "       [-0., -0.,  0., -0.,  0.,  1.,  0.,  0.],\n",
              "       [-0.,  0., -0., -0.,  0., -0.,  1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "rho(G.element(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMPG_z9jcQLh"
      },
      "source": [
        "Let's see an example of the action on a function.\n",
        "We consider a function which is zero on all group elements apart from the identity ($i=0$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x3KrJjrXcQLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6f818f-a6ff-4f81-e1bd-a2eea9f83f36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "f = np.zeros(8)\n",
        "f[0] = 1\n",
        "f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuFWujk_cQLh"
      },
      "source": [
        "Observe that $\\rho(e) \\mathbf{f} = \\mathbf{f}$, where $e = 0\\frac{2\\pi}{8}$ is the identity element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "La0rfdEycQLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1a2348-c661-4aa0-b1e1-27f71c67ca13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  0., -0., -0., -0., -0.,  0., -0.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "rho(G.identity) @ f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlWW5joqcQLh"
      },
      "source": [
        "$\\mathbf{f}$ is non-zero only on the element $e$.\n",
        "If an element $g$ acts on this function, it moves the non-zero value to the entry associated with $g$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UZJV-YfkcQLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8debb42c-1ff7-4cf3-c346-ed52bbd4991a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  1.,  0., -0., -0., -0., -0., -0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "rho(G.element(1)) @ f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qEHsuyIMcQLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdeaf27-ee33-402e-dea9-bf923bc7c2c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0., -0., -0., -0., -0., -0.,  1., -0.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "rho(G.element(6)) @ f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC2C598ScQLi"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 3\n",
        "Prove the result above.\n",
        "\n",
        "#### ANSWER 3\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I1Df5BEcQLi"
      },
      "source": [
        "#### Equivalent Representations\n",
        "\n",
        "Two representations $\\rho$ and $\\rho'$ of a group $G$ on the same vector space $\\mathbb{R}^d$ are called *equivalent* (or **isomorphic**) if and only if they are related by a change of basis $Q \\in \\mathbb{R}^{d \\times d}$, i.e.\n",
        "$$ \\forall g \\in G \\quad \\rho(g) = Q \\rho'(g) Q^{-1} \\ . $$\n",
        "\n",
        "Equivalent representations behave similarly since their composition is *basis-independent* as seen by\n",
        "$$ \\rho'(g_1) \\rho'(g_2) = Q \\rho(g_1)Q^{−1}Q \\rho(g_2)Q^{−1} = Q \\rho(g_1)\\rho(g_2)Q^{−1} \\ .$$\n",
        "\n",
        "*Direct sum* and *change of basis matrices* provide a way to combine representations to construct larger and more complex representations.\n",
        "In the next example, we concatenate two trivial representations and two regular representations and apply a random change of basis $Q$.\n",
        "The final representation is formally defined as:\n",
        "$$\n",
        "\\rho(g) = Q\n",
        "\\left(\n",
        "\\rho_\\text{trivial} \\oplus\n",
        "\\rho_\\text{regular} \\oplus\n",
        "\\rho_\\text{regular} \\oplus\n",
        "\\rho_\\text{trivial}\n",
        "\\right)\n",
        "Q^{-1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0OP51IsBcQLi"
      },
      "outputs": [],
      "source": [
        "d = G.trivial_representation.size * 2 + G.regular_representation.size * 2\n",
        "Q = np.random.randn(d, d)\n",
        "rho = directsum(\n",
        "    [G.trivial_representation, G.regular_representation, G.regular_representation, G.trivial_representation],\n",
        "    change_of_basis=Q\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ewPHjFszcQLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c55341-2b76-47ff-9ad2-a08c551c48bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "rho.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnegNCevcQLj"
      },
      "source": [
        "#### Irreducible Representations (or *Irreps*)\n",
        "\n",
        "Under minor conditions, any representation can be decomposed in this way, that is, any representation $\\rho$ of a compact group $G$ can be written as a *direct sum* of a number of smaller representations, up to a *change of basis*.\n",
        "These \"smaller representations\" can not be decomposed further and play a very important role in the theory of group representations and steerable CNNs and are called **irreducible representations**, or simply **irreps**.\n",
        "\n",
        "The set of *irreducible representations* of a group $G$ is generally denoted as $\\hat{G}$.\n",
        "We will often use the notation $\\hat{G} = \\{\\rho_j\\}_j$ to index this set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhzTXFsWcQLj"
      },
      "source": [
        "We can access the irreps of a group via the `irrep()` method.\n",
        "The *trivial representation* is *always* an irreducible representation.\n",
        "For $G=C_8$, we access it with the index $j=0$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JY-vdM2GcQLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3203e9ad-d2fe-43fa-9ecc-919dc5acb34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "rho_0 = G.irrep(0)\n",
        "\n",
        "print(rho_0 == G.trivial_representation)\n",
        "\n",
        "rho_0(G.sample())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re7L8u5McQLk"
      },
      "source": [
        "The next irrep $j=1$ gives the representation of $i\\frac{2\\pi}{8}$ as the $2 \\times 2$ rotation matrix by $\\theta = i\\frac{2\\pi}{8}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CePW0KyNcQLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f776aca-153d-4149-fa0e-e63173a2c766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1[2pi/8]\n",
            "\n",
            "[[ 0.707 -0.707]\n",
            " [ 0.707  0.707]]\n"
          ]
        }
      ],
      "source": [
        "rho = G.irrep(1)\n",
        "g = G.sample()\n",
        "\n",
        "print(g)\n",
        "print()\n",
        "print(rho(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Brfn36_cQLk"
      },
      "source": [
        "Irreducible representations provide the building blocks to construct any representation $\\rho$ via direct sums and change of basis, i.e:\n",
        "$$ \\rho = Q \\left( \\bigoplus_{j \\in \\mathcal{I}} \\rho_j \\right) Q^{-1} $$\n",
        "\n",
        "where $\\mathcal{I}$ is an index set (possibly with repetitions) over $\\hat{G}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6VbbktxcQLk"
      },
      "source": [
        "Internally, any `escnn.group.Representation` is indeed implemented as a list of irreps (representing the index set $\\mathcal{I}$) and a change of basis $Q$.\n",
        "An irrep is identified by a *tuple* `id`.\n",
        "\n",
        "Let's see an example.\n",
        "Let's take the regular representaiton of $C_8$ and check its decomposition into irreps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7gnOnfIncQLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3b479d-5470-402e-a199-2c1a6f04c8a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,), (1,), (2,), (3,), (4,)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "rho = G.regular_representation\n",
        "rho.irreps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HZ0vO35FcQLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8aa68a-3127-4669-ff6c-c1fb9bad2db0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.354,  0.5  ,  0.   ,  0.5  ,  0.   ,  0.5  ,  0.   ,  0.354],\n",
              "       [ 0.354,  0.354,  0.354,  0.   ,  0.5  , -0.354,  0.354, -0.354],\n",
              "       [ 0.354,  0.   ,  0.5  , -0.5  ,  0.   , -0.   , -0.5  ,  0.354],\n",
              "       [ 0.354, -0.354,  0.354, -0.   , -0.5  ,  0.354,  0.354, -0.354],\n",
              "       [ 0.354, -0.5  ,  0.   ,  0.5  , -0.   , -0.5  ,  0.   ,  0.354],\n",
              "       [ 0.354, -0.354, -0.354,  0.   ,  0.5  ,  0.354, -0.354, -0.354],\n",
              "       [ 0.354, -0.   , -0.5  , -0.5  ,  0.   ,  0.   ,  0.5  ,  0.354],\n",
              "       [ 0.354,  0.354, -0.354, -0.   , -0.5  , -0.354, -0.354, -0.354]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "rho.change_of_basis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aC8_wK4TcQLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab77894-29bf-4cdd-b98a-b8cb23086a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rho_id : (1,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.707, -0.707],\n",
              "       [ 0.707,  0.707]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# let's access second irrep\n",
        "rho_id = rho.irreps[1]\n",
        "print(f\"rho_id : {rho_id}\")\n",
        "rho_1 = G.irrep(*rho_id)\n",
        "\n",
        "# we verify it is the irrep j=1 we described before\n",
        "rho_1(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iajjFdqhid9U"
      },
      "source": [
        "Finally, let's verify that this direct sum and this change of basis indeed yield the regular representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VOfg1c1DitSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b4b6cd-e15a-410e-867c-3a57b108ec4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular representation of 1[2pi/8]\n",
            "[[ 0. -0.  0. -0. -0.  0. -0.  1.]\n",
            " [ 1.  0. -0. -0. -0. -0.  0. -0.]\n",
            " [ 0.  1.  0. -0.  0. -0. -0. -0.]\n",
            " [-0.  0.  1. -0. -0.  0. -0.  0.]\n",
            " [-0. -0. -0.  1.  0. -0.  0. -0.]\n",
            " [-0.  0. -0.  0.  1.  0.  0. -0.]\n",
            " [-0. -0.  0. -0.  0.  1.  0.  0.]\n",
            " [-0.  0. -0. -0.  0. -0.  1.  0.]]\n",
            "________________________________________\n",
            "Direct sum of the irreps:\n",
            "[[ 1.     0.     0.     0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.707 -0.707  0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.707  0.707  0.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     0.    -1.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     1.     0.     0.     0.     0.   ]\n",
            " [ 0.     0.     0.     0.     0.    -0.707 -0.707  0.   ]\n",
            " [ 0.     0.     0.     0.     0.     0.707 -0.707  0.   ]\n",
            " [ 0.     0.     0.     0.     0.     0.     0.    -1.   ]]\n",
            "________________________________________\n",
            "Apply the change of basis on the direct sum of the irreps:\n",
            "[[ 0. -0.  0. -0. -0.  0. -0.  1.]\n",
            " [ 1.  0. -0. -0. -0. -0.  0. -0.]\n",
            " [ 0.  1.  0. -0.  0. -0. -0. -0.]\n",
            " [-0.  0.  1.  0. -0.  0. -0.  0.]\n",
            " [-0. -0. -0.  1.  0. -0.  0. -0.]\n",
            " [-0.  0. -0.  0.  1.  0.  0. -0.]\n",
            " [-0. -0.  0. -0.  0.  1.  0.  0.]\n",
            " [-0.  0. -0. -0.  0. -0.  1.  0.]]\n",
            "________________________________________\n",
            "Are the two representations equal? True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# evaluate all the irreps in rho.irreps:\n",
        "irreps = [\n",
        "          G.irrep(*irrep)(g) for irrep in rho.irreps\n",
        "]\n",
        "\n",
        "# build the direct sum\n",
        "direct_sum = np.asarray(scipy.sparse.block_diag(irreps, format='csc').todense())\n",
        "\n",
        "print('Regular representation of', g)\n",
        "print(rho(g))\n",
        "print('_'*40)\n",
        "print('Direct sum of the irreps:')\n",
        "print(direct_sum)\n",
        "print(\"_\"*40)\n",
        "print('Apply the change of basis on the direct sum of the irreps:')\n",
        "print(rho.change_of_basis @ direct_sum @ rho.change_of_basis_inv)\n",
        "print(\"_\"*40)\n",
        "print('Are the two representations equal?', np.allclose(rho(g), rho.change_of_basis @ direct_sum @ rho.change_of_basis_inv))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn2amCSQcQLl"
      },
      "source": [
        "### 1.2 Fourier Transform\n",
        "\n",
        "We can finally approach the harmonic analysis of functions over a group $G$.\n",
        "\n",
        "Note that a representation $\\rho: G \\to \\mathbb{R}^{d \\times d}$ can be interpreted as a collection of $d^2$ functions over $G$, one for each matrix entry of $\\rho$.\n",
        "The **Peter-Weyl theorem** states that the collection of functions in the matrix entries of all irreps $\\hat{G}$ of a group $G$ spans the space of all (square-integrable) functions over $G$.\n",
        "\n",
        "This result gives us a way to parameterize functions over the group. This is the focus of this section.\n",
        "In particular, this is useful to parameterize functions over groups with infinite elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l0487w2cQLl"
      },
      "source": [
        "In this section, we will first consider the *dihedral group* $D_8$ as example.\n",
        "This is the group containing the $8$ planar rotations by angles multiple of $\\frac{2\\pi}{8}$ and *reflection* along the $X$ axis.\n",
        "The group contains in total $16$ elements ($8$ normal rotations and $8$ rotations preceeded by the reflection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "M7FGPHzFcQLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2ffc08-381f-4c21-f185-8f3c19aac466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "G = dihedral_group(8)\n",
        "G.order()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_P1zJdo7cQLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56b4e34-495c-4a0a-ec4c-c100c748af76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-, 0[2pi/8])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# element representing the reflection (-) and no rotations\n",
        "G.reflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VM64mjrYcQLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6665fa-b6b3-4bc9-d0ab-85620a153459"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(+, 2[2pi/8])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# element representing a rotation by pi/2 (i.e. 2 * 2pi/8) and no reflections (+)\n",
        "G.element((0, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wSPPV8xqcQLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba106f4-cb7e-4aef-9adb-ba7f0780fa53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-, 2[2pi/8])\n",
            "(-, 2[2pi/8])\n"
          ]
        }
      ],
      "source": [
        "# reflection followed by a rotation by pi/2\n",
        "print(G.element((0, 2)) @ G.reflection)\n",
        "\n",
        "# we can also directly generate this element as\n",
        "print(G.element((1, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yhXuYmCVcQLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d1e377-4aff-49ba-dfe4-c5e13dbc4d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True (-, 6[2pi/8])\n",
            "False (-, 2[2pi/8])\n"
          ]
        }
      ],
      "source": [
        "# a rotation by pi/2 followed by a reflection is equivalent to a reclection followed by a rotation by 6*2pi/8\n",
        "print(G.reflection @ G.element((0, 2)) == G.element((1, 6)), G.reflection @ G.element((0, 2)))\n",
        "\n",
        "print(G.element((0, 2))@G.reflection == G.element((1, 6)), G.element((0, 2))@G.reflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS-i3cMCcQLm"
      },
      "source": [
        "The list of all elements in the group is obtaied as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pN2RwwF8cQLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8841cfce-7d1e-405d-e799-8f6eaafe2b6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(+, 0[2pi/8]),\n",
              " (+, 1[2pi/8]),\n",
              " (+, 2[2pi/8]),\n",
              " (+, 3[2pi/8]),\n",
              " (+, 4[2pi/8]),\n",
              " (+, 5[2pi/8]),\n",
              " (+, 6[2pi/8]),\n",
              " (+, 7[2pi/8]),\n",
              " (-, 0[2pi/8]),\n",
              " (-, 1[2pi/8]),\n",
              " (-, 2[2pi/8]),\n",
              " (-, 3[2pi/8]),\n",
              " (-, 4[2pi/8]),\n",
              " (-, 5[2pi/8]),\n",
              " (-, 6[2pi/8]),\n",
              " (-, 7[2pi/8])]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "G.elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wteIYcqQcQLn"
      },
      "source": [
        "#### Fourier and Inverse Fourier Transform\n",
        "\n",
        "For most groups, the entries of the irreps don't only span the space of functions but form also a basis (i.e. these functions are mutually orthogonal to each other).\n",
        "Therefore, we can write a function $f: G \\to \\mathbb{R}$ as\n",
        "$$ f(g) = \\sum_{\\rho_j \\in \\hat{G}} \\sum_{m,n < d_j} w_{j,m,n} \\cdot \\sqrt{d_j} [\\rho_j(g)]_{mn}$$\n",
        "\n",
        "where $d_j$ is the dimension of the irrep $\\rho_j$, while $m, n$ index the $d_j^2$ entries of $\\rho_j$.\n",
        "The coefficients $\\{ w_{j, m, n} \\in \\mathbb{R} \\}_{j, m, n}$ parameterize the function $f$ on this basis.\n",
        "The $\\sqrt{d_j}$ is a scalar factor to ensure the basis is normalized.\n",
        "\n",
        "We rewrite this expression in a cleaner form by using the following fact.\n",
        "If $A, B \\in \\mathbb{R}^{d \\times d}$, then\n",
        "$$\\text{Tr}(A^T B) = \\sum_{m, n < d} A_{mn} B_{mn} \\in \\mathbb{R} \\ .$$\n",
        "\n",
        "By definining $\\hat{f}(\\rho_j) \\in \\mathbb{R}^{d_j \\times d_j}$ as the matrix containing the $d_j^2$ coefficients $\\{ w_{j, m, n} \\in \\mathbb{R} \\}_{m, n < d_j}$, we can express the **Inverse Fourier Transform** as:\n",
        "$$ f(g) = \\sum_{\\rho_j \\in \\hat{G}} \\sqrt{d_j} \\text{Tr}\\left(\\rho_j(g)^T \\hat{f}(\\rho_j)\\right) $$\n",
        "\n",
        "Similarly, we can project a general function $f: G \\to \\mathbb{R}$ on an element $\\rho_{j,m,n}: G \\to \\mathbb{R}$ of the basis via:\n",
        "$$ w_{j,m,n} = \\frac{1}{|G|} \\sum_{g \\in G} f(g) \\sqrt{d_j} [\\rho_j(g)]_{m, n} \\ . $$\n",
        "\n",
        "The projection over all entries of $\\rho_j$ can be more cleanly written as follows:\n",
        "$$ \\hat{f}(\\rho_j) = \\frac{1}{|G|} \\sum_{g \\in G} f(g) \\sqrt{d_j} \\rho_j(g) \\ . $$\n",
        "\n",
        "which we refer to as **Fourier Transform**.\n",
        "\n",
        "If the group $G$ is *infinite*, we replace the average over the group elements with an *integral* over them:\n",
        "$$ \\hat{f}(\\rho_j) = \\int_G f(g) \\sqrt{d_j} \\rho_j(g) dg \\ , $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SGtT8HqcQLn"
      },
      "source": [
        "For a finite group $G$, we can access all its irreps by using the ``Group.irreps()`` method.\n",
        "Let's see an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UX1j_wiMcQLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd7d65a-c10e-437b-b8c8-06d7a23103c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dihedral group D8 has 7 irreps\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[D8|[irrep_0,0]:1,\n",
              " D8|[irrep_1,0]:1,\n",
              " D8|[irrep_1,1]:2,\n",
              " D8|[irrep_1,2]:2,\n",
              " D8|[irrep_1,3]:2,\n",
              " D8|[irrep_1,4]:1,\n",
              " D8|[irrep_0,4]:1]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "irreps = G.irreps()\n",
        "print(f'The dihedral group D8 has {len(irreps)} irreps')\n",
        "irreps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = G.irrep(*irreps[2].id)\n",
        "h = G.sample()\n",
        "print(f\"group_element : {h}\")\n",
        "r.representation(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEXMm-5RvsZ_",
        "outputId": "16a0b6f5-3057-47c8-a7e9-5c023b31e617"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group_element : (+, 3[2pi/8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.707, -0.707],\n",
              "       [ 0.707, -0.707]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "U-DtyU37cQLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32c6dd5-0ae6-41ed-99f7-86c60e327b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# the first one, is the 1-dimensional trivial representation\n",
        "print(irreps[0] == G.trivial_representation == G.irrep(0, 0))\n",
        "irreps[3].size , irreps[-1].size , irreps[1].size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvTWLjOPcQLn"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 4\n",
        "We can now implement the Fourier Transform and the Inverse Fourier Transform for the Dihedral Group $D_8$.\n",
        "Using the equations above, implement the following methods:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qk-8qCYqcQLn"
      },
      "outputs": [],
      "source": [
        "def fourier_transform_D8(f: np.array):\n",
        "    # the method gets in input a function on the elements of D_8\n",
        "    # and should return a dictionary mapping each irrep's `id` to the corresponding Fourier Transform\n",
        "    # The i-th element of `f` stores the value of the function on the group element `G.elements[i]`\n",
        "\n",
        "    G = dihedral_group(8)\n",
        "    assert f.shape == (16,), f.shape\n",
        "    ft = {}\n",
        "\n",
        "    ########################\n",
        "    # INSERT YOUR CODE HERE:\n",
        "\n",
        "    # Iterate over all irreps\n",
        "    for irrep in  G.irreps():\n",
        "        irrep_id = irrep.id  # Unique identifier for the irrep\n",
        "        ft_irrep = np.zeros((irrep.size, irrep.size))\n",
        "\n",
        "        # Compute the sum over all group elements\n",
        "        for i, g in enumerate(G.elements):\n",
        "            ft_irrep += (f[i] * np.sqrt(irrep.size) * G.irrep(*irrep_id)(g)) / len(G.elements)\n",
        "\n",
        "        # Store the result in the dictionary\n",
        "        ft[irrep_id] = ft_irrep\n",
        "\n",
        "    ########################\n",
        "\n",
        "    return ft\n",
        "#_______________________________________________________________________________________________\n",
        "show_eg = False\n",
        "if show_eg:\n",
        "  # Eg\n",
        "  from escnn.group import dihedral_group\n",
        "  import numpy as np\n",
        "\n",
        "  G = dihedral_group(8)\n",
        "  f = np.random.rand(16)  # Random function values on D8\n",
        "\n",
        "  ft = fourier_transform_D8(f)\n",
        "\n",
        "  # Print the Fourier Transform for each irrep\n",
        "  for irrep_id, transform in ft.items():\n",
        "      print(f\"Irrep {irrep_id}:\")\n",
        "      print(transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "MZgP2GEHcQLo"
      },
      "outputs": [],
      "source": [
        "def inverse_fourier_transform_D8(ft: dict):\n",
        "    # the method gets in input a dictionary mapping each irrep's `id` to the corresponding Fourier Transform\n",
        "    # and should return the function `f` on the elements of D_8\n",
        "    # The i-th element of `f` stores the value of the function on the group element `G.elements[i]`\n",
        "\n",
        "    G = dihedral_group(8)\n",
        "    f = np.zeros(16)\n",
        "\n",
        "    ########################\n",
        "    # INSERT YOUR CODE HERE:\n",
        "    # Compute the inverse Fourier transform\n",
        "    for i, g in enumerate(G.elements):\n",
        "        # Initialize f(g) for this group element\n",
        "        value = 0\n",
        "        for irrep in G.irreps():\n",
        "            irrep_id = irrep.id\n",
        "            d_rho = irrep.size  # Dimension of the irrep\n",
        "            rho_g = irrep(g)  # Representation matrix of g\n",
        "            w = ft[irrep_id]  # Fourier coefficient for this irrep\n",
        "\n",
        "            # Add the contribution of this irrep to f(g)\n",
        "            value += np.sqrt(d_rho) * np.trace(rho_g.T @ w)\n",
        "\n",
        "        f[i] = value\n",
        "\n",
        "    ########################\n",
        "\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a random function on D8\n",
        "G = dihedral_group(8)\n",
        "f_original = np.random.rand(16)\n",
        "\n",
        "# Compute the Fourier Transform\n",
        "ft = fourier_transform_D8(f_original)\n",
        "\n",
        "# Compute the Inverse Fourier Transform\n",
        "f_reconstructed = inverse_fourier_transform_D8(ft)\n",
        "\n",
        "# Verify the reconstruction\n",
        "print(\"Original f:\", f_original)\n",
        "print(\"Reconstructed f:\", f_reconstructed)\n",
        "print(\"Difference:\", np.abs(f_original - f_reconstructed))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9yWX19Yp7kP",
        "outputId": "9fbcfd35-52fd-4682-b443-699afbcf5777"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original f: [0.356 0.945 0.867 0.401 0.264 0.39  0.891 0.393 0.73  0.109 0.37  0.575 0.034 0.87  0.664 0.702]\n",
            "Reconstructed f: [0.356 0.945 0.867 0.401 0.264 0.39  0.891 0.393 0.73  0.109 0.37  0.575 0.034 0.87  0.664 0.702]\n",
            "Difference: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3E0QDIOcQLo"
      },
      "source": [
        "We now want to verify that the **Fourier Transform** and the **Inverse Fourier Transform** are inverse of each other:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OF6A_JzwcQLo"
      },
      "outputs": [],
      "source": [
        "f = np.random.randn(16)\n",
        "\n",
        "ft = fourier_transform_D8(f)\n",
        "\n",
        "new_f = inverse_fourier_transform_D8(ft)\n",
        "\n",
        "assert np.allclose(f, new_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Dyf0j9cQLo"
      },
      "source": [
        "#### Parameterizing functions over infinite groups\n",
        "This allows us to also parameterize functions over infinite groups, such as $O(2)$, i.e. the group of all planar rotations and reflections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "I9ezRrM0cQLo"
      },
      "outputs": [],
      "source": [
        "G = o2_group()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "a_VzVXqUcQLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f7ced8-20d4-4bcd-86ca-e18b9fec6377"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# the group has infinite many elements, so the `order` method just returns -1\n",
        "G.order()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0to6C36EcQLp"
      },
      "source": [
        "The equations remain the same, but this group has an *infinite* number of *irreps*.\n",
        "We can, however, parameterize a function over the group by only considering a finite number of irreps in the sum inside the definition of *Inverse Fourier Transform*.\n",
        "Let $\\tilde{G} \\subset \\hat{G}$ be a finite subset of the irreps of $G$.\n",
        "We can then write the following transforms within the subspace of functions spanned only by the entries of the irreps in $\\tilde{G}$.\n",
        "\n",
        "**Inverse Fourier Transform**:\n",
        "$$ f(g) = \\sum_{\\rho_j \\in \\tilde{G}} \\sqrt{d_j} \\text{Tr}\\left(\\rho_j(g)^T \\hat{f}(\\rho_j)\\right) $$\n",
        "\n",
        "and **Fourier Transform**:\n",
        "$$ \\hat{f}(\\rho_j) = \\int_G f(g) \\sqrt{d_j} \\rho_j(g) dg \\ , $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysGoKX7rcQLp"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 5\n",
        "We can now implement the Inverse Fourier Transform for the Orthogonal Group $O(2)$.\n",
        "Since the group has infinite many elements, we can not store the values the function take on each element.\n",
        "Instead, we just sample the function on a particular element of the group:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xlca8Xv8cQLp"
      },
      "outputs": [],
      "source": [
        "def inverse_fourier_transform_O2(g: GroupElement, ft: dict):\n",
        "    # the method gets in input a dictionary mapping each irrep's `id` to the corresponding Fourier Transform\n",
        "    # and a group element `g`\n",
        "    # The method should return the value of the function evaluated on `g`.\n",
        "\n",
        "    G = o2_group()\n",
        "    f = 0\n",
        "\n",
        "    ########################\n",
        "    # INSERT YOUR CODE HERE:\n",
        "    for irrep_id, w in ft.items():\n",
        "        # Retrieve the representation matrix rho_j(g) for the current irrep\n",
        "        rho_g = G.irrep(*irrep_id)(g)    # Assuming this method exists\n",
        "\n",
        "        # Calculate trace term: Tr(rho_j(g)^T @ ft_matrix)\n",
        "        trace_term = np.trace(rho_g.T @ w)\n",
        "\n",
        "        # Calculate dimension scaling factor sqrt(d_j)\n",
        "        d_j = rho_g.shape[0]  # Dimension of the representation\n",
        "        scaling_factor = np.sqrt(d_j)\n",
        "\n",
        "        # Accumulate the result\n",
        "        f += scaling_factor * trace_term\n",
        "\n",
        "    ########################\n",
        "\n",
        "    return f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0JPQeYXcQLp"
      },
      "source": [
        "Let's plot a function.\n",
        "First we generate a random function by using a few irreps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "l8HxIbnDcQLp"
      },
      "outputs": [],
      "source": [
        "irreps = [G.irrep(0, 0)] + [G.irrep(1, j) for j in range(3)]\n",
        "\n",
        "ft = {        # representing weights of fourier transform\n",
        "    rho.id: np.random.randn(rho.size, rho.size)\n",
        "    for rho in irreps\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX-v7YNJcQLp"
      },
      "source": [
        "Then, we generate a grid on the group where to evaluate the function, i.e. we choose a finite set of element of $G$.\n",
        "Like the Dihedral group, $O(2)$ contains rotations (parameterized by an angle $\\theta \\in [0, 2\\pi)$) and a reflection followed by any rotation.\n",
        "For example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGREVzLKcQLq"
      },
      "source": [
        "To build our grid, we sample $100$ rotations and $100$ rotations preceeded by a reflection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xIcA1mfAcQLq"
      },
      "outputs": [],
      "source": [
        "N = 100\n",
        "thetas = [i*2*np.pi/N for i in range(N)]\n",
        "grid_rot = [G.element((0, theta)) for theta in thetas]\n",
        "grid_refl = [G.element((1, theta)) for theta in thetas]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_rot[10] , grid_refl[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJSQrmMg7_R_",
        "outputId": "c5b2fb9d-28bf-48cd-c2a6-000468b90b92"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((+, 0.6283185307179586), (-, 0.6283185307179586))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCCVddnocQLq"
      },
      "source": [
        "We now evaluate the function over all these elements and, finally, plot it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsDDkSKOcQLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "0c597d8f-fa21-4207-9ccf-5fefb39cda8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"406.940312pt\" height=\"310.86825pt\" viewBox=\"0 0 406.940312 310.86825\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-01-09T12:19:56.229954</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 310.86825 \nL 406.940312 310.86825 \nL 406.940312 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 42.620313 273.312 \nL 399.740313 273.312 \nL 399.740313 7.2 \nL 42.620313 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m84ede7d90f\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"58.85304\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.67179 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"111.045338\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(107.864088 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"163.237637\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(160.056387 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"215.429936\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(212.248686 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"267.622235\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(264.440985 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"319.814533\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(316.633283 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m84ede7d90f\" x=\"372.006832\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(368.825582 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- theta [0, 2pi) -->\n     <g transform=\"translate(188.356094 301.588562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \nL 1875 4863 \nL 1875 4416 \nL 1125 4416 \nL 1125 -397 \nL 1875 -397 \nL 1875 -844 \nL 550 -844 \nL 550 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(39.208984 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(102.587891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(164.111328 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(203.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(264.599609 0)\"/>\n      <use xlink:href=\"#DejaVuSans-5b\" transform=\"translate(296.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(335.400391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(399.023438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(430.810547 0)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(462.597656 0)\"/>\n      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(526.220703 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(589.697266 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(617.480469 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m3a601b917e\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"252.748629\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −5 -->\n      <g transform=\"translate(20.878125 256.547848) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"216.556966\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −4 -->\n      <g transform=\"translate(20.878125 220.356185) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"180.365302\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −3 -->\n      <g transform=\"translate(20.878125 184.164521) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"144.173639\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- −2 -->\n      <g transform=\"translate(20.878125 147.972858) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"107.981976\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- −1 -->\n      <g transform=\"translate(20.878125 111.781195) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"71.790312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0 -->\n      <g transform=\"translate(29.257813 75.589531) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m3a601b917e\" x=\"42.620313\" y=\"35.598649\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1 -->\n      <g transform=\"translate(29.257813 39.397868) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- f(g) -->\n     <g transform=\"translate(14.798438 149.091937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(35.205078 0)\"/>\n      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(74.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(137.695312 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 58.85304 83.509509 \nL 62.132379 81.988671 \nL 65.411717 80.627826 \nL 68.691056 79.384513 \nL 71.970395 78.217026 \nL 75.249734 77.085319 \nL 78.529073 75.951864 \nL 81.808412 74.782464 \nL 85.087751 73.546996 \nL 88.367089 72.220081 \nL 91.646428 70.781655 \nL 94.925767 69.217455 \nL 98.205106 67.519383 \nL 101.484445 65.685767 \nL 104.763784 63.7215 \nL 108.043122 61.638054 \nL 111.322461 59.453379 \nL 114.6018 57.191678 \nL 117.881139 54.883066 \nL 121.160478 52.563117 \nL 124.439817 50.272305 \nL 127.719155 48.055352 \nL 130.998494 45.960489 \nL 134.277833 44.038641 \nL 137.557172 42.342554 \nL 140.836511 40.925877 \nL 144.11585 39.842207 \nL 147.395189 39.14412 \nL 150.674527 38.882204 \nL 153.953866 39.104104 \nL 157.233205 39.8536 \nL 160.512544 41.169727 \nL 163.791883 43.085961 \nL 167.071222 45.629478 \nL 170.35056 48.820495 \nL 173.629899 52.671719 \nL 176.909238 57.187891 \nL 180.188577 62.365458 \nL 183.467916 68.19236 \nL 186.747255 74.647947 \nL 190.026593 81.703019 \nL 193.305932 89.320006 \nL 196.585271 97.453266 \nL 199.86461 106.049511 \nL 203.143949 115.048355 \nL 206.423288 124.382963 \nL 209.702627 133.980815 \nL 212.981965 143.764552 \nL 216.261304 153.652903 \nL 219.540643 163.561683 \nL 222.819982 173.40483 \nL 226.099321 183.095494 \nL 229.37866 192.547129 \nL 232.657998 201.674601 \nL 235.937337 210.395277 \nL 239.216676 218.630085 \nL 242.496015 226.304532 \nL 245.775354 233.349662 \nL 249.054693 239.702931 \nL 252.334032 245.309011 \nL 255.61337 250.120478 \nL 258.892709 254.098402 \nL 262.172048 257.212813 \nL 265.451387 259.443048 \nL 268.730726 260.777959 \nL 272.010065 261.216 \nL 275.289403 260.765169 \nL 278.568742 259.442826 \nL 281.848081 257.27538 \nL 285.12742 254.297846 \nL 288.406759 250.553294 \nL 291.686098 246.092185 \nL 294.965436 240.971604 \nL 298.244775 235.254418 \nL 301.524114 229.008352 \nL 304.803453 222.305012 \nL 308.082792 215.218857 \nL 311.362131 207.826154 \nL 314.64147 200.203911 \nL 317.920808 192.428822 \nL 321.200147 184.576226 \nL 324.479486 176.719106 \nL 327.758825 168.927142 \nL 331.038164 161.265824 \nL 334.317503 153.795642 \nL 337.596841 146.571377 \nL 340.87618 139.641482 \nL 344.155519 133.047575 \nL 347.434858 126.824053 \nL 350.714197 120.997823 \nL 353.993536 115.588156 \nL 357.272874 110.606676 \nL 360.552213 106.05746 \nL 363.831552 101.937272 \nL 367.110891 98.235912 \nL 370.39023 94.936667 \nL 373.669569 92.016877 \nL 376.948908 89.448585 \nL 380.228246 87.199267 \nL 383.507585 85.23264 \n\" clip-path=\"url(#p7b4b820092)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 58.85304 29.421732 \nL 62.132379 30.777515 \nL 65.411717 32.154927 \nL 68.691056 33.551276 \nL 71.970395 34.96663 \nL 75.249734 36.403739 \nL 78.529073 37.867883 \nL 81.808412 39.366686 \nL 85.087751 40.909869 \nL 88.367089 42.50897 \nL 91.646428 44.177016 \nL 94.925767 45.92817 \nL 98.205106 47.777345 \nL 101.484445 49.739804 \nL 104.763784 51.830742 \nL 108.043122 54.064864 \nL 111.322461 56.455967 \nL 114.6018 59.016525 \nL 117.881139 61.757301 \nL 121.160478 64.686967 \nL 124.439817 67.811768 \nL 127.719155 71.135217 \nL 130.998494 74.657826 \nL 134.277833 78.376896 \nL 137.557172 82.286345 \nL 140.836511 86.3766 \nL 144.11585 90.63454 \nL 147.395189 95.043503 \nL 150.674527 99.583347 \nL 153.953866 104.230574 \nL 157.233205 108.958511 \nL 160.512544 113.737544 \nL 163.791883 118.535413 \nL 167.071222 123.317544 \nL 170.35056 128.047439 \nL 173.629899 132.687091 \nL 176.909238 137.197445 \nL 180.188577 141.538875 \nL 183.467916 145.671687 \nL 186.747255 149.556632 \nL 190.026593 153.15542 \nL 193.305932 156.431235 \nL 196.585271 159.349235 \nL 199.86461 161.877041 \nL 203.143949 163.985184 \nL 206.423288 165.647538 \nL 209.702627 166.841699 \nL 212.981965 167.549324 \nL 216.261304 167.756418 \nL 219.540643 167.453569 \nL 222.819982 166.636115 \nL 226.099321 165.304262 \nL 229.37866 163.463123 \nL 232.657998 161.122707 \nL 235.937337 158.297831 \nL 239.216676 155.007976 \nL 242.496015 151.277081 \nL 245.775354 147.13327 \nL 249.054693 142.608534 \nL 252.334032 137.738357 \nL 255.61337 132.561299 \nL 258.892709 127.118536 \nL 262.172048 121.453373 \nL 265.451387 115.610729 \nL 268.730726 109.6366 \nL 272.010065 103.577523 \nL 275.289403 97.480022 \nL 278.568742 91.390075 \nL 281.848081 85.35258 \nL 285.12742 79.410856 \nL 288.406759 73.606159 \nL 291.686098 67.977241 \nL 294.965436 62.559948 \nL 298.244775 57.38686 \nL 301.524114 52.486988 \nL 304.803453 47.885527 \nL 308.082792 43.603658 \nL 311.362131 39.658421 \nL 314.64147 36.062645 \nL 317.920808 32.82494 \nL 321.200147 29.949749 \nL 324.479486 27.437466 \nL 327.758825 25.284606 \nL 331.038164 23.484027 \nL 334.317503 22.025208 \nL 337.596841 20.894568 \nL 340.87618 20.075824 \nL 344.155519 19.550382 \nL 347.434858 19.297755 \nL 350.714197 19.296 \nL 353.993536 19.522167 \nL 357.272874 19.952751 \nL 360.552213 20.564139 \nL 363.831552 21.333053 \nL 367.110891 22.236968 \nL 370.39023 23.254509 \nL 373.669569 24.365818 \nL 376.948908 25.552877 \nL 380.228246 26.799801 \nL 383.507585 28.093072 \n\" clip-path=\"url(#p7b4b820092)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 42.620313 273.312 \nL 42.620313 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 399.740313 273.312 \nL 399.740313 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 42.620313 273.312 \nL 399.740313 273.312 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 42.620313 7.2 \nL 399.740313 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 49.620313 268.312 \nL 187.917188 268.312 \nQ 189.917188 268.312 189.917188 266.312 \nL 189.917188 237.95575 \nQ 189.917188 235.95575 187.917188 235.95575 \nL 49.620313 235.95575 \nQ 47.620313 235.95575 47.620313 237.95575 \nL 47.620313 266.312 \nQ 47.620313 268.312 49.620313 268.312 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 51.620313 244.054187 \nL 61.620313 244.054187 \nL 71.620313 244.054187 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_17\">\n     <!-- rotations -->\n     <g transform=\"translate(79.620313 247.554187) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(100.044922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(139.253906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(200.533203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(239.742188 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(267.525391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(328.707031 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(392.085938 0)\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 51.620313 258.732312 \nL 61.620313 258.732312 \nL 71.620313 258.732312 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- reflection + rotations -->\n     <g transform=\"translate(79.620313 262.232312) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2b\" d=\"M 2944 4013 \nL 2944 2272 \nL 4684 2272 \nL 4684 1741 \nL 2944 1741 \nL 2944 0 \nL 2419 0 \nL 2419 1741 \nL 678 1741 \nL 678 2272 \nL 2419 2272 \nL 2419 4013 \nL 2944 4013 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-66\" transform=\"translate(100.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(135.591797 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(163.375 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(224.898438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(279.878906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(319.087891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(346.871094 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(408.052734 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(471.431641 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2b\" transform=\"translate(503.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(587.007812 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(618.794922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(657.658203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(718.839844 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(758.048828 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(819.328125 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(858.537109 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(886.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(947.501953 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1010.880859 0)\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7b4b820092\">\n   <rect x=\"42.620313\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "f_rot = [\n",
        "    inverse_fourier_transform_O2(g, ft) for g in grid_rot\n",
        "]\n",
        "f_refl = [\n",
        "    inverse_fourier_transform_O2(g, ft) for g in grid_refl\n",
        "]\n",
        "\n",
        "\n",
        "plt.plot(thetas, f_rot, label='rotations')\n",
        "plt.plot(thetas, f_refl, label='reflection + rotations')\n",
        "plt.xlabel('theta [0, 2pi)')\n",
        "plt.ylabel('f(g)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH5RBOBZcQLq"
      },
      "source": [
        "Observe that using more irreps allows one to parameterize more flexible functions.\n",
        "Let's try to add some more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Ic9uAMJEcQLr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "963eba22-74cb-4a04-a8f0-b0364aab05e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"413.302812pt\" height=\"310.86825pt\" viewBox=\"0 0 413.302812 310.86825\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-01-11T01:33:57.915123</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 310.86825 \nL 413.302812 310.86825 \nL 413.302812 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 48.982813 273.312 \nL 406.102813 273.312 \nL 406.102813 7.2 \nL 48.982813 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m7e4d699173\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"65.21554\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(62.03429 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"117.407838\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(114.226588 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"169.600137\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(166.418887 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"221.792436\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(218.611186 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"273.984735\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(270.803485 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"326.177033\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(322.995783 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m7e4d699173\" x=\"378.369332\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(375.188082 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- theta [0, 2pi) -->\n     <g transform=\"translate(194.718594 301.588562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \nL 1875 4863 \nL 1875 4416 \nL 1125 4416 \nL 1125 -397 \nL 1875 -397 \nL 1875 -844 \nL 550 -844 \nL 550 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(39.208984 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(102.587891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(164.111328 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(203.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(264.599609 0)\"/>\n      <use xlink:href=\"#DejaVuSans-5b\" transform=\"translate(296.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(335.400391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(399.023438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(430.810547 0)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(462.597656 0)\"/>\n      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(526.220703 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(589.697266 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(617.480469 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m42d4142868\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m42d4142868\" x=\"48.982813\" y=\"253.005991\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −15 -->\n      <g transform=\"translate(20.878125 256.80521) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(147.412109 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m42d4142868\" x=\"48.982813\" y=\"208.877041\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −10 -->\n      <g transform=\"translate(20.878125 212.676259) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(147.412109 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m42d4142868\" x=\"48.982813\" y=\"164.74809\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −5 -->\n      <g transform=\"translate(27.240625 168.547309) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m42d4142868\" x=\"48.982813\" y=\"120.61914\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(35.620313 124.418359) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m42d4142868\" x=\"48.982813\" y=\"76.49019\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 5 -->\n      <g transform=\"translate(35.620313 80.289408) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m42d4142868\" x=\"48.982813\" y=\"32.361239\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 10 -->\n      <g transform=\"translate(29.257813 36.160458) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- f(g) -->\n     <g transform=\"translate(14.798438 149.091937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(35.205078 0)\"/>\n      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(74.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(137.695312 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 65.21554 149.724691 \nL 68.494879 159.008396 \nL 71.774217 169.597538 \nL 75.053556 179.740349 \nL 78.332895 187.415187 \nL 81.612234 190.703574 \nL 84.891573 188.178025 \nL 88.170912 179.232171 \nL 91.450251 164.288029 \nL 94.729589 144.834938 \nL 98.008928 123.283216 \nL 101.288267 102.648159 \nL 104.567606 86.110559 \nL 107.846945 76.523034 \nL 111.126284 75.942896 \nL 114.405622 85.269783 \nL 117.684961 104.050228 \nL 120.9643 130.484458 \nL 124.243639 161.637641 \nL 127.522978 193.82436 \nL 130.802317 223.106974 \nL 134.081655 245.830662 \nL 137.360994 259.113139 \nL 140.640333 261.216 \nL 143.919672 251.745469 \nL 147.199011 231.65915 \nL 150.47835 203.087034 \nL 153.757689 169.00386 \nL 157.037027 132.811221 \nL 160.316366 97.8981 \nL 163.595705 67.246554 \nL 166.875044 43.136183 \nL 170.154383 26.979603 \nL 173.433722 19.296 \nL 176.71306 19.805607 \nL 179.992399 27.609273 \nL 183.271738 41.40713 \nL 186.551077 59.710223 \nL 189.830416 81.008023 \nL 193.109755 103.870598 \nL 196.389093 126.983043 \nL 199.668432 149.127379 \nL 202.947771 169.139725 \nL 206.22711 185.875445 \nL 209.506449 198.211329 \nL 212.785788 205.102533 \nL 216.065127 205.695688 \nL 219.344465 199.481957 \nL 222.623804 186.458967 \nL 225.903143 167.26202 \nL 229.182482 143.225075 \nL 232.461821 116.341224 \nL 235.74116 89.109281 \nL 239.020498 64.274752 \nL 242.299837 44.4954 \nL 245.579176 31.979695 \nL 248.858515 28.156473 \nL 252.137854 33.433924 \nL 255.417193 47.094781 \nL 258.696532 67.354039 \nL 261.97587 91.579018 \nL 265.255209 116.643753 \nL 268.534548 139.365679 \nL 271.813887 156.95689 \nL 275.093226 167.417943 \nL 278.372565 169.810405 \nL 281.651903 164.363837 \nL 284.931242 152.400381 \nL 288.210581 136.090829 \nL 291.48992 118.084455 \nL 294.769259 101.075966 \nL 298.048598 87.382909 \nL 301.327936 78.603852 \nL 304.607275 75.412398 \nL 307.886614 77.517199 \nL 311.165953 83.788352 \nL 314.445292 92.521148 \nL 317.724631 101.784611 \nL 321.00397 109.788654 \nL 324.283308 115.2025 \nL 327.562647 117.368219 \nL 330.841986 116.374516 \nL 334.121325 112.983251 \nL 337.400664 108.429252 \nL 340.680003 104.137518 \nL 343.959341 101.416554 \nL 347.23868 101.189558 \nL 350.518019 103.81622 \nL 353.797358 109.03868 \nL 357.076697 116.059735 \nL 360.356036 123.734531 \nL 363.635374 130.834108 \nL 366.914713 136.32466 \nL 370.194052 139.603168 \nL 373.473391 140.63874 \nL 376.75273 139.98797 \nL 380.032069 138.678166 \nL 383.311408 137.979482 \nL 386.590746 139.110461 \nL 389.870085 142.936543 \n\" clip-path=\"url(#pe4df723999)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 65.21554 48.034726 \nL 68.494879 45.295923 \nL 71.774217 46.790944 \nL 75.053556 52.817645 \nL 78.332895 63.000089 \nL 81.612234 76.303728 \nL 84.891573 91.17004 \nL 88.170912 105.749215 \nL 91.450251 118.19167 \nL 94.729589 126.948283 \nL 98.008928 131.027127 \nL 101.288267 130.161601 \nL 104.567606 124.859865 \nL 107.846945 116.325868 \nL 111.126284 106.264301 \nL 114.405622 96.601737 \nL 117.684961 89.17059 \nL 120.9643 85.408789 \nL 124.243639 86.125248 \nL 127.522978 91.369926 \nL 130.802317 100.429374 \nL 134.081655 111.947536 \nL 137.360994 124.150653 \nL 140.640333 135.138098 \nL 143.919672 143.190675 \nL 147.199011 147.045857 \nL 150.47835 146.095895 \nL 153.757689 140.478361 \nL 157.037027 131.046916 \nL 160.316366 119.229914 \nL 163.595705 106.802264 \nL 166.875044 95.609061 \nL 170.154383 87.285767 \nL 173.433722 83.018449 \nL 176.71306 83.379364 \nL 179.992399 88.259676 \nL 183.271738 96.904876 \nL 186.551077 108.042337 \nL 189.830416 120.077087 \nL 193.109755 131.323198 \nL 196.389093 140.235403 \nL 199.668432 145.608427 \nL 202.947771 146.719221 \nL 206.22711 143.39795 \nL 209.506449 136.025206 \nL 212.785788 125.463404 \nL 216.065127 112.938089 \nL 219.344465 99.889052 \nL 222.623804 87.811616 \nL 225.903143 78.105738 \nL 229.182482 71.945969 \nL 232.461821 70.179995 \nL 235.74116 73.258861 \nL 239.020498 81.198786 \nL 242.299837 93.573132 \nL 245.579176 109.533275 \nL 248.858515 127.858124 \nL 252.137854 147.032895 \nL 255.417193 165.357483 \nL 258.696532 181.082809 \nL 261.97587 192.56974 \nL 265.255209 198.460033 \nL 268.534548 197.843357 \nL 271.813887 190.400084 \nL 275.093226 176.497669 \nL 278.372565 157.220157 \nL 281.651903 134.316094 \nL 284.931242 110.059716 \nL 288.210581 87.032456 \nL 291.48992 67.844789 \nL 294.769259 54.830011 \nL 298.048598 49.74934 \nL 301.327936 53.550089 \nL 304.607275 66.214444 \nL 307.886614 86.725805 \nL 311.165953 113.16389 \nL 314.445292 142.921161 \nL 317.724631 173.014558 \nL 321.00397 200.45104 \nL 324.283308 222.595931 \nL 327.562647 237.49123 \nL 330.841986 244.077651 \nL 334.121325 242.288265 \nL 337.400664 233.001225 \nL 340.680003 217.860939 \nL 343.959341 198.997654 \nL 347.23868 178.691272 \nL 350.518019 159.033578 \nL 353.797358 141.642459 \nL 357.076697 127.472167 \nL 360.356036 116.746834 \nL 363.635374 109.02311 \nL 366.914713 103.365656 \nL 370.194052 98.60013 \nL 373.473391 93.595496 \nL 376.75273 87.5233 \nL 380.032069 80.046536 \nL 383.311408 71.404175 \nL 386.590746 62.376701 \nL 389.870085 54.139922 \n\" clip-path=\"url(#pe4df723999)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 48.982813 273.312 \nL 48.982813 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 406.102813 273.312 \nL 406.102813 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 48.982813 273.312 \nL 406.102813 273.312 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 48.982813 7.2 \nL 406.102813 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 260.805938 44.55625 \nL 399.102813 44.55625 \nQ 401.102813 44.55625 401.102813 42.55625 \nL 401.102813 14.2 \nQ 401.102813 12.2 399.102813 12.2 \nL 260.805938 12.2 \nQ 258.805938 12.2 258.805938 14.2 \nL 258.805938 42.55625 \nQ 258.805938 44.55625 260.805938 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 262.805938 20.298437 \nL 272.805938 20.298437 \nL 282.805938 20.298437 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- rotations -->\n     <g transform=\"translate(290.805938 23.798437) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(100.044922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(139.253906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(200.533203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(239.742188 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(267.525391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(328.707031 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(392.085938 0)\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 262.805938 34.976562 \nL 272.805938 34.976562 \nL 282.805938 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_17\">\n     <!-- reflection + rotations -->\n     <g transform=\"translate(290.805938 38.476562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2b\" d=\"M 2944 4013 \nL 2944 2272 \nL 4684 2272 \nL 4684 1741 \nL 2944 1741 \nL 2944 0 \nL 2419 0 \nL 2419 1741 \nL 678 1741 \nL 678 2272 \nL 2419 2272 \nL 2419 4013 \nL 2944 4013 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-66\" transform=\"translate(100.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(135.591797 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(163.375 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(224.898438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(279.878906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(319.087891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(346.871094 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(408.052734 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(471.431641 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2b\" transform=\"translate(503.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(587.007812 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(618.794922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(657.658203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(718.839844 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(758.048828 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(819.328125 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(858.537109 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(886.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(947.501953 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1010.880859 0)\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe4df723999\">\n   <rect x=\"48.982813\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "irreps = [G.irrep(0, 0)] + [G.irrep(1, j) for j in range(8)]\n",
        "\n",
        "ft = {\n",
        "    rho.id: np.random.randn(rho.size, rho.size)\n",
        "    for rho in irreps\n",
        "}\n",
        "\n",
        "f_rot = [\n",
        "    inverse_fourier_transform_O2(g, ft) for g in grid_rot\n",
        "]\n",
        "f_refl = [\n",
        "    inverse_fourier_transform_O2(g, ft) for g in grid_refl\n",
        "]\n",
        "\n",
        "\n",
        "plt.plot(thetas, f_rot, label='rotations')\n",
        "plt.plot(thetas, f_refl, label='reflection + rotations')\n",
        "plt.xlabel('theta [0, 2pi)')\n",
        "plt.ylabel('f(g)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ-VvAUmcQLr"
      },
      "source": [
        "#### Fourier Transform of shifted functions\n",
        "\n",
        "Recall that a group element $g \\in G$ can act on a function $f: G \\to \\mathbb{R}$ as:\n",
        "$$ [g.f](h) = f(g^{-1}h) \\ .$$\n",
        "\n",
        "The Fourier transform defined before has the convenient property that the Fourier transform of $f$ and of $[g.f]$ are related as follows:\n",
        "$$\\widehat{g.f}(\\rho_j) = \\rho_j(g) \\widehat{f} $$\n",
        "\n",
        "for any irrep $\\rho_j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_qj4VCacQLr"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 6\n",
        "Prove the property above.\n",
        "\n",
        "#### ANSWER 6\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QtTiJ6fcQLr"
      },
      "source": [
        "We can verify this property visually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "RaPtUhgxcQLr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "88704ffc-a35f-4f97-b31b-d2f706d94e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming the function with g=(+, 3.558464390171007)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"856.442812pt\" height=\"351.034375pt\" viewBox=\"0 0 856.442812 351.034375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-01-11T01:38:01.335975</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 351.034375 \nL 856.442812 351.034375 \nL 856.442812 0 \nL -0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 48.982813 313.478125 \nL 422.642813 313.478125 \nL 422.642813 22.318125 \nL 48.982813 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m28ecbd9866\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"65.967358\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(62.786108 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"120.576941\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(117.395691 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"175.186524\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(172.005274 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"229.796107\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(226.614857 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"284.405691\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(281.224441 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"339.015274\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(335.834024 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"393.624857\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(390.443607 328.076563) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- theta [0, 2pi) -->\n     <g transform=\"translate(202.988594 341.754687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \nL 1875 4863 \nL 1875 4416 \nL 1125 4416 \nL 1125 -397 \nL 1875 -397 \nL 1875 -844 \nL 550 -844 \nL 550 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(39.208984 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(102.587891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(164.111328 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(203.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(264.599609 0)\"/>\n      <use xlink:href=\"#DejaVuSans-5b\" transform=\"translate(296.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(335.400391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(399.023438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(430.810547 0)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(462.597656 0)\"/>\n      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(526.220703 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(589.697266 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(617.480469 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m4ebf752626\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"48.982813\" y=\"287.072109\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −15 -->\n      <g transform=\"translate(20.878125 290.871328) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(147.412109 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"48.982813\" y=\"237.05151\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −10 -->\n      <g transform=\"translate(20.878125 240.850729) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(147.412109 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"48.982813\" y=\"187.030911\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −5 -->\n      <g transform=\"translate(27.240625 190.83013) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"48.982813\" y=\"137.010313\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(35.620312 140.809531) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"48.982813\" y=\"86.989714\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 5 -->\n      <g transform=\"translate(35.620312 90.788932) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"48.982813\" y=\"36.969115\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 10 -->\n      <g transform=\"translate(29.257812 40.768334) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- f(g) -->\n     <g transform=\"translate(14.798438 176.734063) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(35.205078 0)\"/>\n      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(74.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(137.695312 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 65.967358 177.992597 \nL 69.398579 175.904097 \nL 72.829801 177.099832 \nL 76.261022 179.311888 \nL 79.692243 180.184774 \nL 83.123464 177.786719 \nL 86.554686 171.032437 \nL 89.985907 159.935316 \nL 93.417128 145.638964 \nL 96.84835 130.219535 \nL 100.279571 116.293734 \nL 103.710792 106.504686 \nL 107.142014 102.98199 \nL 110.573235 106.878687 \nL 114.004456 118.075231 \nL 117.435678 135.111003 \nL 120.866899 155.362811 \nL 124.29812 175.444631 \nL 127.729341 191.761841 \nL 131.160563 201.123897 \nL 134.591784 201.307261 \nL 138.023005 191.46769 \nL 141.454227 172.326533 \nL 144.885448 146.094871 \nL 148.316669 116.145195 \nL 151.747891 86.484589 \nL 155.179112 61.11814 \nL 158.610333 43.41039 \nL 162.041554 35.55267 \nL 165.472776 38.225359 \nL 168.903997 50.509827 \nL 172.335218 70.061456 \nL 175.76644 93.510352 \nL 179.197661 117.018152 \nL 182.628882 136.894407 \nL 186.060104 150.168325 \nL 189.491325 155.022448 \nL 192.922546 151.02143 \nL 196.353768 139.106608 \nL 199.784989 121.36832 \nL 203.21621 100.645566 \nL 206.647431 80.029945 \nL 210.078653 62.363396 \nL 213.509874 49.815325 \nL 216.941095 43.605687 \nL 220.372317 43.910604 \nL 223.803538 49.952119 \nL 227.234759 60.240424 \nL 230.665981 72.911473 \nL 234.097202 86.089665 \nL 237.528423 98.206197 \nL 240.959644 108.217796 \nL 244.390866 115.694488 \nL 247.822087 120.773644 \nL 251.253308 124.004838 \nL 254.68453 126.130713 \nL 258.115751 127.859068 \nL 261.546972 129.679265 \nL 264.978194 131.762579 \nL 268.409415 133.964642 \nL 271.840636 135.9233 \nL 275.271857 137.222613 \nL 278.703079 137.578074 \nL 282.1343 136.9929 \nL 285.565521 135.841469 \nL 288.996743 134.852483 \nL 292.427964 134.98756 \nL 295.859185 137.235902 \nL 299.290407 142.366976 \nL 302.721628 150.696001 \nL 306.152849 161.918497 \nL 309.584071 175.059308 \nL 313.015292 188.560275 \nL 316.446513 200.502999 \nL 319.877734 208.934432 \nL 323.308956 212.239193 \nL 326.740177 209.488635 \nL 330.171398 200.696067 \nL 333.60262 186.920893 \nL 337.033841 170.189791 \nL 340.465062 153.235986 \nL 343.896284 139.092077 \nL 347.327505 130.60122 \nL 350.758726 129.929926 \nL 354.189947 138.16935 \nL 357.621169 155.099616 \nL 361.05239 179.165097 \nL 364.483611 207.672361 \nL 367.914833 237.183008 \nL 371.346054 264.038179 \nL 374.777275 284.926775 \nL 378.208497 297.400072 \nL 381.639718 300.24358 \nL 385.070939 293.641348 \nL 388.502161 279.104357 \nL 391.933382 259.176494 \nL 395.364603 236.971426 \nL 398.795824 215.623954 \nL 402.227046 197.754727 \nL 405.658267 185.044349 \n\" clip-path=\"url(#p0ce1c339e6)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 65.967358 121.070031 \nL 69.398579 137.739285 \nL 72.829801 160.114273 \nL 76.261022 185.507031 \nL 79.692243 210.769334 \nL 83.123464 232.849969 \nL 86.554686 249.309928 \nL 89.985907 258.699719 \nL 93.417128 260.732945 \nL 96.84835 256.232162 \nL 100.279571 246.868485 \nL 103.710792 234.756387 \nL 107.142014 221.991871 \nL 110.573235 210.230696 \nL 114.004456 200.392174 \nL 117.435678 192.54583 \nL 120.866899 185.998786 \nL 124.29812 179.559224 \nL 127.729341 171.914347 \nL 131.160563 162.037261 \nL 134.591784 149.531136 \nL 138.023005 134.831966 \nL 141.454227 119.220659 \nL 144.885448 104.635193 \nL 148.316669 93.315934 \nL 151.747891 87.353468 \nL 155.179112 88.230898 \nL 158.610333 96.456712 \nL 162.041554 111.368967 \nL 165.472776 131.159325 \nL 168.903997 153.122659 \nL 172.335218 174.092796 \nL 175.76644 190.986557 \nL 179.197661 201.354233 \nL 182.628882 203.830206 \nL 186.060104 198.393779 \nL 189.491325 186.384683 \nL 192.922546 170.263867 \nL 196.353768 153.159232 \nL 199.784989 138.278437 \nL 203.21621 128.298478 \nL 206.647431 124.848663 \nL 210.078653 128.188162 \nL 213.509874 137.144072 \nL 216.941095 149.32723 \nL 220.372317 161.589964 \nL 223.803538 170.6427 \nL 227.234759 173.714023 \nL 230.665981 169.127818 \nL 234.097202 156.684109 \nL 237.528423 137.765091 \nL 240.959644 115.138345 \nL 244.390866 92.486218 \nL 247.822087 73.742957 \nL 251.253308 62.359553 \nL 254.68453 60.63284 \nL 258.115751 69.226631 \nL 261.546972 86.979873 \nL 264.978194 111.045582 \nL 268.409415 137.343998 \nL 271.840636 161.255002 \nL 275.271857 178.429293 \nL 278.703079 185.57363 \nL 282.1343 181.067496 \nL 285.565521 165.296663 \nL 288.996743 140.638556 \nL 292.427964 111.096131 \nL 295.859185 81.640108 \nL 299.290407 57.372216 \nL 302.721628 42.655074 \nL 306.152849 40.361251 \nL 309.584071 51.37359 \nL 313.015292 74.424741 \nL 316.446513 106.303874 \nL 319.877734 142.393687 \nL 323.308956 177.442681 \nL 326.740177 206.436856 \nL 330.171398 225.418574 \nL 333.60262 232.111362 \nL 337.033841 226.245455 \nL 340.465062 209.533372 \nL 343.896284 185.307615 \nL 347.327505 157.89225 \nL 350.758726 131.825981 \nL 354.189947 111.07814 \nL 357.621169 98.396889 \nL 361.05239 94.901665 \nL 364.483611 99.984873 \nL 367.914833 111.530043 \nL 371.346054 126.395886 \nL 374.777275 141.068524 \nL 378.208497 152.356089 \nL 381.639718 157.995669 \nL 385.070939 157.062497 \nL 388.502161 150.111109 \nL 391.933382 139.030054 \nL 395.364603 126.645754 \nL 398.795824 116.157057 \nL 402.227046 110.511518 \nL 405.658267 111.842324 \n\" clip-path=\"url(#p0ce1c339e6)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 48.982813 313.478125 \nL 48.982813 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 422.642813 313.478125 \nL 422.642813 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 48.982813 313.478125 \nL 422.642812 313.478125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 48.982813 22.318125 \nL 422.642812 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- f(~g @ h) -->\n    <g transform=\"translate(206.565625 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-7e\" d=\"M 4684 2553 \nL 4684 1997 \nQ 4356 1750 4076 1644 \nQ 3797 1538 3494 1538 \nQ 3150 1538 2694 1722 \nQ 2659 1734 2644 1741 \nQ 2622 1750 2575 1766 \nQ 2091 1959 1797 1959 \nQ 1522 1959 1253 1839 \nQ 984 1719 678 1459 \nL 678 2016 \nQ 1006 2263 1286 2370 \nQ 1566 2478 1869 2478 \nQ 2213 2478 2672 2291 \nQ 2703 2278 2719 2272 \nQ 2744 2263 2788 2247 \nQ 3272 2053 3566 2053 \nQ 3834 2053 4098 2172 \nQ 4363 2291 4684 2553 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-40\" d=\"M 2381 1678 \nQ 2381 1231 2603 976 \nQ 2825 722 3213 722 \nQ 3597 722 3817 978 \nQ 4038 1234 4038 1678 \nQ 4038 2116 3813 2373 \nQ 3588 2631 3206 2631 \nQ 2828 2631 2604 2375 \nQ 2381 2119 2381 1678 \nz\nM 4084 744 \nQ 3897 503 3655 389 \nQ 3413 275 3091 275 \nQ 2553 275 2217 664 \nQ 1881 1053 1881 1678 \nQ 1881 2303 2218 2693 \nQ 2556 3084 3091 3084 \nQ 3413 3084 3656 2967 \nQ 3900 2850 4084 2613 \nL 4084 3022 \nL 4531 3022 \nL 4531 722 \nQ 4988 791 5245 1139 \nQ 5503 1488 5503 2041 \nQ 5503 2375 5404 2669 \nQ 5306 2963 5106 3213 \nQ 4781 3622 4314 3839 \nQ 3847 4056 3297 4056 \nQ 2913 4056 2559 3954 \nQ 2206 3853 1906 3653 \nQ 1416 3334 1139 2817 \nQ 863 2300 863 1697 \nQ 863 1200 1042 765 \nQ 1222 331 1563 0 \nQ 1891 -325 2322 -495 \nQ 2753 -666 3244 -666 \nQ 3647 -666 4036 -530 \nQ 4425 -394 4750 -141 \nL 5031 -488 \nQ 4641 -791 4180 -952 \nQ 3719 -1113 3244 -1113 \nQ 2666 -1113 2153 -908 \nQ 1641 -703 1241 -313 \nQ 841 78 631 592 \nQ 422 1106 422 1697 \nQ 422 2266 634 2781 \nQ 847 3297 1241 3688 \nQ 1644 4084 2172 4295 \nQ 2700 4506 3291 4506 \nQ 3953 4506 4520 4234 \nQ 5088 3963 5472 3463 \nQ 5706 3156 5829 2797 \nQ 5953 2438 5953 2053 \nQ 5953 1231 5456 756 \nQ 4959 281 4084 263 \nL 4084 744 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-66\"/>\n     <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(35.205078 0)\"/>\n     <use xlink:href=\"#DejaVuSans-7e\" transform=\"translate(74.21875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(158.007812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(221.484375 0)\"/>\n     <use xlink:href=\"#DejaVuSans-40\" transform=\"translate(253.271484 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(353.271484 0)\"/>\n     <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(385.058594 0)\"/>\n     <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(448.4375 0)\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 55.982813 308.478125 \nL 194.279687 308.478125 \nQ 196.279687 308.478125 196.279687 306.478125 \nL 196.279687 278.121875 \nQ 196.279687 276.121875 194.279687 276.121875 \nL 55.982813 276.121875 \nQ 53.982813 276.121875 53.982813 278.121875 \nL 53.982813 306.478125 \nQ 53.982813 308.478125 55.982813 308.478125 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 57.982813 284.220312 \nL 67.982812 284.220312 \nL 77.982812 284.220312 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_17\">\n     <!-- rotations -->\n     <g transform=\"translate(85.982812 287.720312) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(100.044922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(139.253906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(200.533203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(239.742188 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(267.525391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(328.707031 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(392.085938 0)\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 57.982813 298.898438 \nL 67.982812 298.898438 \nL 77.982812 298.898438 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- reflection + rotations -->\n     <g transform=\"translate(85.982812 302.398438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2b\" d=\"M 2944 4013 \nL 2944 2272 \nL 4684 2272 \nL 4684 1741 \nL 2944 1741 \nL 2944 0 \nL 2419 0 \nL 2419 1741 \nL 678 1741 \nL 678 2272 \nL 2419 2272 \nL 2419 4013 \nL 2944 4013 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-66\" transform=\"translate(100.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(135.591797 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(163.375 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(224.898438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(279.878906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(319.087891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(346.871094 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(408.052734 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(471.431641 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2b\" transform=\"translate(503.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(587.007812 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(618.794922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(657.658203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(718.839844 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(758.048828 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(819.328125 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(858.537109 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(886.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(947.501953 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1010.880859 0)\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 475.582812 313.478125 \nL 849.242812 313.478125 \nL 849.242812 22.318125 \nL 475.582812 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"492.567358\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 0 -->\n      <g transform=\"translate(489.386108 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_19\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"547.176941\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 1 -->\n      <g transform=\"translate(543.995691 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"601.786524\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 2 -->\n      <g transform=\"translate(598.605274 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_21\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"656.396107\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 3 -->\n      <g transform=\"translate(653.214857 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"711.005691\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 4 -->\n      <g transform=\"translate(707.824441 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_23\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"765.615274\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 5 -->\n      <g transform=\"translate(762.434024 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#m28ecbd9866\" x=\"820.224857\" y=\"313.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 6 -->\n      <g transform=\"translate(817.043607 328.076563) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_26\">\n     <!-- theta [0, 2pi) -->\n     <g transform=\"translate(629.588594 341.754687) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(39.208984 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(102.587891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(164.111328 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(203.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(264.599609 0)\"/>\n      <use xlink:href=\"#DejaVuSans-5b\" transform=\"translate(296.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(335.400391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(399.023438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(430.810547 0)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(462.597656 0)\"/>\n      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(526.220703 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(589.697266 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(617.480469 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"475.582812\" y=\"287.072109\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- −15 -->\n      <g transform=\"translate(447.478125 290.871328) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(147.412109 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"475.582812\" y=\"237.05151\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_28\">\n      <!-- −10 -->\n      <g transform=\"translate(447.478125 240.850729) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(83.789062 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(147.412109 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_27\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"475.582812\" y=\"187.030911\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- −5 -->\n      <g transform=\"translate(453.840625 190.83013) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(83.789062 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"475.582812\" y=\"137.010313\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_30\">\n      <!-- 0 -->\n      <g transform=\"translate(462.220312 140.809531) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_29\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"475.582812\" y=\"86.989714\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- 5 -->\n      <g transform=\"translate(462.220312 90.788932) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m4ebf752626\" x=\"475.582812\" y=\"36.969115\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_32\">\n      <!-- 10 -->\n      <g transform=\"translate(455.857812 40.768334) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_33\">\n     <!-- f(g) -->\n     <g transform=\"translate(441.398438 176.734063) rotate(-90) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(35.205078 0)\"/>\n      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(74.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(137.695312 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 492.567358 177.992597 \nL 495.998579 175.904097 \nL 499.429801 177.099832 \nL 502.861022 179.311888 \nL 506.292243 180.184774 \nL 509.723464 177.786719 \nL 513.154686 171.032437 \nL 516.585907 159.935316 \nL 520.017128 145.638964 \nL 523.44835 130.219535 \nL 526.879571 116.293734 \nL 530.310792 106.504686 \nL 533.742014 102.98199 \nL 537.173235 106.878687 \nL 540.604456 118.075231 \nL 544.035678 135.111003 \nL 547.466899 155.362811 \nL 550.89812 175.444631 \nL 554.329341 191.761841 \nL 557.760563 201.123897 \nL 561.191784 201.307261 \nL 564.623005 191.46769 \nL 568.054227 172.326533 \nL 571.485448 146.094871 \nL 574.916669 116.145195 \nL 578.347891 86.484589 \nL 581.779112 61.11814 \nL 585.210333 43.41039 \nL 588.641554 35.55267 \nL 592.072776 38.225359 \nL 595.503997 50.509827 \nL 598.935218 70.061456 \nL 602.36644 93.510352 \nL 605.797661 117.018152 \nL 609.228882 136.894407 \nL 612.660104 150.168325 \nL 616.091325 155.022448 \nL 619.522546 151.02143 \nL 622.953768 139.106608 \nL 626.384989 121.36832 \nL 629.81621 100.645566 \nL 633.247431 80.029945 \nL 636.678653 62.363396 \nL 640.109874 49.815325 \nL 643.541095 43.605687 \nL 646.972317 43.910604 \nL 650.403538 49.952119 \nL 653.834759 60.240424 \nL 657.265981 72.911473 \nL 660.697202 86.089665 \nL 664.128423 98.206197 \nL 667.559644 108.217796 \nL 670.990866 115.694488 \nL 674.422087 120.773644 \nL 677.853308 124.004838 \nL 681.28453 126.130713 \nL 684.715751 127.859068 \nL 688.146972 129.679265 \nL 691.578194 131.762579 \nL 695.009415 133.964642 \nL 698.440636 135.9233 \nL 701.871857 137.222613 \nL 705.303079 137.578074 \nL 708.7343 136.9929 \nL 712.165521 135.841469 \nL 715.596743 134.852483 \nL 719.027964 134.98756 \nL 722.459185 137.235902 \nL 725.890407 142.366976 \nL 729.321628 150.696001 \nL 732.752849 161.918497 \nL 736.184071 175.059308 \nL 739.615292 188.560275 \nL 743.046513 200.502999 \nL 746.477734 208.934432 \nL 749.908956 212.239193 \nL 753.340177 209.488635 \nL 756.771398 200.696067 \nL 760.20262 186.920893 \nL 763.633841 170.189791 \nL 767.065062 153.235986 \nL 770.496284 139.092077 \nL 773.927505 130.60122 \nL 777.358726 129.929926 \nL 780.789947 138.16935 \nL 784.221169 155.099616 \nL 787.65239 179.165097 \nL 791.083611 207.672361 \nL 794.514833 237.183008 \nL 797.946054 264.038179 \nL 801.377275 284.926775 \nL 804.808497 297.400072 \nL 808.239718 300.24358 \nL 811.670939 293.641348 \nL 815.102161 279.104357 \nL 818.533382 259.176494 \nL 821.964603 236.971426 \nL 825.395824 215.623954 \nL 828.827046 197.754727 \nL 832.258267 185.044349 \n\" clip-path=\"url(#p61c93b2ca3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 492.567358 121.070031 \nL 495.998579 137.739285 \nL 499.429801 160.114273 \nL 502.861022 185.507031 \nL 506.292243 210.769334 \nL 509.723464 232.849969 \nL 513.154686 249.309928 \nL 516.585907 258.699719 \nL 520.017128 260.732945 \nL 523.44835 256.232162 \nL 526.879571 246.868485 \nL 530.310792 234.756387 \nL 533.742014 221.991871 \nL 537.173235 210.230696 \nL 540.604456 200.392174 \nL 544.035678 192.54583 \nL 547.466899 185.998786 \nL 550.89812 179.559224 \nL 554.329341 171.914347 \nL 557.760563 162.037261 \nL 561.191784 149.531136 \nL 564.623005 134.831966 \nL 568.054227 119.220659 \nL 571.485448 104.635193 \nL 574.916669 93.315934 \nL 578.347891 87.353468 \nL 581.779112 88.230898 \nL 585.210333 96.456712 \nL 588.641554 111.368967 \nL 592.072776 131.159325 \nL 595.503997 153.122659 \nL 598.935218 174.092796 \nL 602.36644 190.986557 \nL 605.797661 201.354233 \nL 609.228882 203.830206 \nL 612.660104 198.393779 \nL 616.091325 186.384683 \nL 619.522546 170.263867 \nL 622.953768 153.159232 \nL 626.384989 138.278437 \nL 629.81621 128.298478 \nL 633.247431 124.848663 \nL 636.678653 128.188162 \nL 640.109874 137.144072 \nL 643.541095 149.32723 \nL 646.972317 161.589964 \nL 650.403538 170.6427 \nL 653.834759 173.714023 \nL 657.265981 169.127818 \nL 660.697202 156.684109 \nL 664.128423 137.765091 \nL 667.559644 115.138345 \nL 670.990866 92.486218 \nL 674.422087 73.742957 \nL 677.853308 62.359553 \nL 681.28453 60.63284 \nL 684.715751 69.226631 \nL 688.146972 86.979873 \nL 691.578194 111.045582 \nL 695.009415 137.343998 \nL 698.440636 161.255002 \nL 701.871857 178.429293 \nL 705.303079 185.57363 \nL 708.7343 181.067496 \nL 712.165521 165.296663 \nL 715.596743 140.638556 \nL 719.027964 111.096131 \nL 722.459185 81.640108 \nL 725.890407 57.372216 \nL 729.321628 42.655074 \nL 732.752849 40.361251 \nL 736.184071 51.37359 \nL 739.615292 74.424741 \nL 743.046513 106.303874 \nL 746.477734 142.393687 \nL 749.908956 177.442681 \nL 753.340177 206.436856 \nL 756.771398 225.418574 \nL 760.20262 232.111362 \nL 763.633841 226.245455 \nL 767.065062 209.533372 \nL 770.496284 185.307615 \nL 773.927505 157.89225 \nL 777.358726 131.825981 \nL 780.789947 111.07814 \nL 784.221169 98.396889 \nL 787.65239 94.901665 \nL 791.083611 99.984873 \nL 794.514833 111.530043 \nL 797.946054 126.395886 \nL 801.377275 141.068524 \nL 804.808497 152.356089 \nL 808.239718 157.995669 \nL 811.670939 157.062497 \nL 815.102161 150.111109 \nL 818.533382 139.030054 \nL 821.964603 126.645754 \nL 825.395824 116.157057 \nL 828.827046 110.511518 \nL 832.258267 111.842324 \n\" clip-path=\"url(#p61c93b2ca3)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 475.582812 313.478125 \nL 475.582812 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 849.242812 313.478125 \nL 849.242812 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 475.582812 313.478125 \nL 849.242812 313.478125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 475.582812 22.318125 \nL 849.242812 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_34\">\n    <!-- rho(g) @ f^ -->\n    <g transform=\"translate(627.132812 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-5e\" d=\"M 2988 4666 \nL 4684 2925 \nL 4056 2925 \nL 2681 4159 \nL 1306 2925 \nL 678 2925 \nL 2375 4666 \nL 2988 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-72\"/>\n     <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(39.363281 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(102.742188 0)\"/>\n     <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(163.923828 0)\"/>\n     <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(202.9375 0)\"/>\n     <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(266.414062 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(305.427734 0)\"/>\n     <use xlink:href=\"#DejaVuSans-40\" transform=\"translate(337.214844 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(437.214844 0)\"/>\n     <use xlink:href=\"#DejaVuSans-66\" transform=\"translate(469.001953 0)\"/>\n     <use xlink:href=\"#DejaVuSans-5e\" transform=\"translate(504.207031 0)\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 482.582812 308.478125 \nL 620.879688 308.478125 \nQ 622.879688 308.478125 622.879688 306.478125 \nL 622.879688 278.121875 \nQ 622.879688 276.121875 620.879688 276.121875 \nL 482.582812 276.121875 \nQ 480.582812 276.121875 480.582812 278.121875 \nL 480.582812 306.478125 \nQ 480.582812 308.478125 482.582812 308.478125 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 484.582812 284.220312 \nL 494.582812 284.220312 \nL 504.582812 284.220312 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_35\">\n     <!-- rotations -->\n     <g transform=\"translate(512.582813 287.720312) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(100.044922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(139.253906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(200.533203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(239.742188 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(267.525391 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(328.707031 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(392.085938 0)\"/>\n     </g>\n    </g>\n    <g id=\"line2d_34\">\n     <path d=\"M 484.582812 298.898438 \nL 494.582812 298.898438 \nL 504.582812 298.898438 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_36\">\n     <!-- reflection + rotations -->\n     <g transform=\"translate(512.582813 302.398438) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(38.863281 0)\"/>\n      <use xlink:href=\"#DejaVuSans-66\" transform=\"translate(100.386719 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(135.591797 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(163.375 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(224.898438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(279.878906 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(319.087891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(346.871094 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(408.052734 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(471.431641 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2b\" transform=\"translate(503.21875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(587.007812 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(618.794922 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(657.658203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(718.839844 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(758.048828 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(819.328125 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(858.537109 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(886.320312 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(947.501953 0)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1010.880859 0)\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0ce1c339e6\">\n   <rect x=\"48.982813\" y=\"22.318125\" width=\"373.66\" height=\"291.16\"/>\n  </clipPath>\n  <clipPath id=\"p61c93b2ca3\">\n   <rect x=\"475.582812\" y=\"22.318125\" width=\"373.66\" height=\"291.16\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "irreps = [G.irrep(0, 0)] + [G.irrep(1, j) for j in range(8)]\n",
        "\n",
        "# first, we generate a random function, as earlier\n",
        "ft = {\n",
        "    rho.id: np.random.randn(rho.size, rho.size)\n",
        "    for rho in irreps\n",
        "}\n",
        "\n",
        "# second, we sample a random group element `g`\n",
        "g = G.sample()\n",
        "print(f'Transforming the function with g={g}')\n",
        "\n",
        "# finally, we transform the Fourier coefficients as in the equations above:\n",
        "gft = {\n",
        "    rho.id: rho(g) @ ft[rho.id]\n",
        "    for rho in irreps\n",
        "}\n",
        "\n",
        "# Let's now visualize the two functions:\n",
        "\n",
        "f_rot = [\n",
        "    inverse_fourier_transform_O2((~g)@h, ft) for h in grid_rot     # passing in shifted groups\n",
        "]\n",
        "f_refl = [\n",
        "    inverse_fourier_transform_O2((~g)@h, ft) for h in grid_refl    # passing in shifted groups\n",
        "]\n",
        "\n",
        "gf_rot = [\n",
        "    inverse_fourier_transform_O2(h, gft) for h in grid_rot\n",
        "]\n",
        "gf_refl = [\n",
        "    inverse_fourier_transform_O2(h, gft) for h in grid_refl\n",
        "]\n",
        "\n",
        "# Create a figure with two subplots in the same row\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# First plot: f\n",
        "axs[0].plot(thetas, f_rot, label='rotations')\n",
        "axs[0].plot(thetas, f_refl, label='reflection + rotations')\n",
        "axs[0].set_xlabel('theta [0, 2pi)')\n",
        "axs[0].set_ylabel('f(g)')\n",
        "axs[0].set_title('f(~g @ h)')\n",
        "axs[0].legend()\n",
        "\n",
        "# Second plot: g.f\n",
        "axs[1].plot(thetas, gf_rot, label='rotations')\n",
        "axs[1].plot(thetas, gf_refl, label='reflection + rotations')\n",
        "axs[1].set_xlabel('theta [0, 2pi)')\n",
        "axs[1].set_ylabel('f(g)')\n",
        "axs[1].set_title('rho(g) @ f^')\n",
        "axs[1].legend()\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEtyoU54cQLs"
      },
      "source": [
        "#### From the Fourier Transform to the Regular Representation\n",
        "\n",
        "For simplicity, we can stack all the Fourier coefficients (the output of the Fourier transform, that is, the input of the inverse Fourier transform) into a unique vector.\n",
        "We define the vector $\\mathbf{f}$ as the stack of the columns of each Fourier coefficients matrix $f(\\rho_j)$.\n",
        "\n",
        "Let's first introduce some notation.\n",
        "We denote the stack of two vectors $\\mathbf{v_1}, \\mathbf{v_2}$ as $\\mathbf{v_1} \\oplus \\mathbf{v_2}$.\n",
        "The use of $\\oplus$ is not random: if $\\rho_1$ is a representation acting on $\\mathbf{v_1}$ and $\\rho_2$ is a representation acting on $\\mathbf{v_2}$, then the *direct sum* $\\rho_1 \\oplus \\rho_2$ acts on the concatenated vector $\\mathbf{v_1} \\oplus \\mathbf{v_2}$.\n",
        "\n",
        "Second, we denote by $\\text{vec}(A)$ the vector which is the stack of the columns of a matrix $A$.\n",
        "In `numpy`, this is written as `A.T.reshape(-1)`, where the transpose is necessary since `numpy` stacks rows by default.\n",
        "\n",
        "Then, we write:\n",
        "$$ \\mathbf{f} = \\bigoplus_{\\rho_j} \\text{vec}(\\hat{f}(\\rho_j)) \\ .$$\n",
        "\n",
        "Moreover, by using $\\widehat{g.f}(\\rho_j) = \\rho_j(g) \\hat{f}(\\rho_j)$, we see that the vector containing the coefficients of the function $[g.f]$ will be:\n",
        "$$\n",
        "\\bigoplus_{\\rho_j} \\text{vec}(\\rho_j(g) \\hat{f}(\\rho_j)) =\n",
        "\\bigoplus_{\\rho_j} \\left(\\bigoplus^{d_j} \\rho_j(g)\\right) \\text{vec}(\\hat{f}(\\rho_j))\n",
        "$$\n",
        "\n",
        "In other words, the group $G$ is acting on the vector $\\mathbf{f}$ with the following representation:\n",
        "$$\n",
        "\\rho(g) = \\bigoplus_{\\rho_j} \\bigoplus^{d_j} \\rho_j(g)\n",
        "$$\n",
        "\n",
        "i.e. $\\rho(g) \\mathbf{f}$ is the vector containing the Fourier coefficients of the function $[g.f]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soETTVlMcQLs"
      },
      "source": [
        "Note that, essentially, the representation $\\rho$ acts on a vector space containing functions over $G$.\n",
        "This should remind you of the **regular representation** we defined for *finite groups* earlier.\n",
        "Indeed, it turns out that, if $G$ is finite, the representation $\\rho$ we have just constructed is **isomorphic** (*equivalent*) to the *regular representation* defined earlier.\n",
        "The change of basis $Q$ is a matrix which performs the Fourier transform, while $Q^{-1}$ performs the inverse Fourier transform.\n",
        "More formally:\n",
        "$$ \\rho_\\text{reg}(g) = Q^{-1} \\left(\\bigoplus_{\\rho_j} \\bigoplus^{d_j} \\rho_j(g) \\right) Q $$\n",
        "\n",
        "where each irrep $\\rho_j$ is repeated $d_j$ times, i.e. a number of times equal to its size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDqHvssGptvW"
      },
      "source": [
        "**Intuition**: recall that a function $f : G \\to \\mathbb{R}$ is just a vector living in a vector space. Such vector can be expressed with respect to any basis for this vector space. The first time we introduced the *regular representation* for finite groups, we chose a basis where each axis is associated with a group element; the action of $G$ is realized in this basis by a permutation of all the axes. Here, instead, we defined a basis for the same vector space where $G$ acts indipendently on different subsets of the axes, i.e. the action of $G$ is a block-diagonal matrix (the direct sum of irreps). This is often a more convenient choice of basis as we will see later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvgKeBEZcQLs"
      },
      "source": [
        "Let verify this equivalence for the Dihdral group $D_8$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdlvVFUJcQLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1758f41-1ae7-4d1f-a6c2-04cc17661b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The representations have the same size:\n",
            "16 16\n",
            "And contain the same irreps:\n",
            "[(0, 0), (1, 0), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (0, 4)]\n",
            "[(0, 0), (1, 0), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (0, 4)]\n",
            "\n",
            "Are the two representations equivalent? True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "G = dihedral_group(8)\n",
        "\n",
        "rho_irreps = []\n",
        "for rho_j in G.irreps():\n",
        "    d_j = rho_j.size\n",
        "    # repeat each irrep a number of times equal to its size\n",
        "    rho_irreps += [rho_j]*d_j\n",
        "\n",
        "rho = directsum(rho_irreps)\n",
        "\n",
        "print('The representations have the same size:')\n",
        "print(rho.size, G.regular_representation.size)\n",
        "\n",
        "print('And contain the same irreps:')\n",
        "print(rho.irreps)\n",
        "print(G.regular_representation.irreps)\n",
        "\n",
        "# Fourier transform matrix:\n",
        "Q = G.regular_representation.change_of_basis\n",
        "# inverse Fourier transform matrix:\n",
        "Qinv = G.regular_representation.change_of_basis_inv\n",
        "\n",
        "# let's check that the two representations are indeed equivalent\n",
        "g = G.sample()\n",
        "\n",
        "rho_g = rho(g)\n",
        "reg_g = G.regular_representation(g)\n",
        "print()\n",
        "print('Are the two representations equivalent?', np.allclose(Q @ rho_g @ Qinv, reg_g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWja59scQLs"
      },
      "source": [
        "When $G$ is not finite, we can not explicitly store the regular representation $\\rho_\\text{reg}$ or the Fourier transform matrix $Q$, since they are infinite dimensional.\n",
        "Nevertheless, as we have done earlier, we can just consider a subset of all functions, spanned only by a finite number of irreps.\n",
        "We can sample the function on any group element via the Inverse Fourier Transform when needed, without the need to compute the full Inverse Fourier Transform $Q^{-1}$ to store all values.\n",
        "\n",
        "This is the underlying idea we will exploit later to build GCNNs equivariant to infinite groups.\n",
        "\n",
        "---\n",
        "\n",
        "### Why does \\( O(2) \\) have infinitely many irreps?\n",
        " - **Irreps of \\( SO(2) \\):**\n",
        "   - The subgroup \\( SO(2) \\) (rotations) is isomorphic to the circle group \\( U(1) \\), which has irreps labeled by integers \\( n \\in \\mathbb{Z} \\), corresponding to the Fourier modes \\( e^{in\\theta} \\).\n",
        "   - Thus, \\( SO(2) \\) has infinitely many irreps.\n",
        "\n",
        " - **Adding Reflections:**\n",
        "   - Reflections in \\( O(2) \\) add complexity. Each irrep of \\( SO(2) \\) splits into two irreps of \\( O(2) \\), depending on how reflections act (symmetric or antisymmetric under reflection).\n",
        "   - This doubling of irreps still leads to an infinite set of irreps for \\( O(2) \\).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuA63jcqcQLt"
      },
      "source": [
        "We can easily generate this representation as (`bl_regular_representation` stands for \"band-limited\", since only a limited subset of irreps, i.e. frequencies, is used):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "jK5l0p-ocQLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee20cf4-d3af-40e1-ef20-f5c431648f33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0),\n",
              " (1, 0),\n",
              " (1, 1),\n",
              " (1, 1),\n",
              " (1, 2),\n",
              " (1, 2),\n",
              " (1, 3),\n",
              " (1, 3),\n",
              " (1, 4),\n",
              " (1, 4),\n",
              " (1, 5),\n",
              " (1, 5),\n",
              " (1, 6),\n",
              " (1, 6),\n",
              " (1, 7),\n",
              " (1, 7)]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "G = o2_group()\n",
        "\n",
        "rho = G.bl_regular_representation(7)\n",
        "\n",
        "rho.irreps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ciIlTnmcQLt"
      },
      "source": [
        "#### Irreps with redundant entries: the case of $SO(2)$\n",
        "We need to conclude with a final note about the Fourier transform.\n",
        "When we introduced it earlier, we said that the entries of the irreps form a **basis** for the functions over *most* groups.\n",
        "Indeed, there exists some groups where the entries of the irreps are partially redundant and, therefore, form an *overcomplete* basis.\n",
        "This is the case, for example, of the group of planar rotations $SO(2)$ (or the group of $N$ discrete rotations $C_N$).\n",
        "Indeed, an irrep of $SO(2)$ has form:\n",
        "\n",
        "$$\n",
        "\\rho_j(r_\\theta) = \\begin{bmatrix}\n",
        "    \\cos(j \\cdot \\theta) & -\\sin(j \\cdot \\theta) \\\\\n",
        "    \\sin(j \\cdot \\theta) & \\cos(j \\cdot \\theta) \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "for $\\theta \\in [0, 2\\pi)$, where the integer $j \\in \\mathbb{N}$ is interpreted as the rotational *frequency*.\n",
        "\n",
        "You can observe that the two columns of $\\rho_j(r_\\theta)$ contain redundant elements and span the same $2$ dimensional space of functions.\n",
        "It is indeed sufficient to consider only one of the two columns to parameterize functions over $SO(2)$.\n",
        "This also means that the irrep $\\rho_j$ appears only once (instead of $d_j=2$ times) in the regular representation.\n",
        "\n",
        "We don't generally need to worry much about this, since we can generate the representation as earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "s4Xh-rTMcQLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20a9719-7dc4-4ed1-e4ff-bd74fd62af04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "G = so2_group()\n",
        "\n",
        "rho = G.bl_regular_representation(7)\n",
        "\n",
        "\n",
        "# observe that each irrep is now repeated only once, even if some are 2-dimensional\n",
        "rho.irreps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfsEg4U8cQLt"
      },
      "source": [
        "## 2. From Group CNNs to Steerable CNNs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrCqjd6fcQLt"
      },
      "source": [
        "We consider a GCNN equivariant to a *semi-direct* product group $\\mathbb{R}^n \\rtimes G$, with compact group $G \\leq O(n)$.\n",
        "This setting covers equivariance to **isometries** (distance preserving transformations) of the Euclidean space $\\mathbb{R}^n$; in particular, it includes equivariance to *translations* in $\\mathbb{R}^n$ and to a origin-preserving symmetry $G$ (e.g. rotations or reflections in $n$-dimensions).\n",
        "We call $G$ a **point group**.\n",
        "\n",
        "If $G=O(n)$, the group of all rotations and reflections in $\\mathbb{R}^n$, then $E(n) = \\mathbb{R}^n \\rtimes O(n)$ is called the **Euclidean group**, and includes all isometries of $\\mathbb{R}^n$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8W8MoctMjn_"
      },
      "source": [
        "### 2.1 Feature Fields\n",
        "In a GCNN, a feature map is a signal $f: \\mathbb{R}^n \\times G \\to \\mathbb{R}$.\n",
        "The action of an element $(x, g) \\in \\mathbb{R}^n \\rtimes G$ is:\n",
        "\n",
        "$$ [(x, g).f](y,h):= f(g^{-1}(y-x), g^{-1}h) $$\n",
        "\n",
        "where $x, y \\in \\mathbb{R}^n$ and $g, h \\in G$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0-9VSbwcQLu"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 7\n",
        "Prove the action has indeed this form.\n",
        "\n",
        "#### ANSWER 7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTJxbzY4cQLu"
      },
      "source": [
        "In a GCNN, a feature map $f$ is stored as a multi-dimensional array with an axis for each of the $n$ spatial dimensions and one for the group $G$.\n",
        "\n",
        "In a steerable CNN, we replace the $G$ axis with a \"Fourier\" axis, which contains $c$ Fourier coefficients used to parameterize a function over $G$, as described in the previous section.\n",
        "Again, let's call $\\rho: G \\to \\mathbb{R}^{c \\times c}$ the representation of $G$ acting on these $c$ coefficients.\n",
        "The result is equivalent to a standard GCNN if $G$ is finite (and we have $c = |G|$), but we can now also use infinite $G$, such as $SO(2)$.\n",
        "\n",
        "\n",
        "A feature map $f$ can now be interpreted as a vector field on the space $\\mathbb{R}^n$, i.e.:\n",
        "$$ f: \\mathbb{R}^n \\to \\mathbb{R}^c $$\n",
        "\n",
        "which assigns a $c$-dimensional feature vector $f(x)\\in\\mathbb{R}^c$ to each spatial position $x\\in\\mathbb{R}^n$.\n",
        "We call such vector field a **feature vector field**.\n",
        "\n",
        "The action of $\\mathbb{R}^n \\rtimes G$ on one such feature vector field is defined as:\n",
        "\n",
        "$$ [(x, g).f](y):= \\rho(g) f(g^{-1}(y-x)) $$\n",
        "\n",
        "where $x, y \\in \\mathbb{R}^n$ and $g \\in G$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7wievExcQLu"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 8\n",
        "Prove that this is indeed the right action of $\\mathbb{R}^n \\rtimes G$ on the feature vector field $f: \\mathbb{R}^n \\to \\mathbb{R}^c$.\n",
        "Recall the action of this group over the functions of the form $\\underline{f}: \\mathbb{R}^n \\rtimes G \\to \\mathbb{R}$ that we described earlier.\n",
        "Moreover, note that the vector $f(x) \\in \\mathbb{R}^c$ contains the $c$ Fourier coefficients of the function $\\underline{f}(x, \\cdot) : G \\to \\mathbb{R}$ along its $G$ axis, i.e.:\n",
        "$$\n",
        "    f(x) = \\bigoplus_{\\rho_j} \\text{vec}\\left(\\widehat{\\underline{f}(x, \\cdot)}(\\rho_j)\\right)\n",
        "$$\n",
        "\n",
        "#### ANSWER 8:\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX2IVGuTcQLu"
      },
      "source": [
        "### General Steerable CNNs\n",
        "The framework of Steerable CNNs is actually more general and allows for any representation $\\rho$ of $G$.\n",
        "A different choice of $\\rho$ generally require some structural change in the architecture, e.g. by adapting the non-linearity used to ensure equivariance.\n",
        "Anyways, for simplicity, we will stick with the Fourier example in this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn9ztlcjcQLu"
      },
      "source": [
        "Throughout the rest of this tutorial, we will assume $n=2$ for simplicity.\n",
        "That means we will be working for example with planar images and with the isometries of the plane (2D rotations or mirroring).\n",
        "The actions of $g \\in G=SO(2)$ on two examples of feature vector fields over $\\mathbb{R}^2$ are shown next.\n",
        "On the left, $\\rho$ is the trivial representation of $SO(2)$ while, on the right, $\\rho$ is the representation of $SO(2)$ as $2\\times 2$ rotation matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npYYVFKNcQLu"
      },
      "source": [
        "![feature field examples](https://github.com/QUVA-Lab/e2cnn/raw/master/visualizations/feature_fields.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBCJq30ycQLu"
      },
      "source": [
        "### 2.2 Defining a Steerable CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHD8hI5fcQLv"
      },
      "source": [
        "We can now proceed with building a Steerable CNN.\n",
        "First we import some other useful packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "E9TilpbScQLv"
      },
      "outputs": [],
      "source": [
        "from escnn import group\n",
        "from escnn import gspaces\n",
        "from escnn import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPhRRlFDM0wm"
      },
      "source": [
        "First, we need to choose the group $G$ of point symmetries (reflections and rotations) which are being considered.\n",
        "All of these choices are subgroups $G\\leq O(2)$ of the orthogonal group.\n",
        "\n",
        "For simplicity, we first consider the *finite* group $G=C_4$, which models the $4$ *rotations* by angle $\\theta \\in \\big\\{0, \\frac{\\pi}{2}, \\pi, \\frac{3\\pi}{2}\\big\\}$.\n",
        "Because these are perfect symmetries of the grid, transforming an image with this group does not require any interpolation.\n",
        "We will later extend our examples to an infinite group such as $SO(2)$ or $O(2)$.\n",
        "\n",
        "Recall that a semi-direct product $\\mathbb{R}^2 \\rtimes G$ is defined by $G$ but also by the action of $G$ on $\\mathbb{R}^2$.\n",
        "We determine both the **point group** $G$ and its **action on the space** $\\mathbb{R}^2$  by instantiating a subclass of `gspace.GSpace`.\n",
        "For the rotational action of $G=C_4$ on $\\mathbb{R}^2$ this is done by:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "GtrK5XjccQLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83f18c6-081d-4ea3-aacd-351a2fac0d71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C4_on_R2[(None, 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "r2_act = gspaces.rot2dOnR2(N=4)\n",
        "r2_act"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "QS4UPsa3RfBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf4bb2d-5935-4173-a490-290dd0fae6e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C4"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# we can access the group G as\n",
        "G = r2_act.fibergroup\n",
        "G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpQ3HO_tcQLv"
      },
      "source": [
        "Having specified the symmetry transformation on the *base space* $\\mathbb{R}^2$, we next need to define the representation $\\rho: G \\to \\mathbb{R}^{c \\times c}$ which describes how a **feature vector field** $f : \\mathbb{R}^2 \\to \\mathbb{R}^c$ transforms under the action of $G$.\n",
        "This transformation law of feature fields is implemented by  ``nn.FieldType``.\n",
        "\n",
        "We instantiate the `nn.FieldType` modeling a GCNN feature by passing it the `gspaces.GSpace` instance and the *regular representation* of $G=C_4$.\n",
        "We call a feature field associated with the regular representation $\\rho_\\text{reg}$ a **regular feature field**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "1HcUHvbHRS1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414cdc6b-51a7-43b0-c198-188b9e465565"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[C4_on_R2[(None, 4)]: {regular (x1)}(4)]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "feat_type = nn.FieldType(r2_act, [G.regular_representation])\n",
        "feat_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7iQyWXgZxHx"
      },
      "source": [
        "Recall that the regular representation of a finite group $G$ built by `G.regular_representation` is a permutation matrix of shape $|G| \\times |G|$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "yLHOXaPmZ9zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e87c58-6b8c-46da-8b18-f4b42818cc9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -0., -0.,  1.],\n",
              "       [ 1.,  0., -0., -0.],\n",
              "       [ 0.,  1.,  0., -0.],\n",
              "       [-0.,  0.,  1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "G.regular_representation(G.sample())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RWv1FOrQXqO"
      },
      "source": [
        "#### Deep Feature spaces\n",
        "The deep feature spaces of a GCNN typically comprise multiple channels.\n",
        "Similarly, the feature spaces of a steerable CNN can include multiple independent feature fields.\n",
        "This is achieved via **direc sum**, but stacking multiple copies of $\\rho$.\n",
        "\n",
        "For example, we can use $3$ copies of the regular representation $\\rho_\\text{reg}: G \\to \\mathbb{R}^{|G|}$.\n",
        "The full feature space is in this case modeled as a *stacked* field $f: \\mathbb{R}^2 \\to \\mathbb{R}^{3|G|}$ which transforms according to the **direct sum** of three regular representations:\n",
        "\n",
        "$$\n",
        "\\rho(r_\\theta)\n",
        "    \\ =\\ \\rho_\\text{reg}(r_\\theta) \\oplus \\rho_\\text{reg}(r_\\theta) \\oplus \\rho_\\text{reg}(r_\\theta)\n",
        "    \\ =\\ \\begin{bmatrix}\n",
        "            \\rho_\\text{reg}(\\theta) & 0 & 0 \\\\\n",
        "            0 & \\rho_\\text{reg}(\\theta) & 0 \\\\\n",
        "            0 & 0 & \\rho_\\text{reg}(\\theta) \\\\\n",
        "          \\end{bmatrix}\n",
        "          \\quad\\in\\ \\mathbb{R}^{3|G| \\times 3|G|}\n",
        "$$\n",
        "\n",
        "We instantiate a `nn.FieldType` composed of $3$ regular representations by passing the full field representation as a list of three regular representations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dc0pd9W7TVrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3580c67-a1fa-4407-b942-ff0952538d9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[C4_on_R2[(None, 4)]: {regular (x3)}(12)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Technically, one can also construct the direct-sum representation G.regular_representation + G.regular_representation + G.regular_representation as done\n",
        "# before. Passing a list containing 3 copies of G.regular_representation allows for more efficient implementation of certain operations internally.\n",
        "feat_type = nn.FieldType(r2_act, [G.regular_representation]*3)\n",
        "feat_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvxqTdJURs6C"
      },
      "source": [
        "#### Input Features\n",
        "Each hidden layer of a steerable CNN has its own transformation law which the user needs to specify (equivalent to the choice of number of channels in each layer of a conventional CNN).\n",
        "The *input* and *output* of a steerable CNN are also feature fields and their type (i.e. transformation law) is typically determined by the inference task.\n",
        "\n",
        "The most common example is that of gray-scale input images.\n",
        "A rotation of a gray-scale image is performed by moving each pixel to a new position without changing their intensity values.\n",
        "The invariance of the scalar pixel values under rotations is modeled by the **trivial representation** $\\rho_0: G\\to\\mathbb{R},\\ g\\mapsto 1$ of $G$ and identifies them as **scalar fields**.\n",
        "Formally, a scalar field is a function $f: \\mathbb{R}^2 \\to \\mathbb{R}$ mapping to a feature vector with $c=1$ channels.\n",
        "A rotation $r_\\theta \\in C_4$ transforms this scalar field as\n",
        "\n",
        "$$ \\big[r_{\\theta}\\,. f\\big](x)\n",
        "   \\ :=\\ \\rho_0(r_\\theta)\\,f\\big(r_\\theta^{-1}x\\big)\n",
        "   \\ =\\ 1\\cdot f\\big(r_\\theta^{-1}x\\big)\n",
        "   \\ =\\ f\\big(r_\\theta^{-1}x\\big) \\ .\n",
        "$$\n",
        "\n",
        "\n",
        "We instantiate the `nn.FieldType` modeling a gray-scale image by passing it the trivial representation of $G$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "NMTEZGYicQLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d47addf-53af-479d-eb7e-041120ed6dbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[C4_on_R2[(None, 4)]: {irrep_0 (x1)}(1)]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "feat_type_in = nn.FieldType(r2_act, [G.trivial_representation])\n",
        "feat_type_in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l2ascq8cQLw"
      },
      "source": [
        "#### Equivariant Layers\n",
        "\n",
        "When we build a model **equivariant** to a group $G$, we require that the output produced by the model transforms consistently when the input transforms under the action of an element $g \\in G$.\n",
        "For a function $F$ (e.g. a neural network), the **equivariance constraint** requires:\n",
        "\n",
        "$$ \\mathcal{T}^\\text{out}_g \\big[F(x)\\big]\\ =\\ F\\big(\\mathcal{T}^\\text{in}_g[x]\\big) \\quad \\forall g\\in G$$\n",
        "\n",
        "where $\\mathcal{T}^\\text{in}_g$ is the transformation of the input by the group element $g$ while $\\mathcal{T}^\\text{out}_g$ is the transformation of the output by the same element.\n",
        "The *field type* `feat_type_in` we have just defined above precisely describes $\\mathcal{T}^\\text{in}$.\n",
        "The transformation law $\\mathcal{T}^\\text{out}$ of the output of the first layer is similarly chosen by defining an instance `feat_type_out` of `nn.FieldType`.\n",
        "\n",
        "For example, let's use $3$ *regular feature fields* in output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "CKR3ape0cQLw"
      },
      "outputs": [],
      "source": [
        "feat_type_out = nn.FieldType(r2_act, [G.regular_representation]*3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhhZ6uPBa3A0"
      },
      "source": [
        "As a shortcut, we can also use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "1UzV5jQma6WR"
      },
      "outputs": [],
      "source": [
        "feat_type_in = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
        "feat_type_out = nn.FieldType(r2_act, [r2_act.regular_repr]*3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxhwT14cQMx"
      },
      "source": [
        "Once having defined how the input and output feature spaces should transform, we can build neural network functions as **equivariant modules**.\n",
        "These are implemented as subclasses of an abstract base class `nn.EquivariantModule` which itself inherits from `torch.nn.Module`.\n",
        "\n",
        "**Equivariant Convolution Layer**: We start by instantiating a convolutional layer that maps between fields of types `feat_type_in` and `feat_type_out`.\n",
        "\n",
        "Let $\\rho_\\text{in}: G \\to \\mathbb{R}^{c_\\text{in} \\times c_\\text{in}}$ and $\\rho_\\text{out}: G \\to \\mathbb{R}^{c_\\text{out} \\times c_\\text{out}}$ be respectively the representations of $G$ associated with `feat_type_in` and `feat_type_out`.\n",
        "Then, an equivariant convolution layer is a standard convolution layer with a filter $k: \\mathbb{R}^2 \\to \\mathbb{R}^{c_\\text{out} \\times c_\\text{in}}$ (note the number of input and output channels) which satisfies a particular **steerability constraint**:\n",
        "$$\n",
        "\\forall g \\in G, x \\in \\mathbb{R}^2 \\quad k(g.x) = \\rho_\\text{out}(g) k(x) \\rho_\\text{in}(g)^{-1}\n",
        "$$\n",
        "\n",
        "In particular, the use of convolution guarantees the translation equivariance, while the fact the filters satisfy this steerability constraint guarantees the $G$-equivairance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkIZ3Te3EAu8"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 9\n",
        "\n",
        "Show that if a filter $k: \\mathbb{R}^2 \\to \\mathbb{R}^{c_\\text{out} \\times c_\\text{in}}$ satisfies the constraint above, the convolution with it is equivariant to $G$, i.e. show that\n",
        "$$\n",
        "  f_\\text{out} = k \\star f_\\text{in} \\implies [g.f_\\text{out}] = k \\star [g.f_\\text{in}]\n",
        "$$\n",
        "\n",
        "for all $g \\in G$.\n",
        "\n",
        "The action on the features $f_\\text{in}$ and $f_\\text{out}$ is the one previously defined, i.e:\n",
        "$$\n",
        "  [g.f_\\text{in}](x) = \\rho_\\text{in}(g) f(g^{-1}x)\n",
        "$$\n",
        "\n",
        "and\n",
        "$$\n",
        "  [g.f_\\text{out}](x) = \\rho_\\text{out}(g) f(g^{-1}x)\n",
        "$$\n",
        "\n",
        "while the convolution is defined as\n",
        "$$\n",
        "  f_\\text{out}(y) = [k \\star f_\\text{in}](y) = \\int_{\\mathbb{R}^2} k(x-y) f_\\text{in}(x) dx\n",
        "$$\n",
        "\n",
        "#### ANSWER 9\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm5WY-HdD-pr"
      },
      "source": [
        "The steerability constraint restricts the space of possible learnable filters to a smaller space of equivariant filters.\n",
        "Solving this constraint goes beyond the scope of this tutorial; fortunately, the `nn.R2Conv` module takes care of properly parameterizing the filter $k$ such that it satisfies the constraint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "fHMs8D-fcQMx"
      },
      "outputs": [],
      "source": [
        "conv = nn.R2Conv(feat_type_in, feat_type_out, kernel_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvWkbVAJcQMx"
      },
      "source": [
        "Each equivariant module has an input and output type.\n",
        "As a function (`.forward()`), it *requires* its inputs to transform according to its input type and is guaranteed to return feature fields associated with its output type.\n",
        "To prevent the user from accidentally feeding an incorrectly transforming input field into an equivariant module, we perform a dynamic type checking.\n",
        "In order to do so, we define **geometric tensors** as data containers.\n",
        "They are wrapping a *PyTorch* `torch.Tensor` to augment them with an instance of `FieldType`.\n",
        "\n",
        "Let's build a few random 32x32 gray-scale images and wrap them into an `nn.GeometricTensor`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "2FH6tglrcQMy"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(4, 1, 32, 32)\n",
        "# FieldType is a callable object; its call method can be used to wrap PyTorch tensors into GeometricTensors\n",
        "x = feat_type_in(x)\n",
        "\n",
        "assert isinstance(x.tensor, torch.Tensor)\n",
        "assert isinstance(x, nn.GeometricTensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkgNfFM1cQMy"
      },
      "source": [
        "As usually done in *PyTorch*, an image or feature map is stored in a 4-dimensional array of shape BxCxHxW, where B is the batch-size, C is the number of channels and W and H are the spatial dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_inH8X-zcQMy"
      },
      "source": [
        "We can feed a geometric tensor to an equivariant module as we feed normal tensors in *PyTorch*'s modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "3FidAyDccQMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebc9241-4944-48b1-db6d-641e0226b908"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "g_tensor([[[[-7.8852e-01, -1.8233e+00, -3.0325e-01,  ...,  1.2842e-01,\n",
              "              1.8592e+00,  1.6324e+00],\n",
              "            [-1.0397e+00, -2.2640e-01,  1.6896e+00,  ...,  2.4441e-01,\n",
              "              2.5026e-01,  1.0067e-01],\n",
              "            [-1.3551e-01,  2.1015e+00,  1.0636e+00,  ..., -4.3562e-01,\n",
              "             -5.3019e-01, -1.9867e+00],\n",
              "            ...,\n",
              "            [ 5.8703e-01,  1.0115e+00,  5.0390e-01,  ..., -1.4187e-01,\n",
              "              7.5401e-01, -2.5149e-01],\n",
              "            [ 4.5801e-01,  9.0574e-02,  2.3865e-01,  ..., -8.9551e-02,\n",
              "             -2.5960e-01, -4.0281e-01],\n",
              "            [-2.8338e-01, -4.0538e-01, -5.4185e-01,  ...,  4.7880e-01,\n",
              "              1.2258e+00,  1.1356e+00]],\n",
              "  \n",
              "           [[ 1.6553e-01, -1.1630e+00,  6.5751e-01,  ...,  9.2218e-01,\n",
              "              7.7118e-02,  2.8035e-01],\n",
              "            [-1.1570e+00,  6.7897e-01,  7.2184e-01,  ...,  1.4658e+00,\n",
              "              3.3531e-01, -3.1345e-01],\n",
              "            [-1.6127e+00,  9.5315e-01,  1.0292e+00,  ...,  6.1334e-01,\n",
              "              2.1212e+00, -2.1854e-01],\n",
              "            ...,\n",
              "            [ 9.3880e-02, -4.9015e-01, -3.6521e-01,  ..., -2.5441e+00,\n",
              "              3.2615e-01,  1.3111e+00],\n",
              "            [ 1.3172e+00, -8.5272e-01, -1.4960e+00,  ..., -1.3723e+00,\n",
              "             -9.4499e-01,  6.3104e-01],\n",
              "            [ 1.0879e+00,  2.2682e-01, -1.9152e-01,  ..., -5.2531e-01,\n",
              "             -8.6998e-01,  2.5057e-02]],\n",
              "  \n",
              "           [[ 3.5300e-01,  7.2890e-01,  8.7440e-01,  ..., -2.8434e-01,\n",
              "             -9.9414e-01, -1.8363e+00],\n",
              "            [ 9.5944e-01,  6.9521e-01, -1.7918e+00,  ..., -8.9738e-01,\n",
              "             -6.7190e-01, -2.1403e-01],\n",
              "            [-5.8454e-02, -1.4719e+00, -2.0878e+00,  ..., -4.3015e-01,\n",
              "              1.8466e+00,  6.1515e-01],\n",
              "            ...,\n",
              "            [-9.3111e-01, -6.7052e-01, -1.7487e-01,  ..., -2.7416e-01,\n",
              "              1.4660e-01, -1.9435e-01],\n",
              "            [-4.5013e-01, -5.8512e-01, -5.4212e-01,  ...,  9.5343e-01,\n",
              "             -3.1812e-01,  4.3697e-01],\n",
              "            [-3.9970e-01,  8.9936e-01,  9.1979e-01,  ..., -2.0680e-01,\n",
              "             -6.8809e-01, -7.4716e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-3.6303e-02,  2.0857e-01,  3.0348e-01,  ..., -1.2931e-02,\n",
              "              3.7061e-01,  2.0714e-01],\n",
              "            [-6.7760e-01,  3.7746e-01,  1.0355e+00,  ...,  6.7624e-01,\n",
              "              1.0909e+00, -3.6809e-01],\n",
              "            [ 5.9028e-01,  1.7175e+00,  4.8133e-01,  ..., -7.3457e-01,\n",
              "             -3.3296e-01, -1.0636e+00],\n",
              "            ...,\n",
              "            [ 3.4130e-01, -3.2942e-01, -7.6575e-01,  ..., -1.0777e-01,\n",
              "              1.8933e-01,  1.1496e-01],\n",
              "            [ 2.3755e-01,  3.6269e-01,  6.2650e-01,  ..., -4.3820e-01,\n",
              "              3.8817e-01, -3.7945e-02],\n",
              "            [-9.2473e-02, -8.9091e-01, -7.3789e-01,  ...,  1.4988e-01,\n",
              "             -6.2593e-01,  1.7022e-01]],\n",
              "  \n",
              "           [[ 5.4106e-01,  1.9767e-01,  2.0351e-01,  ...,  7.3163e-01,\n",
              "             -5.8574e-01,  3.2865e-02],\n",
              "            [ 3.2676e-01,  4.5415e-01,  2.1390e-01,  ...,  7.8226e-01,\n",
              "             -6.6062e-01, -2.7112e-01],\n",
              "            [-4.9499e-01, -4.3450e-01,  7.8678e-01,  ...,  1.4143e+00,\n",
              "              3.0155e-01,  9.9701e-01],\n",
              "            ...,\n",
              "            [ 4.7624e-02, -1.8915e-01,  3.5504e-01,  ..., -9.8790e-01,\n",
              "             -1.5753e-01,  8.0988e-01],\n",
              "            [ 3.5110e-01, -6.5972e-01, -1.0119e+00,  ..., -1.0341e+00,\n",
              "             -2.1336e-01,  4.7122e-01],\n",
              "            [ 8.0809e-01,  1.1591e-01,  4.6118e-02,  ..., -6.9701e-01,\n",
              "             -2.4463e-01, -1.2027e-01]],\n",
              "  \n",
              "           [[ 2.7265e-01,  1.2710e+00,  5.7048e-01,  ..., -4.4813e-01,\n",
              "             -5.4878e-01, -1.0966e+00],\n",
              "            [ 4.5233e-01,  5.3252e-01, -4.7190e-01,  ..., -3.0609e-01,\n",
              "              4.7100e-01, -3.7553e-01],\n",
              "            [ 1.0396e+00,  1.4379e-01, -1.0704e+00,  ..., -9.2247e-01,\n",
              "              2.3349e-02, -2.0733e-01],\n",
              "            ...,\n",
              "            [-2.8555e-01, -6.6356e-01, -7.3540e-01,  ...,  5.7543e-01,\n",
              "              8.4866e-03, -3.3127e-01],\n",
              "            [-5.0963e-01,  2.6720e-01,  7.0159e-01,  ...,  4.7692e-01,\n",
              "              5.5117e-01,  8.0124e-02],\n",
              "            [-5.4635e-01, -3.7544e-01, -6.1416e-02,  ...,  6.4086e-02,\n",
              "             -8.5744e-01, -4.2670e-01]]],\n",
              "  \n",
              "  \n",
              "          [[[-2.7988e-01, -1.2096e+00, -9.0188e-01,  ..., -9.5595e-01,\n",
              "              6.1151e-01,  1.4530e+00],\n",
              "            [-2.3138e+00, -1.2302e+00,  1.4157e-01,  ...,  2.0440e-01,\n",
              "              1.1428e+00,  1.0377e+00],\n",
              "            [-4.4299e-02,  1.3354e+00,  1.1116e+00,  ...,  2.0235e+00,\n",
              "              3.0173e-01,  8.2189e-02],\n",
              "            ...,\n",
              "            [ 4.6663e-01, -3.9863e-01, -7.7693e-01,  ..., -1.1317e+00,\n",
              "              3.2651e-02, -8.8026e-01],\n",
              "            [-1.5476e+00, -8.5750e-01,  3.1041e-01,  ..., -3.3411e-01,\n",
              "              3.0479e-01,  1.2832e+00],\n",
              "            [-6.1882e-01,  2.9780e-01,  8.6036e-01,  ...,  2.2602e-01,\n",
              "              2.9672e-01, -3.8531e-01]],\n",
              "  \n",
              "           [[-1.4194e+00, -8.7137e-01, -3.0807e-01,  ...,  5.8747e-01,\n",
              "              5.4655e-01, -8.0711e-01],\n",
              "            [-1.3410e+00, -3.8908e-01,  1.0108e+00,  ...,  1.1544e+00,\n",
              "              1.4280e+00, -6.6995e-01],\n",
              "            [-1.7795e+00, -4.9732e-01,  1.2648e+00,  ...,  2.0527e+00,\n",
              "              1.7493e+00,  3.9464e-01],\n",
              "            ...,\n",
              "            [-2.8684e-01,  8.2831e-02, -4.9773e-01,  ..., -6.0066e-01,\n",
              "             -4.8784e-01,  5.9342e-01],\n",
              "            [-3.1607e-01, -8.0597e-01,  9.7225e-01,  ...,  6.1345e-01,\n",
              "              4.2977e-01,  3.2641e-01],\n",
              "            [ 5.4529e-01,  4.7553e-01,  2.1218e-02,  ..., -4.2259e-01,\n",
              "              8.7095e-01, -4.1167e-01]],\n",
              "  \n",
              "           [[-2.3405e-01,  1.0377e+00,  8.5783e-01,  ...,  1.2496e+00,\n",
              "              3.2357e-02, -1.1213e+00],\n",
              "            [ 1.6453e+00,  2.1743e+00, -3.1513e-01,  ...,  7.1101e-01,\n",
              "             -1.3404e+00, -1.0424e+00],\n",
              "            [ 1.7844e-01, -7.3154e-01, -1.3545e+00,  ..., -1.2889e-01,\n",
              "             -1.3940e+00,  1.2885e+00],\n",
              "            ...,\n",
              "            [-1.1910e+00,  6.8279e-01,  2.6154e-01,  ..., -1.1752e-01,\n",
              "              7.8950e-01,  2.4170e-01],\n",
              "            [ 7.9382e-01,  6.9771e-01,  3.5750e-01,  ...,  1.5087e+00,\n",
              "             -2.2276e-01, -5.1492e-01],\n",
              "            [ 8.7130e-01, -1.5406e-01, -1.4057e+00,  ..., -6.4918e-01,\n",
              "              6.2270e-02, -7.0931e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-1.3157e-01, -9.3118e-02,  5.2550e-02,  ..., -4.3333e-01,\n",
              "             -2.1316e-01, -3.4356e-01],\n",
              "            [-1.5703e+00, -1.2077e-01,  6.4797e-01,  ...,  9.4926e-01,\n",
              "              5.7166e-01,  4.6248e-01],\n",
              "            [-6.5196e-01,  5.8646e-01,  6.6928e-01,  ...,  8.4715e-01,\n",
              "             -6.9163e-01, -1.1931e+00],\n",
              "            ...,\n",
              "            [ 5.2662e-02, -4.0993e-01,  3.8227e-01,  ..., -2.4928e-01,\n",
              "              4.9043e-01, -3.4931e-01],\n",
              "            [-2.3752e-02,  1.6053e-01,  1.7510e-01,  ..., -7.4829e-01,\n",
              "             -1.1893e-01, -5.9884e-01],\n",
              "            [-3.8475e-01,  6.5321e-01,  3.4133e-01,  ...,  1.0292e-01,\n",
              "              9.3469e-01,  3.7949e-01]],\n",
              "  \n",
              "           [[-6.4020e-01, -3.5774e-01,  4.8120e-02,  ...,  1.2188e-01,\n",
              "             -1.6282e-01, -4.1847e-01],\n",
              "            [ 5.2129e-01, -3.3231e-01,  5.5152e-01,  ..., -5.3094e-01,\n",
              "              1.1101e-01, -1.2444e+00],\n",
              "            [-4.1205e-01, -4.1306e-01,  6.0758e-01,  ..., -4.9086e-01,\n",
              "              1.3453e+00, -6.1235e-01],\n",
              "            ...,\n",
              "            [ 3.3264e-01,  1.9539e-01, -5.2233e-02,  ...,  2.2583e-01,\n",
              "             -1.1596e+00,  6.1697e-01],\n",
              "            [ 2.9972e-01, -1.8179e-01,  2.8170e-01,  ...,  3.5753e-02,\n",
              "              1.3326e-01,  4.9292e-02],\n",
              "            [ 8.0891e-01,  8.2106e-02,  3.2682e-01,  ..., -1.5970e-02,\n",
              "             -5.4832e-01, -1.7198e-01]],\n",
              "  \n",
              "           [[ 2.4665e-01,  9.2151e-01,  7.3206e-01,  ...,  1.9225e-01,\n",
              "             -4.9320e-01, -8.9681e-01],\n",
              "            [ 2.5420e-01,  1.2977e+00,  1.0451e-01,  ...,  7.7796e-01,\n",
              "             -8.2233e-01, -1.3210e-01],\n",
              "            [ 5.9005e-02,  8.5876e-02, -6.2752e-01,  ..., -3.4694e-01,\n",
              "             -1.8915e+00, -6.4226e-01],\n",
              "            ...,\n",
              "            [-5.0608e-01,  2.7863e-02,  7.7149e-01,  ...,  1.2270e-01,\n",
              "              9.3057e-01, -2.0067e-01],\n",
              "            [ 7.6793e-01,  9.0019e-01, -1.6677e-02,  ..., -8.5231e-02,\n",
              "             -4.2060e-01, -1.1437e+00],\n",
              "            [ 5.4495e-02,  3.1475e-01, -5.2388e-01,  ..., -1.2601e-01,\n",
              "              5.2201e-01,  1.8532e-01]]],\n",
              "  \n",
              "  \n",
              "          [[[-1.4971e+00,  3.7496e-01,  1.8221e+00,  ..., -1.4278e-01,\n",
              "              8.6113e-01,  5.6162e-01],\n",
              "            [-7.8549e-01,  1.6083e+00,  8.9740e-01,  ...,  5.9931e-01,\n",
              "             -4.8917e-01,  1.6147e+00],\n",
              "            [ 1.4756e+00,  5.7772e-01, -1.4094e+00,  ..., -3.0748e-01,\n",
              "             -3.4763e-01, -3.6363e-01],\n",
              "            ...,\n",
              "            [-8.7296e-01, -9.8070e-01, -5.5174e-01,  ..., -1.9701e+00,\n",
              "             -1.6501e+00, -9.8869e-01],\n",
              "            [-4.8409e-01,  9.8725e-01,  9.7420e-01,  ...,  4.2548e-01,\n",
              "              4.9668e-01, -2.2986e-01],\n",
              "            [ 2.4025e-01, -5.4088e-01, -1.2180e+00,  ...,  2.9442e-01,\n",
              "              1.4565e+00,  8.4381e-01]],\n",
              "  \n",
              "           [[-2.4501e+00, -6.3100e-01,  2.7221e+00,  ..., -6.5841e-01,\n",
              "             -3.7521e-01, -3.4289e-01],\n",
              "            [-9.3235e-01,  8.8229e-01,  1.5141e+00,  ..., -1.9527e-01,\n",
              "             -9.4963e-01,  1.5007e+00],\n",
              "            [-1.7673e-01,  8.0810e-01, -7.7452e-01,  ..., -3.8118e-01,\n",
              "              1.9121e-01,  3.7870e-01],\n",
              "            ...,\n",
              "            [ 2.3190e-02, -6.1572e-02,  9.0832e-01,  ...,  8.9098e-01,\n",
              "              7.6052e-02, -7.7330e-01],\n",
              "            [-7.3969e-01,  7.6201e-01,  6.7513e-01,  ..., -9.1589e-02,\n",
              "              8.6540e-01,  5.0449e-01],\n",
              "            [ 4.0132e-01,  3.2186e-01, -7.8728e-01,  ..., -3.5143e-01,\n",
              "             -1.0683e+00, -3.9559e-01]],\n",
              "  \n",
              "           [[ 9.3088e-01,  8.3778e-02, -1.5207e+00,  ...,  9.8779e-01,\n",
              "             -9.3663e-01, -1.4715e+00],\n",
              "            [ 1.5761e+00, -1.1996e+00, -1.1806e+00,  ..., -2.5276e-01,\n",
              "             -8.6740e-01,  3.7331e-01],\n",
              "            [-6.0737e-01, -1.3743e+00,  3.1075e-01,  ...,  1.1535e-01,\n",
              "              7.2802e-01, -3.7887e-01],\n",
              "            ...,\n",
              "            [ 1.1235e+00,  4.4955e-01,  4.8326e-01,  ...,  1.4465e+00,\n",
              "              1.8035e+00,  3.7838e-01],\n",
              "            [ 3.8795e-01, -5.3468e-01, -7.9129e-01,  ..., -2.4028e-01,\n",
              "              3.7668e-01, -2.8939e-02],\n",
              "            [ 1.8597e-01, -5.9379e-01, -4.3399e-02,  ..., -9.7999e-01,\n",
              "             -1.7085e+00, -7.7039e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-2.6265e-01,  1.1533e+00,  1.5063e+00,  ..., -1.2396e-01,\n",
              "              5.3444e-01,  1.4243e+00],\n",
              "            [-7.2248e-02,  1.0556e+00, -3.9176e-01,  ...,  7.3824e-01,\n",
              "              7.4178e-03,  4.3055e-01],\n",
              "            [ 7.5166e-01,  6.8591e-01, -2.7176e-01,  ..., -3.8280e-01,\n",
              "              1.1437e-01,  8.8153e-01],\n",
              "            ...,\n",
              "            [-5.6570e-01,  4.6153e-01,  7.5132e-02,  ..., -9.0767e-01,\n",
              "              3.1467e-01, -1.4515e-01],\n",
              "            [ 5.2053e-01,  1.6819e-01, -1.6188e-01,  ..., -7.9574e-01,\n",
              "             -7.3824e-01, -1.7990e-01],\n",
              "            [ 4.5339e-01,  1.1259e+00,  5.6239e-01,  ...,  1.3711e+00,\n",
              "              8.8904e-01, -2.0541e-01]],\n",
              "  \n",
              "           [[-6.6225e-01, -7.2427e-01,  3.0394e-01,  ..., -5.5284e-01,\n",
              "             -2.6818e-02, -3.1574e-01],\n",
              "            [-5.7295e-01, -5.1857e-02,  1.0362e+00,  ..., -6.2532e-01,\n",
              "              4.3231e-01, -5.2341e-01],\n",
              "            [-7.0842e-01,  4.4742e-01,  2.3381e-01,  ...,  2.2294e-01,\n",
              "             -3.0570e-02, -1.7226e-03],\n",
              "            ...,\n",
              "            [ 3.9944e-01,  1.7448e-01,  4.9343e-01,  ...,  1.0979e+00,\n",
              "             -5.0087e-01,  3.5811e-02],\n",
              "            [-2.8664e-01,  4.3136e-01,  5.3861e-01,  ...,  5.8655e-01,\n",
              "              6.2209e-01,  6.2595e-01],\n",
              "            [ 1.4430e-01,  2.6680e-01, -5.5732e-03,  ..., -6.7367e-01,\n",
              "             -9.1592e-01, -5.0337e-02]],\n",
              "  \n",
              "           [[ 1.2579e+00,  1.2064e+00, -5.6933e-01,  ...,  5.8052e-01,\n",
              "             -6.3524e-04,  5.8247e-01],\n",
              "            [ 1.1263e+00, -2.1049e-01, -1.5323e+00,  ...,  4.7930e-01,\n",
              "              3.3050e-03, -2.2899e-01],\n",
              "            [ 1.4837e-01, -3.8385e-01,  4.2641e-01,  ..., -9.5632e-02,\n",
              "              4.6431e-01,  5.6579e-01],\n",
              "            ...,\n",
              "            [ 2.1127e-01,  8.5358e-01,  1.3583e-01,  ...,  4.2588e-03,\n",
              "              1.4141e+00,  4.7854e-01],\n",
              "            [ 9.8800e-01, -5.1593e-01, -8.9947e-01,  ..., -8.6308e-01,\n",
              "             -8.2316e-01, -2.7421e-01],\n",
              "            [ 3.4628e-01,  7.5501e-01,  9.7030e-01,  ...,  7.9065e-01,\n",
              "              1.1175e-02, -5.8072e-01]]],\n",
              "  \n",
              "  \n",
              "          [[[-1.7559e+00, -1.2750e-01,  7.4757e-02,  ..., -1.2978e+00,\n",
              "              5.0172e-02, -8.1101e-02],\n",
              "            [-3.2166e-01,  1.3557e+00,  8.7105e-01,  ..., -6.0260e-01,\n",
              "              2.1220e-01, -7.1594e-01],\n",
              "            [ 1.3661e+00,  1.5892e+00,  2.3253e-01,  ..., -6.5040e-01,\n",
              "              1.0572e+00,  6.6543e-02],\n",
              "            ...,\n",
              "            [-8.7832e-01,  2.7806e-01, -2.9592e-01,  ...,  6.7954e-02,\n",
              "              6.3891e-01,  3.7120e-01],\n",
              "            [ 1.3623e+00,  8.3690e-01, -9.4963e-01,  ...,  1.0227e-02,\n",
              "             -6.4431e-01,  1.2564e-01],\n",
              "            [ 1.0052e+00, -3.0918e-01, -8.3579e-01,  ...,  7.9749e-02,\n",
              "             -2.0170e+00, -7.6891e-01]],\n",
              "  \n",
              "           [[-5.3883e-01,  1.2537e+00,  8.9735e-01,  ..., -1.0946e+00,\n",
              "              3.9331e-01,  2.4132e-01],\n",
              "            [-1.0906e+00,  1.4565e+00,  6.3664e-01,  ..., -1.6505e+00,\n",
              "              2.1866e-01,  5.2119e-01],\n",
              "            [-6.0506e-01,  1.4336e+00,  7.9776e-01,  ..., -2.2697e+00,\n",
              "              3.0310e-01,  4.8763e-01],\n",
              "            ...,\n",
              "            [-7.2284e-01,  8.6386e-01, -5.8448e-01,  ...,  2.8947e-01,\n",
              "             -3.9274e-01, -5.0412e-01],\n",
              "            [-6.1744e-01,  8.7158e-01, -2.3491e-01,  ...,  1.2828e+00,\n",
              "             -2.3511e-01, -4.3806e-01],\n",
              "            [-9.9055e-01, -1.1442e+00, -1.0370e+00,  ...,  7.2052e-01,\n",
              "             -3.6239e-02,  7.1245e-01]],\n",
              "  \n",
              "           [[ 1.1070e+00,  1.0294e+00, -7.0344e-01,  ...,  4.0049e-01,\n",
              "              1.1821e+00, -1.0893e+00],\n",
              "            [ 3.0505e-01, -1.0966e+00, -1.7728e+00,  ..., -1.3713e-01,\n",
              "              3.8619e-01, -5.3943e-01],\n",
              "            [-8.0383e-01, -1.6656e+00, -5.9306e-01,  ..., -6.9655e-03,\n",
              "              1.5760e-01, -1.1768e+00],\n",
              "            ...,\n",
              "            [ 7.0755e-01, -7.5193e-02, -6.8922e-01,  ...,  1.2214e-01,\n",
              "             -5.5243e-01, -2.4150e-01],\n",
              "            [-3.3123e-01, -8.7139e-01,  4.5840e-01,  ...,  4.1700e-01,\n",
              "             -6.5178e-02,  5.4039e-01],\n",
              "            [-6.7271e-01, -6.5158e-01,  8.5621e-01,  ...,  2.5445e-01,\n",
              "              1.2990e+00,  1.4611e+00]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-7.9980e-01,  5.5007e-01, -3.7704e-01,  ..., -8.1750e-01,\n",
              "              5.0659e-01,  4.0062e-01],\n",
              "            [ 4.6779e-01,  1.5660e+00,  4.4723e-01,  ..., -8.8582e-01,\n",
              "              1.1471e+00, -3.2106e-01],\n",
              "            [ 7.0448e-01,  6.8494e-01, -3.6298e-01,  ..., -2.9627e-01,\n",
              "              6.8825e-01, -3.4040e-03],\n",
              "            ...,\n",
              "            [ 4.4441e-02,  9.4748e-01,  9.2353e-02,  ...,  2.5848e-01,\n",
              "             -1.7909e-01, -7.2911e-02],\n",
              "            [-4.6379e-02, -2.7678e-01, -7.0690e-01,  ...,  2.4798e-01,\n",
              "             -2.9090e-01,  1.8402e-01],\n",
              "            [ 7.2487e-01,  1.1228e-01, -3.6096e-01,  ..., -3.0066e-01,\n",
              "             -9.2502e-01,  6.3775e-01]],\n",
              "  \n",
              "           [[ 9.8484e-01,  1.6365e-01,  1.2104e+00,  ...,  6.1114e-01,\n",
              "             -4.9520e-01,  7.5615e-01],\n",
              "            [-1.6922e-01,  8.8769e-02,  5.5968e-01,  ...,  4.1691e-01,\n",
              "             -5.7020e-01,  1.4243e+00],\n",
              "            [-5.3833e-01,  5.5241e-01,  5.7629e-01,  ..., -3.9854e-01,\n",
              "             -5.2877e-01,  1.1412e+00],\n",
              "            ...,\n",
              "            [-1.1845e-01, -1.3084e-01,  2.6087e-01,  ..., -3.6194e-01,\n",
              "             -2.7983e-01, -3.5460e-01],\n",
              "            [-6.3282e-01,  7.8763e-01,  6.3908e-01,  ...,  6.3894e-02,\n",
              "              1.6328e-01, -8.8905e-01],\n",
              "            [-1.2957e+00, -1.6484e-01, -3.5768e-02,  ...,  3.6710e-01,\n",
              "              8.8326e-01, -5.1344e-01]],\n",
              "  \n",
              "           [[ 3.6631e-01,  6.3384e-01, -9.4364e-01,  ...,  7.7662e-02,\n",
              "              8.8761e-01, -1.9594e-01],\n",
              "            [ 9.9762e-01,  1.8316e-01, -8.0358e-01,  ..., -2.0215e-01,\n",
              "              1.1161e+00, -5.2769e-01],\n",
              "            [ 1.8020e-01, -9.1167e-01, -9.0128e-01,  ...,  5.6505e-01,\n",
              "              4.0502e-01, -6.9781e-01],\n",
              "            ...,\n",
              "            [ 7.8223e-01,  4.9237e-01,  3.8460e-04,  ...,  1.5803e-01,\n",
              "             -4.4245e-01, -1.0311e-01],\n",
              "            [-2.7525e-01, -1.0710e+00, -1.3557e-01,  ...,  1.2269e-02,\n",
              "             -1.0697e-01,  5.0742e-01],\n",
              "            [ 4.0587e-01,  2.1182e-01,  5.9027e-01,  ..., -3.7328e-01,\n",
              "              2.1843e-01,  1.1753e+00]]]], grad_fn=<ConvolutionBackward0>, [C4_on_R2[(None, 4)]: {regular (x3)}(12)])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "y = conv(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPzlskTvcQMy"
      },
      "source": [
        "We can verify that the output is indeed associated with the output type of the convolutional layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "0C-TI2XucQMy",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe757e20-bc2f-4175-e741-88fd7de4ac0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[C4_on_R2[(None, 4)]: {regular (x3)}(12)]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "assert y.type == feat_type_out\n",
        "\n",
        "feat_type_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQfGtWyKcQMy"
      },
      "source": [
        "Lets check whether the output transforms as described by the output type when the input transforms according to the input type.\n",
        "The $G$-transformation of a geometric tensor is hereby conveniently done by calling `nn.GeometricTensor.transform()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "2blpKyR4cQMz",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# for each group element\n",
        "for g in G.elements:\n",
        "    # transform the input with the current group element according to the input type\n",
        "    x_transformed = x.transform(g)\n",
        "\n",
        "    # feed the transformed input in the convolutional layer\n",
        "    y_from_x_transformed = conv(x_transformed)\n",
        "\n",
        "    # the result should be equivalent to rotating the output produced in the\n",
        "    # previous block according to the output type\n",
        "    y_transformed_from_x = y.transform(g)\n",
        "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-5), g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlVmEn4ocQMz"
      },
      "source": [
        "Any network operation is required to be equivariant.\n",
        "`escnn.nn` provides a wide range of equivariant network modules which guarantee this behavior.\n",
        "\n",
        "**Non-Linearities**:\n",
        "As an example, we will next apply an *equivariant nonlinearity* to the output feature field of the convolution.\n",
        "Since the regular representations of a finite group $G$ consists of permutation matrices, any pointwise nonlinearity like *ReLUs* is equivariant.\n",
        "Note that this is *not* the case for many other choices of representations / field types!\n",
        "\n",
        "We instantiate a `escnn.nn.ReLU`, which, as an `nn.EquivariantModule`, requires to be informed about its input type to be able to perform the type checking.\n",
        "Here we are passing `feat_type_out`, the output of the equivariant convolution layer, as input type.\n",
        "It is not necessary to pass an output type to the nonlinearity since this is here determined by its input type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Ja5uesnlcQMz"
      },
      "outputs": [],
      "source": [
        "relu = nn.ReLU(feat_type_out)\n",
        "\n",
        "z = relu(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX-dHFVvcQMz"
      },
      "source": [
        "We can verify the equivariance again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "JjdjyzF-cQMz"
      },
      "outputs": [],
      "source": [
        "# for each group element\n",
        "for g in G.elements:\n",
        "    y_transformed = y.transform(g)\n",
        "    z_from_y_transformed = relu(y_transformed)\n",
        "\n",
        "    z_transformed_from_y = z.transform(g)\n",
        "\n",
        "    assert torch.allclose(z_from_y_transformed.tensor, z_transformed_from_y.tensor, atol=1e-5), g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAnTVtIucQMz"
      },
      "source": [
        "**Deeper Models**: In *deep learning* we usually want to stack multiple layers to build a deep model.\n",
        "As long as each layer is equivariant and consecutive layers are compatible, the equivariance property is preserved by induction.\n",
        "\n",
        "The compatibility of two consecutive layers requires the output type of the first layer to be equal to the input type of the second layer.\n",
        "\n",
        "In case we feed an input with the wrong type to a module, an error is raised:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "z3EGMW1HcQM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544d03ae-61a1-4220-998c-3242155a0eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error! the type of the input does not match the input type of this module\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.R2Conv(feat_type_in, feat_type_out, kernel_size=3)\n",
        "layer2 = nn.ReLU(feat_type_in) # the input type of the ReLU should be the output type of the convolution\n",
        "\n",
        "x = feat_type_in(torch.randn(3, 1, 7, 7))\n",
        "\n",
        "try:\n",
        "    y = layer2(layer1(x))\n",
        "except AssertionError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt3KkNUTcQM0"
      },
      "source": [
        "Simple deeper architectures can be built using a **SequentialModule**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "XDjfrUpYcQM0"
      },
      "outputs": [],
      "source": [
        "feat_type_in = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
        "feat_type_hid = nn.FieldType(r2_act, 8*[r2_act.regular_repr])\n",
        "feat_type_out = nn.FieldType(r2_act, 2*[r2_act.regular_repr])\n",
        "\n",
        "model = nn.SequentialModule(\n",
        "    nn.R2Conv(feat_type_in, feat_type_hid, kernel_size=3),\n",
        "    nn.InnerBatchNorm(feat_type_hid),\n",
        "    nn.ReLU(feat_type_hid, inplace=True),\n",
        "    nn.R2Conv(feat_type_hid, feat_type_hid, kernel_size=3),\n",
        "    nn.InnerBatchNorm(feat_type_hid),\n",
        "    nn.ReLU(feat_type_hid, inplace=True),\n",
        "    nn.R2Conv(feat_type_hid, feat_type_out, kernel_size=3),\n",
        ").eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRs_N_TqcQM0"
      },
      "source": [
        "As every layer is equivariant and consecutive layers are compatible, the whole model is equivariant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "qOM5wHTccQM0"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(1, 1, 17, 17)\n",
        "x = feat_type_in(x)\n",
        "\n",
        "y = model(x)\n",
        "\n",
        "# for each group element\n",
        "for g in G.elements:\n",
        "    x_transformed = x.transform(g)\n",
        "    y_from_x_transformed = model(x_transformed)\n",
        "\n",
        "    y_transformed_from_x = y.transform(g)\n",
        "\n",
        "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-5), g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdVdUVntcQM1"
      },
      "source": [
        "**Invariant Pooling Layer**: Usually, at the end of the model we want to produce a single feature vector to use for classification.\n",
        "To do so, it is common to pool over the spatial dimensions, e.g. via average pooling.\n",
        "\n",
        "This produces (approximatively) translation-invariant feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8DDnTO8DcQM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4100296-2e4d-4d3b-c8dd-a801123db11b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x : torch.Size([1, 1, 17, 17])\n",
            "out_feature_map : torch.Size([1, 8, 11, 11])\n",
            "y : torch.Size([1, 8, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# average pooling with window size 11\n",
        "avgpool = nn.PointwiseAvgPool(feat_type_out, 11)\n",
        "\n",
        "out_feature_map = model(x)\n",
        "y = avgpool(out_feature_map)\n",
        "\n",
        "print(f\"x : {x.shape}\")\n",
        "print(f\"out_feature_map : {out_feature_map.shape}\")\n",
        "print(f\"y : {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIbR_0GtcQM1"
      },
      "source": [
        "In our case, the feature vectors $f(x)\\in\\mathbb{R}^c$ associated to each point $x\\in\\mathbb{R}^2$ have a well defined transformation law.\n",
        "The output of the model now transforms according to `feat_type_out` (here two $C_4$ regular fields, i.e. 8 channels).\n",
        "For our choice of regular representations (which are permutation representations) the channels in the feature vectors associated to each point permute when the input is rotated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "LNtReKgUcQM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164a4f66-810e-4e5b-bb8c-967ca3e02425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rotation by 0[2pi/4]: [ 0.716  0.724  0.658  0.691  0.04  -0.028  0.033  0.037]\n",
            "rotation by 1[2pi/4]: [ 0.691  0.716  0.724  0.658  0.037  0.04  -0.028  0.033]\n",
            "rotation by 2[2pi/4]: [ 0.658  0.691  0.716  0.724  0.033  0.037  0.04  -0.028]\n",
            "rotation by 3[2pi/4]: [ 0.724  0.658  0.691  0.716 -0.028  0.033  0.037  0.04 ]\n"
          ]
        }
      ],
      "source": [
        "for g in G.elements:\n",
        "    print(f'rotation by {g}:', y.transform(g).tensor[0, ...].detach().numpy().squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9k0MPvucQM1"
      },
      "source": [
        "Many learning tasks require to build models which are **invariant** under rotations.\n",
        "We can compute invariant features from the output of the model using an **invariant map**.\n",
        "For instance, we can take the maximum value within each regular field.\n",
        "We do so using `nn.GroupPooling`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "DUAvcM3UcQM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd62a7ad-a58d-426e-d498-2667f6291087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g_tensor([[[[0.7240]],\n",
            "  \n",
            "           [[0.0397]]]], grad_fn=<CopySlices>, [C4_on_R2[(None, 4)]: {irrep_0 (x2)}(2)])\n",
            "\n",
            "\n",
            "rotation by 0[2pi/4]: [0.724 0.04 ]\n",
            "rotation by 1[2pi/4]: [0.724 0.04 ]\n",
            "rotation by 2[2pi/4]: [0.724 0.04 ]\n",
            "rotation by 3[2pi/4]: [0.724 0.04 ]\n"
          ]
        }
      ],
      "source": [
        "invariant_map = nn.GroupPooling(feat_type_out)\n",
        "\n",
        "y = invariant_map(avgpool(model(x)))\n",
        "print(y, end=\"\\n\\n\\n\")\n",
        "for g in G.elements:\n",
        "    print(f'rotation by {g}:', y.transform(g).tensor[0, ...].detach().numpy().squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "yVY711w-cQM2"
      },
      "outputs": [],
      "source": [
        "# for each group element\n",
        "for g in G.elements:\n",
        "    # rotated the input image\n",
        "    x_transformed = x.transform(g)\n",
        "    y_from_x_transformed = invariant_map(avgpool(model(x_transformed)))\n",
        "\n",
        "    y_transformed_from_x = y # no transform(g) needed since y should be invariant!\n",
        "\n",
        "    # check that the output did not change\n",
        "    # note that here we are not rotating the original output y as before\n",
        "    assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-6), g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJNcJUKBpuK"
      },
      "source": [
        "### 2.3 Steerable CNN with infinite group $G$\n",
        "\n",
        "We can now repeat the same constructions with $G$ being an infinite group, e.g. the group of all planar rotations $G=SO(2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "LHJGeENZGgPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45183a3-ea9a-4f9f-a181-985685956f79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SO(2)_on_R2[(None, -1)]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "# use N=-1 to indicate all rotations\n",
        "r2_act = gspaces.rot2dOnR2(N=-1)\n",
        "r2_act"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "p-46yXnCGowV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facdf3d5-ff54-40b9-929c-f53c87e1f9f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SO(2)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "G = r2_act.fibergroup\n",
        "G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "BXGQWso9lKH1"
      },
      "outputs": [],
      "source": [
        "# For simplicity we take a single-channel gray-scale image in input and we output a single-channel gray-scale image, i.e. we use scalar fields in input and output\n",
        "feat_type_in = nn.FieldType(r2_act, [G.trivial_representation])\n",
        "feat_type_out = nn.FieldType(r2_act, [G.trivial_representation])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzGYVFqllf0O"
      },
      "source": [
        "As intermidiate feature types, we want to use again the *regular representation*.\n",
        "Because $G$ has an infinite number of elements, we use use the Fourier transform idea described earlier.\n",
        "For example, we will use the first three irreps of $G=SO(2)$, which contains cosines and sines of frequency $0$, $1$ and $2$.\n",
        "Earlier, we built this representation as\n",
        "\n",
        "\n",
        "``rho = G.bl_regular_representation(2)``\n",
        "\n",
        "To apply a non-linearity, e.g. ELU, we can use the *Inverse Fourier Transform* to sample the function, apply the non-linearity and, finally, compute the *Fourier Transform* to recover the coeffients.\n",
        "Because $G$ has infinite elements, the Fourier Transform requires an integral over $G$; this can be **approximated** by a sum over a finite number of samples.\n",
        "The more samples one take, the better the approximation will be, although this also increase the computational cost.\n",
        "\n",
        "Fortunately, the class `nn.FourierELU` takes care of most of these details.\n",
        "We can just specify which `irreps` to consider (`G.bl_irreps(2)` returns the list of irreps up to frequency `2`), the number of `channels` (i.e. copies of the regular representation) and the number `N` of elements of $G$ where to sample the function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "5xje7cC5leVu"
      },
      "outputs": [],
      "source": [
        "nonlinearity = nn.FourierELU(r2_act, 16, irreps=G.bl_irreps(2), N=12)\n",
        "# we do not need to pre-define the feature type: FourierELU will create it internally and we can just access it as\n",
        "feat_type_hid = nonlinearity.in_type\n",
        "\n",
        "# note also the its input and output types are the same\n",
        "assert nonlinearity.in_type == nonlinearity.out_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuZrDNbPrag7"
      },
      "source": [
        "Let's build a simple $G=SO(2)$ equivariant model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "ky4-B4u5GvfA"
      },
      "outputs": [],
      "source": [
        "\n",
        "equivariant_so2_model = nn.SequentialModule(\n",
        "    nn.R2Conv(feat_type_in, feat_type_hid, kernel_size=7),\n",
        "    nn.IIDBatchNorm2d(feat_type_hid),\n",
        "    nonlinearity,\n",
        "    nn.R2Conv(feat_type_hid, feat_type_hid, kernel_size=7),\n",
        "    nn.IIDBatchNorm2d(feat_type_hid),\n",
        "    nonlinearity,\n",
        "    nn.R2Conv(feat_type_hid, feat_type_out, kernel_size=7),\n",
        ").eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oEgHC6ero20"
      },
      "source": [
        "and check its equivariance to a few elements of $SO(2)$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "XiJYMBghrx2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5f1ed9-3850-4734-e9cc-09d9cd76e2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error! The model is not equivariant! group element used : 0.39269908169872414\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1, 1, 23, 23)\n",
        "x = feat_type_in(x)\n",
        "\n",
        "y = equivariant_so2_model(x)\n",
        "\n",
        "# check equivariance to N=16 rotations\n",
        "N = 16\n",
        "\n",
        "try:\n",
        "    for i in range(N):\n",
        "        g = G.element(i*2*np.pi/N)\n",
        "        x_transformed = x.transform(g)\n",
        "        y_from_x_transformed = equivariant_so2_model(x_transformed)\n",
        "\n",
        "        y_transformed_from_x = y.transform(g)\n",
        "\n",
        "        assert torch.allclose(y_from_x_transformed.tensor, y_transformed_from_x.tensor, atol=1e-3), f\"group element used : {g}\"\n",
        "except Exception as e:\n",
        "    print('Error! The model is not equivariant!', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw57cTedsMSI"
      },
      "source": [
        "---\n",
        "\n",
        "#### QUESTION 10\n",
        "The model is not perfectly equivariant to $G=SO(2)$ ! Why is this an expected behaviour?\n",
        "\n",
        "#### ANSWER 10\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE6qLnMtsetK"
      },
      "source": [
        "While the model can not be perfectly equivariant, we can compare it with a *conventional CNN* baseline.\n",
        "Let's build a CNN similar to our equivariant model but which is not constrained to be equivariant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "OZ6ZiQQyrfue"
      },
      "outputs": [],
      "source": [
        "\n",
        "conventional_model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(feat_type_in.size, feat_type_hid.size, kernel_size=7),\n",
        "    torch.nn.BatchNorm2d(feat_type_hid.size),\n",
        "    torch.nn.ELU(),\n",
        "    torch.nn.Conv2d(feat_type_hid.size, feat_type_hid.size, kernel_size=7),\n",
        "    torch.nn.BatchNorm2d(feat_type_hid.size),\n",
        "    torch.nn.ELU(),\n",
        "    torch.nn.Conv2d(feat_type_hid.size, feat_type_out.size, kernel_size=7),\n",
        ").eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IFq5k-isxyC"
      },
      "source": [
        "To compare the two models, we compute their *equivariance error* for a few elements of $G$.\n",
        "We define the equivariance error of a model $F$ with respect to a group element $g \\in G$ and an input $x$ as:\n",
        "$$\n",
        "  \\epsilon_g(F) = \\frac{||F(g.X) - g.F(X)||_2}{||F(x)||_2}\n",
        "$$\n",
        "\n",
        "Note that this is a form of *relative* error.\n",
        "Let's now compute the equivariance error of the two models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "BuOcNrfOIX2V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "4285cb98-3d0a-408f-d10f-3e7cebb3d911"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"626.610937pt\" height=\"413.110312pt\" viewBox=\"0 0 626.610937 413.110312\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-01-11T03:02:51.037771</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 413.110312 \nL 626.610937 413.110312 \nL 626.610937 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 61.410938 361.036875 \nL 619.410938 361.036875 \nL 619.410938 28.396875 \nL 61.410938 28.396875 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m7f01edbe85\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"86.774574\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(82.002699 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"167.509536\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(162.737661 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"248.244498\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(243.472623 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"328.97946\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(324.207585 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"409.714422\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(404.942547 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"490.449384\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(485.677509 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m7f01edbe85\" x=\"571.184346\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(566.412471 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- $g = r_\\theta$ -->\n     <g transform=\"translate(313.110937 401.710312) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-Oblique-67\" d=\"M 3816 3500 \nL 3219 434 \nQ 3047 -456 2561 -893 \nQ 2075 -1331 1253 -1331 \nQ 950 -1331 690 -1286 \nQ 431 -1241 206 -1147 \nL 313 -588 \nQ 525 -725 762 -790 \nQ 1000 -856 1269 -856 \nQ 1816 -856 2167 -557 \nQ 2519 -259 2631 300 \nL 2681 563 \nQ 2441 288 2122 144 \nQ 1803 0 1434 0 \nQ 903 0 598 351 \nQ 294 703 294 1319 \nQ 294 1803 478 2267 \nQ 663 2731 997 3091 \nQ 1219 3328 1514 3456 \nQ 1809 3584 2131 3584 \nQ 2484 3584 2746 3420 \nQ 3009 3256 3138 2956 \nL 3238 3500 \nL 3816 3500 \nz\nM 2950 2216 \nQ 2950 2641 2750 2872 \nQ 2550 3103 2181 3103 \nQ 1953 3103 1747 3012 \nQ 1541 2922 1394 2759 \nQ 1156 2491 1023 2127 \nQ 891 1763 891 1375 \nQ 891 944 1092 712 \nQ 1294 481 1672 481 \nQ 2219 481 2584 976 \nQ 2950 1472 2950 2216 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-Oblique-72\" d=\"M 2853 2969 \nQ 2766 3016 2653 3041 \nQ 2541 3066 2413 3066 \nQ 1953 3066 1609 2717 \nQ 1266 2369 1153 1784 \nL 800 0 \nL 225 0 \nL 909 3500 \nL 1484 3500 \nL 1375 2956 \nQ 1603 3259 1920 3421 \nQ 2238 3584 2597 3584 \nQ 2691 3584 2781 3573 \nQ 2872 3563 2963 3538 \nL 2853 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-Oblique-3b8\" d=\"M 2913 2219 \nL 925 2219 \nQ 791 1284 928 888 \nQ 1100 400 1566 400 \nQ 2034 400 2391 891 \nQ 2703 1322 2913 2219 \nz\nM 3009 2750 \nQ 3094 3638 2984 3950 \nQ 2813 4444 2353 4444 \nQ 1875 4444 1525 3956 \nQ 1250 3563 1034 2750 \nL 3009 2750 \nz\nM 2444 4913 \nQ 3194 4913 3494 4250 \nQ 3794 3591 3566 2422 \nQ 3341 1256 2781 594 \nQ 2225 -72 1475 -72 \nQ 722 -72 425 594 \nQ 128 1256 353 2422 \nQ 581 3591 1134 4250 \nQ 1691 4913 2444 4913 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-Oblique-67\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(82.958984 0)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-72\" transform=\"translate(186.230469 0)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(227.34375 -16.40625) scale(0.7)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"ma62262b60c\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#ma62262b60c\" x=\"61.410938\" y=\"345.916875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <g transform=\"translate(30.55625 351.615703) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#ma62262b60c\" x=\"61.410938\" y=\"286.530243\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(30.55625 292.229071) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#ma62262b60c\" x=\"61.410938\" y=\"227.143611\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.4 -->\n      <g transform=\"translate(30.55625 232.842439) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(95.410156 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#ma62262b60c\" x=\"61.410938\" y=\"167.756979\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.6 -->\n      <g transform=\"translate(30.55625 173.455807) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(95.410156 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#ma62262b60c\" x=\"61.410938\" y=\"108.370347\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.8 -->\n      <g transform=\"translate(30.55625 114.069175) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-38\" transform=\"translate(95.410156 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#ma62262b60c\" x=\"61.410938\" y=\"48.983715\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.0 -->\n      <g transform=\"translate(30.55625 54.682543) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- Equivariance Error -->\n     <g transform=\"translate(22.396875 287.10125) rotate(-90) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-71\" d=\"M 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\nM 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 -1331 \nL 2906 -1331 \nL 2906 525 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-71\" transform=\"translate(63.183594 0)\"/>\n      <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(126.660156 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(190.039062 0)\"/>\n      <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(217.822266 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(277.001953 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(338.28125 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(379.394531 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(407.177734 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(468.457031 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(531.835938 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(586.816406 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(648.339844 0)\"/>\n      <use xlink:href=\"#DejaVuSans-45\" transform=\"translate(680.126953 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(743.310547 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(782.673828 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(821.537109 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(882.71875 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 86.774574 345.916875 \nL 91.847301 332.544664 \nL 96.920028 334.850418 \nL 101.992756 333.147075 \nL 107.065483 332.87104 \nL 112.13821 330.559063 \nL 117.210938 332.719827 \nL 122.283665 329.075946 \nL 127.356392 333.613757 \nL 132.429119 334.629011 \nL 137.501847 337.178139 \nL 142.574574 332.046738 \nL 147.647301 327.801253 \nL 152.720028 334.50448 \nL 157.792756 331.705104 \nL 162.865483 330.939262 \nL 167.93821 337.329493 \nL 173.010938 331.261103 \nL 178.083665 331.399066 \nL 183.156392 332.129124 \nL 188.229119 332.420295 \nL 193.301847 331.332975 \nL 198.374574 332.799022 \nL 203.447301 333.641632 \nL 208.520028 332.831523 \nL 213.592756 345.916726 \nL 218.665483 332.544668 \nL 223.73821 334.850404 \nL 228.810937 333.147082 \nL 233.883665 332.871039 \nL 238.956392 330.559055 \nL 244.029119 332.719845 \nL 249.101847 329.075962 \nL 254.174574 333.613753 \nL 259.247301 334.629 \nL 264.320028 337.178137 \nL 269.392756 332.046738 \nL 274.465483 327.801277 \nL 279.53821 334.504488 \nL 284.610937 331.70511 \nL 289.683665 330.939283 \nL 294.756392 337.329512 \nL 299.829119 331.261124 \nL 304.901847 331.399067 \nL 309.974574 332.129137 \nL 315.047301 332.420299 \nL 320.120028 331.33297 \nL 325.192756 332.799018 \nL 330.265483 333.641611 \nL 335.33821 332.831503 \nL 340.410937 345.916717 \nL 345.483665 332.544674 \nL 350.556392 334.850393 \nL 355.629119 333.147078 \nL 360.701847 332.871021 \nL 365.774574 330.559052 \nL 370.847301 332.719847 \nL 375.920028 329.075975 \nL 380.992756 333.613748 \nL 386.065483 334.628994 \nL 391.13821 337.178142 \nL 396.210938 332.046727 \nL 401.283665 327.801274 \nL 406.356392 334.504493 \nL 411.429119 331.705094 \nL 416.501847 330.939284 \nL 421.574574 337.329509 \nL 426.647301 331.261111 \nL 431.720028 331.399071 \nL 436.792756 332.129138 \nL 441.865483 332.420281 \nL 446.93821 331.332962 \nL 452.010938 332.799011 \nL 457.083665 333.641603 \nL 462.156392 332.831516 \nL 467.229119 345.916734 \nL 472.301847 332.544667 \nL 477.374574 334.850413 \nL 482.447301 333.147075 \nL 487.520028 332.871027 \nL 492.592756 330.559052 \nL 497.665483 332.71983 \nL 502.73821 329.075963 \nL 507.810938 333.61374 \nL 512.883665 334.629003 \nL 517.956392 337.178154 \nL 523.029119 332.046729 \nL 528.101847 327.801255 \nL 533.174574 334.504489 \nL 538.247301 331.705098 \nL 543.320028 330.939281 \nL 548.392756 337.329485 \nL 553.465483 331.261101 \nL 558.53821 331.399073 \nL 563.610938 332.129135 \nL 568.683665 332.420272 \nL 573.756392 331.332972 \nL 578.829119 332.799017 \nL 583.901847 333.641604 \nL 588.974574 332.831519 \nL 594.047301 345.916875 \n\" clip-path=\"url(#p6d5ca12045)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 86.774574 345.916875 \nL 91.847301 254.972311 \nL 96.920028 172.417582 \nL 101.992756 132.953063 \nL 107.065483 123.516334 \nL 112.13821 110.344072 \nL 117.210938 87.066647 \nL 122.283665 77.457358 \nL 127.356392 65.983838 \nL 132.429119 67.890584 \nL 137.501847 70.560427 \nL 142.574574 53.590834 \nL 147.647301 46.706872 \nL 152.720028 49.285333 \nL 157.792756 75.435444 \nL 162.865483 77.784448 \nL 167.93821 97.713312 \nL 173.010938 83.994127 \nL 178.083665 90.403225 \nL 183.156392 104.907866 \nL 188.229119 100.440169 \nL 193.301847 94.13794 \nL 198.374574 83.547121 \nL 203.447301 97.28659 \nL 208.520028 79.947004 \nL 213.592756 49.304839 \nL 218.665483 74.658287 \nL 223.73821 71.817558 \nL 228.810937 62.022105 \nL 233.883665 67.123413 \nL 238.956392 72.973423 \nL 244.029119 70.931743 \nL 249.101847 62.881255 \nL 254.174574 52.106115 \nL 259.247301 67.274378 \nL 264.320028 64.345638 \nL 269.392756 82.016983 \nL 274.465483 64.995071 \nL 279.53821 57.709263 \nL 284.610937 70.691004 \nL 289.683665 79.814637 \nL 294.756392 67.913021 \nL 299.829119 49.548613 \nL 304.901847 57.175881 \nL 309.974574 73.028284 \nL 315.047301 99.708794 \nL 320.120028 109.508553 \nL 325.192756 94.007285 \nL 330.265483 87.777841 \nL 335.33821 74.654215 \nL 340.410937 43.516875 \nL 345.483665 89.654393 \nL 350.556392 95.603412 \nL 355.629119 73.773587 \nL 360.701847 71.35102 \nL 365.774574 74.714756 \nL 370.847301 69.669502 \nL 375.920028 78.371706 \nL 380.992756 57.708822 \nL 386.065483 69.12922 \nL 391.13821 70.396908 \nL 396.210938 71.370448 \nL 401.283665 59.106931 \nL 406.356392 67.159572 \nL 411.429119 74.506881 \nL 416.501847 83.977864 \nL 421.574574 70.248304 \nL 426.647301 70.14115 \nL 431.720028 80.619549 \nL 436.792756 86.292214 \nL 441.865483 79.530191 \nL 446.93821 76.575201 \nL 452.010938 66.110316 \nL 457.083665 77.550946 \nL 462.156392 89.421332 \nL 467.229119 69.246153 \nL 472.301847 99.504395 \nL 477.374574 92.124922 \nL 482.447301 61.943536 \nL 487.520028 66.056882 \nL 492.592756 70.844873 \nL 497.665483 72.059724 \nL 502.73821 61.26749 \nL 507.810938 68.468918 \nL 512.883665 67.242914 \nL 517.956392 74.659584 \nL 523.029119 79.961919 \nL 528.101847 51.959689 \nL 533.174574 45.703632 \nL 538.247301 52.743071 \nL 543.320028 56.762959 \nL 548.392756 58.557156 \nL 553.465483 52.83557 \nL 558.53821 63.750884 \nL 563.610938 78.538286 \nL 568.683665 96.390114 \nL 573.756392 126.542708 \nL 578.829119 145.794448 \nL 583.901847 181.378552 \nL 588.974574 255.49642 \nL 594.047301 345.916875 \n\" clip-path=\"url(#p6d5ca12045)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 61.410938 361.036875 \nL 61.410938 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 619.410938 361.036875 \nL 619.410938 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 61.410938 361.036875 \nL 619.410938 361.036875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 61.410938 28.396875 \nL 619.410938 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- Equivariant vs Conventional CNNs -->\n    <g transform=\"translate(169.579687 22.396875) scale(0.2 -0.2)\">\n     <defs>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-45\"/>\n     <use xlink:href=\"#DejaVuSans-71\" transform=\"translate(63.183594 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(126.660156 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(190.039062 0)\"/>\n     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(217.822266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(277.001953 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(338.28125 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(379.394531 0)\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(407.177734 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(468.457031 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(531.835938 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(571.044922 0)\"/>\n     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(602.832031 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(662.011719 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(714.111328 0)\"/>\n     <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(745.898438 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(815.722656 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(876.904297 0)\"/>\n     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(940.283203 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(999.462891 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(1060.986328 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(1124.365234 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(1163.574219 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(1191.357422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(1252.539062 0)\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(1315.917969 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(1377.197266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1404.980469 0)\"/>\n     <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(1436.767578 0)\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(1506.591797 0)\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(1581.396484 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1656.201172 0)\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 203.2 227.073125 \nL 477.621875 227.073125 \nQ 481.621875 227.073125 481.621875 223.073125 \nL 481.621875 166.360625 \nQ 481.621875 162.360625 477.621875 162.360625 \nL 203.2 162.360625 \nQ 199.2 162.360625 199.2 166.360625 \nL 199.2 223.073125 \nQ 199.2 227.073125 203.2 227.073125 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 207.2 178.5575 \nL 227.2 178.5575 \nL 247.2 178.5575 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_17\">\n     <!-- SO(2)-Steerable CNN -->\n     <g transform=\"translate(263.2 185.5575) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1225 4090 567 \nQ 3503 -91 2522 -91 \nQ 1538 -91 948 565 \nQ 359 1222 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-4f\" transform=\"translate(63.476562 0)\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(142.1875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(181.201172 0)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(244.824219 0)\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" transform=\"translate(283.837891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-53\" transform=\"translate(319.921875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(383.398438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(422.607422 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(484.130859 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(545.654297 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(586.767578 0)\"/>\n      <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(648.046875 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(711.523438 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(739.306641 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(800.830078 0)\"/>\n      <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(832.617188 0)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(902.441406 0)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(977.246094 0)\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 207.2 207.91375 \nL 227.2 207.91375 \nL 247.2 207.91375 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- Conventional CNN -->\n     <g transform=\"translate(263.2 214.91375) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(69.824219 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(131.005859 0)\"/>\n      <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(194.384766 0)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(253.564453 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(315.087891 0)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(378.466797 0)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(417.675781 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(445.458984 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(506.640625 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(570.019531 0)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(631.298828 0)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(659.082031 0)\"/>\n      <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(690.869141 0)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(760.693359 0)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(835.498047 0)\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6d5ca12045\">\n   <rect x=\"61.410938\" y=\"28.396875\" width=\"558\" height=\"332.64\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's generate a random image of shape W x W\n",
        "W = 37\n",
        "x = torch.randn(1, 1, W, W)\n",
        "\n",
        "# Because a rotation by an angle smaller than 90 degrees moves pixels outsize the image, we mask out all pixels outside the central disk\n",
        "# We need to do this both for the input and the output\n",
        "\n",
        "def build_mask(W):\n",
        "    center_mask = np.zeros((2, W, W))\n",
        "    center_mask[1, :, :] = np.arange(0, W) - W // 2\n",
        "    center_mask[0, :, :] = np.arange(0, W) - W // 2\n",
        "    center_mask[0, :, :] = center_mask[0, :, :].T\n",
        "    center_mask = center_mask[0, :, :] ** 2 + center_mask[1, :, :] ** 2 < .9*(W // 2) ** 2\n",
        "    center_mask = torch.tensor(center_mask.reshape(1, 1, W, W), dtype=torch.float)\n",
        "    return center_mask\n",
        "\n",
        "\n",
        "# create the mask for the input\n",
        "input_center_mask = build_mask(W)\n",
        "\n",
        "# mask the input image\n",
        "x = x * input_center_mask\n",
        "x = feat_type_in(x)\n",
        "\n",
        "# compute the output of both models\n",
        "y_equivariant = equivariant_so2_model(x)\n",
        "y_conventional = feat_type_out(conventional_model(x.tensor))\n",
        "\n",
        "# create the mask for the output images\n",
        "output_center_mask = build_mask(y_equivariant.shape[-1])\n",
        "\n",
        "# We evaluate the equivariance error on N=100 rotations\n",
        "N = 100\n",
        "\n",
        "error_equivariant = []\n",
        "error_conventional = []\n",
        "\n",
        "# for each of the N rotations\n",
        "for i in range(N+1):\n",
        "    g = G.element(i / N * 2*np.pi)\n",
        "\n",
        "    # rotate the input\n",
        "    x_transformed = x.transform(g)\n",
        "    x_transformed.tensor *= input_center_mask\n",
        "\n",
        "    # F(g.X)  feed the transformed images in both models\n",
        "    y_from_x_transformed_equivariant = equivariant_so2_model(x_transformed).tensor\n",
        "    y_from_x_transformed_conventional = conventional_model(x_transformed.tensor)\n",
        "\n",
        "    # g.F(x)  transform the output of both models\n",
        "    y_transformed_from_x_equivariant = y_equivariant.transform(g)\n",
        "    y_transformed_from_x_conventional = y_conventional.transform(g)\n",
        "\n",
        "    # mask all the outputs\n",
        "    y_from_x_transformed_equivariant = y_from_x_transformed_equivariant * output_center_mask\n",
        "    y_from_x_transformed_conventional = y_from_x_transformed_conventional * output_center_mask\n",
        "    y_transformed_from_x_equivariant = y_transformed_from_x_equivariant.tensor * output_center_mask\n",
        "    y_transformed_from_x_conventional = y_transformed_from_x_conventional.tensor * output_center_mask\n",
        "\n",
        "    # compute the relative error of both models\n",
        "    rel_error_equivariant = torch.norm(y_from_x_transformed_equivariant - y_transformed_from_x_equivariant).item() / torch.norm(y_equivariant.tensor).item()\n",
        "    rel_error_conventional = torch.norm(y_from_x_transformed_conventional - y_transformed_from_x_conventional).item() / torch.norm(y_conventional.tensor).item()\n",
        "\n",
        "    error_equivariant.append(rel_error_equivariant)\n",
        "    error_conventional.append(rel_error_conventional)\n",
        "\n",
        "# plot the error of both models as a function of the rotation angle theta\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "xs = [i*2*np.pi / N for i in range(N+1)]\n",
        "plt.plot(xs, error_equivariant, label='SO(2)-Steerable CNN')\n",
        "plt.plot(xs, error_conventional, label='Conventional CNN')\n",
        "plt.title('Equivariant vs Conventional CNNs', fontsize=20)\n",
        "plt.xlabel(r'$g = r_\\theta$', fontsize=20)\n",
        "plt.ylabel('Equivariance Error', fontsize=20)\n",
        "ax.tick_params(axis='both', which='major', labelsize=15)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K0Lti6wBLR5"
      },
      "source": [
        "## 3. Build and Train Steerable CNNs\n",
        "\n",
        "Finally, we will proceed with implementing a **Steerable CNN** and train it on rotated MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbXKvGZM7sUI"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BJSa9iJ4LF5"
      },
      "source": [
        "We will evaluate the model on the *rotated* MNIST dataset.\n",
        "First, we download the (non-rotated) MNIST 12k data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ZLHXlWCLBZ_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64b5ab3-311f-44ee-829f-0cdeea03edb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-11 02:57:31--  http://www.iro.umontreal.ca/~lisa/icml2007data/mnist.zip\n",
            "Resolving www.iro.umontreal.ca (www.iro.umontreal.ca)... 132.204.26.36\n",
            "Connecting to www.iro.umontreal.ca (www.iro.umontreal.ca)|132.204.26.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23653151 (23M) [application/zip]\n",
            "Saving to: ‘mnist.zip’\n",
            "\n",
            "mnist.zip           100%[===================>]  22.56M  31.1MB/s    in 0.7s    \n",
            "\n",
            "2025-01-11 02:57:32 (31.1 MB/s) - ‘mnist.zip’ saved [23653151/23653151]\n",
            "\n",
            "Archive:  mnist.zip\n",
            "  inflating: mnist/mnist_train.amat  \n",
            "  inflating: mnist/mnist_test.amat   \n"
          ]
        }
      ],
      "source": [
        "# download the dataset\n",
        "!wget -nc http://www.iro.umontreal.ca/~lisa/icml2007data/mnist.zip\n",
        "# uncompress the zip file\n",
        "!unzip -n mnist.zip -d mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk4AEOO44Tcf"
      },
      "source": [
        "Then, we build the dataset and some utility functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "rFflGaisdyaN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import RandomRotation\n",
        "from torchvision.transforms import Pad\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "ZjV8iksl5RPH"
      },
      "outputs": [],
      "source": [
        "class MnistDataset(Dataset):\n",
        "\n",
        "    def __init__(self, mode, rotated: bool = True):\n",
        "        assert mode in ['train', 'test']\n",
        "\n",
        "        if mode == \"train\":\n",
        "            file = \"mnist/mnist_train.amat\"\n",
        "        else:\n",
        "            file = \"mnist/mnist_test.amat\"\n",
        "\n",
        "        data = np.loadtxt(file)\n",
        "\n",
        "        images = data[:, :-1].reshape(-1, 28, 28).astype(np.float32)\n",
        "\n",
        "        # images are padded to have shape 29x29.\n",
        "        # this allows to use odd-size filters with stride 2 when downsampling a feature map in the model\n",
        "        pad = Pad((0, 0, 1, 1), fill=0)\n",
        "\n",
        "        # to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
        "        # we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
        "        resize1 = Resize(87) # to upsample\n",
        "        resize2 = Resize(29) # to downsample\n",
        "\n",
        "        totensor = ToTensor()\n",
        "\n",
        "        if rotated:\n",
        "            self.images = torch.empty((images.shape[0], 1, 29, 29))\n",
        "            for i in tqdm(range(images.shape[0]), leave=False):\n",
        "                img = images[i]\n",
        "                img = Image.fromarray(img, mode='F')\n",
        "                r = (np.random.rand() * 360.)\n",
        "                self.images[i] = totensor(resize2(resize1(pad(img)).rotate(r, Image.BILINEAR))).reshape(1, 29, 29)\n",
        "        else:\n",
        "            self.images = torch.zeros((images.shape[0], 1, 29, 29))\n",
        "            self.images[:, :, :28, :28] = torch.tensor(images).reshape(-1, 1, 28, 28)\n",
        "\n",
        "        self.labels = data[:, -1].astype(np.int64)\n",
        "        self.num_samples = len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.images[index], self.labels[index]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "WlLm-AZ97jVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "d365a9a40ece474d90afe8bc1fe3761c",
            "a12471c29ecd43c0a3e2e657fa05104c",
            "cf6c09575b6140d0a38cfa029bc1a666",
            "31fe5b2895504e90b15f08d2c74a5746",
            "d8a199945b2249eab713edb092b0fd58",
            "2444d2eb35984110bad40401b85bf640",
            "405008bf2b3849e28572d02b8bd503ad",
            "3b852af6ba354a9cb1991fbf58b17256",
            "5a75ac61a83946039ea1bc87367d2c2d",
            "55a2aea488ed4abd89300e86e6872c92",
            "f019215c7e804eca99130532047e2111",
            "8e539dcd2fcf41aa8618adfda993084f",
            "9e7b4b20db28460596bb228db8d6a2c1",
            "0909b4e5376d4ccb8c648a1dc67b7fb3",
            "29bc4706a385449a9f6fd75a781f3774",
            "76b6772a67ca483ab4667eeffe3859db",
            "7ffadd40b1ff475793fe1f5408ec4331",
            "058214c8b9a04a6ebc209325df7c1bc1",
            "54d836e4d5964c7fa3742f68508befde",
            "eb2ef96bd7544534a1abf0de1be5cbb0",
            "0235b5e57d5d4b68944dd2ba4c9e0fd7",
            "7ae838986d9c459097851b5b119af937"
          ]
        },
        "outputId": "59bf345d-04e2-4b3b-8274-7108c4b30bd8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d365a9a40ece474d90afe8bc1fe3761c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e539dcd2fcf41aa8618adfda993084f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# build the rotated training and test datasets\n",
        "mnist_train = MnistDataset(mode='train', rotated=True)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
        "\n",
        "\n",
        "mnist_test = MnistDataset(mode='test', rotated=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=64)\n",
        "\n",
        "# for testing purpose, we also build a version of the test set with *non*-rotated digits\n",
        "raw_mnist_test = MnistDataset(mode='test', rotated=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNhKgypl7m0b"
      },
      "source": [
        "### $SO(2)$ equivariant architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABvLAScf5RPI"
      },
      "source": [
        "We now build an $SO(2)$ equivariant CNN.\n",
        "\n",
        "Because the inputs are still gray-scale images, the input type of the model is again a *scalar field*.\n",
        "In the intermidiate layers, we will use *regular fields*, such that the models are equivalent to *group-equivariant convolutional neural networks* (GCNNs).\n",
        "\n",
        "The final classification is performed by a fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "HuVS40JWzihp"
      },
      "outputs": [],
      "source": [
        "class SO2SteerableCNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes=10):\n",
        "\n",
        "        super(SO2SteerableCNN, self).__init__()\n",
        "\n",
        "        # the model is equivariant under all planar rotations\n",
        "        self.r2_act = gspaces.rot2dOnR2(N=-1)\n",
        "\n",
        "        # the group SO(2)\n",
        "        self.G: SO2 = self.r2_act.fibergroup\n",
        "\n",
        "        # the input image is a scalar field, corresponding to the trivial representation\n",
        "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
        "\n",
        "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
        "        self.input_type = in_type\n",
        "\n",
        "        # We need to mask the input image since the corners are moved outside the grid under rotations\n",
        "        self.mask = nn.MaskModule(in_type, 29, margin=1)\n",
        "\n",
        "        # convolution 1\n",
        "        # first we build the non-linear layer, which also constructs the right feature type\n",
        "        # we choose 8 feature fields, each transforming under the regular representation of SO(2) up to frequency 3\n",
        "        # When taking the ELU non-linearity, we sample the feature fields on N=16 points\n",
        "        activation1 = nn.FourierELU(self.r2_act, 8, irreps=G.bl_irreps(3), N=16, inplace=True)\n",
        "        out_type = activation1.in_type\n",
        "        self.block1 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation1,\n",
        "        )\n",
        "\n",
        "        # convolution 2\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block1.out_type\n",
        "        # the output type of the second convolution layer are 16 regular feature fields\n",
        "        activation2 = nn.FourierELU(self.r2_act, 16, irreps=G.bl_irreps(3), N=16, inplace=True)\n",
        "        out_type = activation2.in_type\n",
        "        self.block2 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation2\n",
        "        )\n",
        "        # to reduce the downsampling artifacts, we use a Gaussian smoothing filter\n",
        "        self.pool1 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 3\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block2.out_type\n",
        "        # the output type of the third convolution layer are 32 regular feature fields\n",
        "        activation3 = nn.FourierELU(self.r2_act, 32, irreps=G.bl_irreps(3), N=16, inplace=True)\n",
        "        out_type = activation3.in_type\n",
        "        self.block3 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation3\n",
        "        )\n",
        "\n",
        "        # convolution 4\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block3.out_type\n",
        "        # the output type of the fourth convolution layer are 64 regular feature fields\n",
        "        activation4 = nn.FourierELU(self.r2_act, 32, irreps=G.bl_irreps(3), N=16, inplace=True)\n",
        "        out_type = activation4.in_type\n",
        "        self.block4 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation4\n",
        "        )\n",
        "        self.pool2 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 5\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block4.out_type\n",
        "        # the output type of the fifth convolution layer are 96 regular feature fields\n",
        "        activation5 = nn.FourierELU(self.r2_act, 64, irreps=G.bl_irreps(3), N=16, inplace=True)\n",
        "        out_type = activation5.in_type\n",
        "        self.block5 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation5\n",
        "        )\n",
        "\n",
        "        # convolution 6\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block5.out_type\n",
        "        # the output type of the sixth convolution layer are 64 regular feature fields\n",
        "        activation6 = nn.FourierELU(self.r2_act, 64, irreps=G.bl_irreps(3), N=16, inplace=True)\n",
        "        out_type = activation6.in_type\n",
        "        self.block6 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation6\n",
        "        )\n",
        "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
        "\n",
        "        # number of output invariant channels\n",
        "        c = 64\n",
        "\n",
        "        # last 1x1 convolution layer, which maps the regular fields to c=64 invariant scalar fields\n",
        "        # this is essential to provide *invariant* features in the final classification layer\n",
        "        output_invariant_type = nn.FieldType(self.r2_act, c*[self.r2_act.trivial_repr])\n",
        "        self.invariant_map = nn.R2Conv(out_type, output_invariant_type, kernel_size=1, bias=False)\n",
        "\n",
        "        # Fully Connected classifier\n",
        "        self.fully_net = torch.nn.Sequential(\n",
        "            torch.nn.BatchNorm1d(c),\n",
        "            torch.nn.ELU(inplace=True),\n",
        "            torch.nn.Linear(c, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor):\n",
        "        # wrap the input tensor in a GeometricTensor\n",
        "        # (associate it with the input type)\n",
        "        x = self.input_type(input)\n",
        "\n",
        "        # mask out the corners of the input image\n",
        "        x = self.mask(x)\n",
        "\n",
        "        # apply each equivariant block\n",
        "\n",
        "        # Each layer has an input and an output type\n",
        "        # A layer takes a GeometricTensor in input.\n",
        "        # This tensor needs to be associated with the same representation of the layer's input type\n",
        "        #\n",
        "        # Each layer outputs a new GeometricTensor, associated with the layer's output type.\n",
        "        # As a result, consecutive layers need to have matching input/output types\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "\n",
        "        # pool over the spatial dimensions\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # extract invariant features\n",
        "        x = self.invariant_map(x)\n",
        "\n",
        "        # unwrap the output GeometricTensor\n",
        "        # (take the Pytorch tensor and discard the associated representation)\n",
        "        x = x.tensor\n",
        "\n",
        "        # classify with the final fully connected layer\n",
        "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnv21BvS70rR"
      },
      "source": [
        "#### Equivariance Test before training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isQ_WYax43Ih"
      },
      "source": [
        "Let's instantiate the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "NjDhOs_048O6"
      },
      "outputs": [],
      "source": [
        "model = SO2SteerableCNN().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqmtMCdh5HVq"
      },
      "source": [
        "The model is now randomly initialized.\n",
        "Therefore, we do not expect it to produce the right class probabilities.\n",
        "\n",
        "However, the model should still produce the same output for rotated versions of the same image.\n",
        "This is true for rotations by multiples of $\\frac{\\pi}{2}$, but is only approximate for other rotations.\n",
        "\n",
        "Let's test it on a random test image:\n",
        "we feed $N=20$ rotated versions of the first image in the test set and print the output logits of the model for each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "0sO8ACqbd_GW"
      },
      "outputs": [],
      "source": [
        "def test_model_single_image(model: torch.nn.Module, x: torch.Tensor, N: int = 8):\n",
        "    np.set_printoptions(linewidth=10000)\n",
        "\n",
        "    x = Image.fromarray(x.cpu().numpy()[0], mode='F')\n",
        "\n",
        "\n",
        "    # to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
        "    # we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
        "    resize1 = Resize(87) # to upsample\n",
        "    resize2 = Resize(29) # to downsample\n",
        "\n",
        "    totensor = ToTensor()\n",
        "\n",
        "    x = resize1(x)\n",
        "\n",
        "    # evaluate the `model` on N rotated versions of the input image `x`\n",
        "    model.eval()\n",
        "\n",
        "    print()\n",
        "    print('##########################################################################################')\n",
        "    header = 'angle  |  ' + '  '.join([\"{:5d}\".format(d) for d in range(10)])\n",
        "    print(header)\n",
        "    with torch.no_grad():\n",
        "        for r in range(N):\n",
        "            x_transformed = totensor(resize2(x.rotate(r*360./N, Image.BILINEAR))).reshape(1, 1, 29, 29)\n",
        "            x_transformed = x_transformed.to(device)\n",
        "\n",
        "            y = model(x_transformed)\n",
        "            y = y.to('cpu').numpy().squeeze()\n",
        "\n",
        "            angle = r * 360. / N\n",
        "            print(\"{:6.1f} : {}\".format(angle, y))\n",
        "    print('##########################################################################################')\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "MMemwcjceUWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ea8cf4-80ac-4374-e698-624fa2c17789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "##########################################################################################\n",
            "angle  |      0      1      2      3      4      5      6      7      8      9\n",
            "   0.0 : [-1.076 -0.62  -1.284  1.256 -0.875  0.541 -0.128  1.157 -2.592 -0.795]\n",
            "  18.0 : [-1.087 -0.635 -1.294  1.257 -0.878  0.553 -0.098  1.15  -2.587 -0.804]\n",
            "  36.0 : [-1.09  -0.631 -1.309  1.243 -0.901  0.564 -0.101  1.152 -2.61  -0.814]\n",
            "  54.0 : [-1.082 -0.614 -1.314  1.257 -0.893  0.566 -0.133  1.157 -2.626 -0.798]\n",
            "  72.0 : [-1.081 -0.615 -1.299  1.259 -0.887  0.555 -0.129  1.156 -2.627 -0.798]\n",
            "  90.0 : [-1.076 -0.62  -1.284  1.256 -0.875  0.541 -0.128  1.157 -2.592 -0.795]\n",
            " 108.0 : [-1.087 -0.635 -1.294  1.257 -0.878  0.553 -0.098  1.15  -2.587 -0.804]\n",
            " 126.0 : [-1.09  -0.631 -1.309  1.243 -0.901  0.564 -0.101  1.152 -2.61  -0.814]\n",
            " 144.0 : [-1.082 -0.614 -1.314  1.257 -0.893  0.566 -0.133  1.157 -2.626 -0.798]\n",
            " 162.0 : [-1.081 -0.615 -1.299  1.259 -0.887  0.555 -0.129  1.156 -2.627 -0.798]\n",
            " 180.0 : [-1.076 -0.62  -1.284  1.256 -0.875  0.541 -0.128  1.157 -2.592 -0.795]\n",
            " 198.0 : [-1.087 -0.635 -1.294  1.257 -0.878  0.553 -0.098  1.15  -2.587 -0.804]\n",
            " 216.0 : [-1.09  -0.631 -1.309  1.243 -0.901  0.564 -0.101  1.152 -2.61  -0.814]\n",
            " 234.0 : [-1.082 -0.614 -1.314  1.257 -0.893  0.566 -0.133  1.157 -2.626 -0.798]\n",
            " 252.0 : [-1.081 -0.615 -1.299  1.259 -0.887  0.555 -0.129  1.156 -2.627 -0.798]\n",
            " 270.0 : [-1.076 -0.62  -1.284  1.256 -0.875  0.541 -0.128  1.157 -2.592 -0.795]\n",
            " 288.0 : [-1.087 -0.635 -1.294  1.257 -0.878  0.553 -0.098  1.15  -2.587 -0.804]\n",
            " 306.0 : [-1.09  -0.631 -1.309  1.243 -0.901  0.564 -0.101  1.152 -2.61  -0.814]\n",
            " 324.0 : [-1.082 -0.614 -1.314  1.257 -0.893  0.566 -0.133  1.157 -2.626 -0.798]\n",
            " 342.0 : [-1.081 -0.615 -1.299  1.259 -0.887  0.555 -0.129  1.156 -2.627 -0.798]\n",
            "##########################################################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# retrieve the first image from the test set\n",
        "x, y = next(iter(raw_mnist_test))\n",
        "\n",
        "# evaluate the model\n",
        "test_model_single_image(model, x, N=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30uH1m-7S63"
      },
      "source": [
        "The output of the model is already almost invariant but we observe small fluctuations in the outputs.\n",
        "This is the effect of the discretization artifacts (e.g. the pixel grid can not be perfectly rotated by any angle without interpolation) and can not be completely removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLoknbhP77Ps"
      },
      "source": [
        "#### Training the model\n",
        "Let's train the model now.\n",
        "The procedure is the same used to train a normal *PyTorch* architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dahlyjtr8RgX"
      },
      "outputs": [],
      "source": [
        "# build the training and test function\n",
        "\n",
        "def test(model: torch.nn.Module):\n",
        "    # test over the full rotated test set\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i, (x, t) in enumerate(test_loader):\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "\n",
        "            y = model(x)\n",
        "\n",
        "            _, prediction = torch.max(y.data, 1)\n",
        "            total += t.shape[0]\n",
        "            correct += (prediction == t).sum().item()\n",
        "    return correct/total*100.\n",
        "\n",
        "\n",
        "def train(model: torch.nn.Module, lr=1e-4, wd=1e-4, checkpoint_path: str = None):\n",
        "    if checkpoint_path is not None:\n",
        "        checkpoint_path = os.path.join(CHECKPOINT_PATH, checkpoint_path)\n",
        "\n",
        "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "        model.eval()\n",
        "        return\n",
        "\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    for epoch in tqdm(range(21)):\n",
        "        model.train()\n",
        "        for i, (x, t) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "\n",
        "            y = model(x)\n",
        "\n",
        "            loss = loss_function(y, t)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            del x, y, t, loss\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            accuracy = test(model)\n",
        "            print(f\"epoch {epoch} | test accuracy: {accuracy}\")\n",
        "\n",
        "    if checkpoint_path is not None:\n",
        "        torch.save(model.state_dict(), checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kLJO_KQ8opD"
      },
      "source": [
        "Finally, train the $SO(2)$ equivariant model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03IyIZpO8kmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab4e95c-5040-4611-cae5-11c1b56fc11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-95-9e1816a8ca25>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 94.982\n"
          ]
        }
      ],
      "source": [
        "# set the seed manually for reproducibility\n",
        "torch.manual_seed(42)\n",
        "model = SO2SteerableCNN().to(device)\n",
        "\n",
        "train(model, checkpoint_path=\"steerable_so2-pretrained.ckpt\")\n",
        "\n",
        "accuracy = test(model)\n",
        "print(f\"Test accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXeaZPTqECzY"
      },
      "outputs": [],
      "source": [
        "def test_model_rotations(model: torch.nn.Module, N: int = 24, M: int = 2000, checkpoint_path: str = None):\n",
        "    # evaluate the `model` on N rotated versions of the first M images in the test set\n",
        "\n",
        "    if checkpoint_path is not None:\n",
        "        checkpoint_path = os.path.join(CHECKPOINT_PATH, checkpoint_path)\n",
        "\n",
        "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
        "        accuracies = np.load(checkpoint_path)\n",
        "        return accuracies.tolist()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
        "    # we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
        "    resize1 = Resize(87) # to upsample\n",
        "    resize2 = Resize(29) # to downsample\n",
        "\n",
        "    totensor = ToTensor()\n",
        "\n",
        "    accuracies = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        for r in tqdm(range(N)):\n",
        "            total = 0\n",
        "            correct = 0\n",
        "\n",
        "            for i in range(M):\n",
        "                x, t = raw_mnist_test[i]\n",
        "\n",
        "                x = Image.fromarray(x.numpy()[0], mode='F')\n",
        "\n",
        "                x = totensor(resize2(resize1(x).rotate(r*360./N, Image.BILINEAR))).reshape(1, 1, 29, 29).to(device)\n",
        "\n",
        "                x = x.to(device)\n",
        "\n",
        "                y = model(x)\n",
        "\n",
        "                _, prediction = torch.max(y.data, 1)\n",
        "                total += 1\n",
        "                correct += (prediction == t).sum().item()\n",
        "\n",
        "            accuracies.append(correct/total*100.)\n",
        "\n",
        "    if checkpoint_path is not None:\n",
        "        np.save(checkpoint_path, np.array(accuracies))\n",
        "\n",
        "    return accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_ueYqe75RPK"
      },
      "outputs": [],
      "source": [
        "accs_so2 = test_model_rotations(model, 16, 10000, checkpoint_path=\"steerable_so2-accuracies.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSX5e3_V5RPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "6987ba80-3d88-44ba-e450-f11c63aca93c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"645.698437pt\" height=\"413.110312pt\" viewBox=\"0 0 645.698437 413.110312\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-01-09T12:22:39.739321</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 413.110312 \nL 645.698437 413.110312 \nL 645.698437 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 80.498438 361.036875 \nL 638.498438 361.036875 \nL 638.498438 28.396875 \nL 80.498438 28.396875 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m3ca4c344df\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"105.862074\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(101.090199 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"186.597036\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(181.825161 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"267.331998\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(262.560123 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"348.06696\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(343.295085 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"428.801922\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(424.030047 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"509.536884\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(504.765009 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m3ca4c344df\" x=\"590.271846\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(585.499971 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Test rotation $\\theta \\in [0, 2\\pi)$ -->\n     <g transform=\"translate(241.898438 401.750937) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-Oblique-3b8\" d=\"M 2913 2219 \nL 925 2219 \nQ 791 1284 928 888 \nQ 1100 400 1566 400 \nQ 2034 400 2391 891 \nQ 2703 1322 2913 2219 \nz\nM 3009 2750 \nQ 3094 3638 2984 3950 \nQ 2813 4444 2353 4444 \nQ 1875 4444 1525 3956 \nQ 1250 3563 1034 2750 \nL 3009 2750 \nz\nM 2444 4913 \nQ 3194 4913 3494 4250 \nQ 3794 3591 3566 2422 \nQ 3341 1256 2781 594 \nQ 2225 -72 1475 -72 \nQ 722 -72 425 594 \nQ 128 1256 353 2422 \nQ 581 3591 1134 4250 \nQ 1691 4913 2444 4913 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2208\" d=\"M 1072 1959 \nQ 1094 1728 1291 1353 \nQ 1522 919 1959 675 \nQ 2388 438 2850 434 \nL 5028 434 \nL 5028 -63 \nL 2850 -63 \nQ 2250 -63 1695 246 \nQ 1141 556 844 1106 \nQ 547 1656 547 2241 \nQ 547 2819 844 3369 \nQ 1141 3919 1695 4231 \nQ 2250 4544 2850 4544 \nL 5028 4544 \nL 5028 4047 \nL 2850 4047 \nQ 2388 4044 1959 3803 \nQ 1525 3556 1291 3125 \nQ 1091 2750 1063 2459 \nL 5028 2459 \nL 5028 1959 \nL 1072 1959 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \nL 1875 4863 \nL 1875 4416 \nL 1125 4416 \nL 1125 -397 \nL 1875 -397 \nL 1875 -844 \nL 550 -844 \nL 550 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-Oblique-3c0\" d=\"M 584 3500 \nL 3938 3500 \nL 3825 2925 \nL 3384 2925 \nL 2966 775 \nQ 2922 550 2981 450 \nQ 3038 353 3209 353 \nQ 3256 353 3325 363 \nQ 3397 369 3419 372 \nL 3338 -44 \nQ 3222 -84 3103 -103 \nQ 2981 -122 2866 -122 \nQ 2491 -122 2388 81 \nQ 2284 288 2391 838 \nL 2797 2925 \nL 1506 2925 \nL 938 0 \nL 350 0 \nL 919 2925 \nL 472 2925 \nL 584 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\" transform=\"translate(0 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(61.083984 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(122.607422 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(174.707031 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(213.916016 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(245.703125 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(286.816406 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(347.998047 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(387.207031 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(448.486328 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(487.695312 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(515.478516 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(576.660156 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(640.039062 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(671.826172 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-2208\" transform=\"translate(752.490234 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-5b\" transform=\"translate(859.082031 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(898.095703 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(961.71875 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(1012.988281 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-3c0\" transform=\"translate(1076.611328 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(1136.816406 0.234375)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m85286566c3\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"345.916875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 95.20 -->\n      <g transform=\"translate(30.55625 351.615703) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"295.516875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 95.25 -->\n      <g transform=\"translate(30.55625 301.215703) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"245.116875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 95.30 -->\n      <g transform=\"translate(30.55625 250.815703) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"194.716875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 95.35 -->\n      <g transform=\"translate(30.55625 200.415703) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"144.316875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 95.40 -->\n      <g transform=\"translate(30.55625 150.015703) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"93.916875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 95.45 -->\n      <g transform=\"translate(30.55625 99.615703) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m85286566c3\" x=\"80.498438\" y=\"43.516875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 95.50 -->\n      <g transform=\"translate(30.55625 49.215703) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(222.65625 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Accuracy -->\n     <g transform=\"translate(22.396875 240.373125) rotate(-90) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(66.658203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(121.638672 0)\"/>\n      <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(176.619141 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(239.998047 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(281.111328 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(342.390625 0)\"/>\n      <use xlink:href=\"#DejaVuSans-79\" transform=\"translate(397.371094 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 105.862074 93.916875 \nL 137.566619 335.836875 \nL 169.271165 335.836875 \nL 200.97571 43.516875 \nL 232.680256 93.916875 \nL 264.384801 335.836875 \nL 296.089347 335.836875 \nL 327.793892 43.516875 \nL 359.498438 93.916875 \nL 391.202983 345.916875 \nL 422.907528 335.836875 \nL 454.612074 43.516875 \nL 486.316619 93.916875 \nL 518.021165 335.836875 \nL 549.72571 335.836875 \nL 581.430256 43.516875 \nL 613.134801 93.916875 \n\" clip-path=\"url(#p71b5e61442)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 80.498438 361.036875 \nL 80.498438 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 638.498438 361.036875 \nL 638.498438 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 80.498438 361.036875 \nL 638.498438 361.036875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 80.498438 28.396875 \nL 638.498438 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- SO(2)-Steerable CNN -->\n    <g transform=\"translate(254.2875 22.396875) scale(0.2 -0.2)\">\n     <defs>\n      <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1225 4090 567 \nQ 3503 -91 2522 -91 \nQ 1538 -91 948 565 \nQ 359 1222 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-53\"/>\n     <use xlink:href=\"#DejaVuSans-4f\" transform=\"translate(63.476562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(142.1875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(181.201172 0)\"/>\n     <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(244.824219 0)\"/>\n     <use xlink:href=\"#DejaVuSans-2d\" transform=\"translate(283.837891 0)\"/>\n     <use xlink:href=\"#DejaVuSans-53\" transform=\"translate(319.921875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(383.398438 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(422.607422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(484.130859 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(545.654297 0)\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(586.767578 0)\"/>\n     <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(648.046875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(711.523438 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(739.306641 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(800.830078 0)\"/>\n     <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(832.617188 0)\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(902.441406 0)\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(977.246094 0)\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p71b5e61442\">\n   <rect x=\"80.498438\" y=\"28.396875\" width=\"558\" height=\"332.64\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot the accuracy of as a function of the rotation angle theta applied to the test set\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "N = 16\n",
        "\n",
        "xs = [i*2*np.pi / N for i in range(N+1)]\n",
        "plt.plot(xs, accs_so2 + [accs_so2[0]])\n",
        "plt.title('SO(2)-Steerable CNN', fontsize=20)\n",
        "plt.xlabel(r'Test rotation $\\theta \\in [0, 2\\pi)$', fontsize=20)\n",
        "plt.ylabel('Accuracy', fontsize=20)\n",
        "ax.tick_params(axis='both', which='major', labelsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po0O4I595RPK"
      },
      "source": [
        "Even after training, the model is not perfectly $SO(2)$ equivariant, but we observe the accuracy is rather stable to rotations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WWv780dC5_R"
      },
      "source": [
        "#### $C_4$ equivariant architecture\n",
        "\n",
        "For comparison, let's build a similar architecture equivariant only to $N=4$ rotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g17NYfmdDC57"
      },
      "outputs": [],
      "source": [
        "class CNSteerableCNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes=10):\n",
        "\n",
        "        super(CNSteerableCNN, self).__init__()\n",
        "\n",
        "        # the model is equivariant to rotations by multiples of 2pi/N\n",
        "        self.r2_act = gspaces.rot2dOnR2(N=4)\n",
        "\n",
        "        # the input image is a scalar field, corresponding to the trivial representation\n",
        "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
        "\n",
        "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
        "        self.input_type = in_type\n",
        "\n",
        "        # We need to mask the input image since the corners are moved outside the grid under rotations\n",
        "        self.mask = nn.MaskModule(in_type, 29, margin=1)\n",
        "\n",
        "        # convolution 1\n",
        "        # first we build the non-linear layer, which also constructs the right feature type\n",
        "        # we choose 8 feature fields, each transforming under the regular representation of C_4\n",
        "        activation1 = nn.ELU(nn.FieldType(self.r2_act, 8*[self.r2_act.regular_repr]), inplace=True)\n",
        "        out_type = activation1.in_type\n",
        "        self.block1 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation1,\n",
        "        )\n",
        "\n",
        "        # convolution 2\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block1.out_type\n",
        "        # the output type of the second convolution layer are 16 regular feature fields\n",
        "        activation2 = nn.ELU(nn.FieldType(self.r2_act, 16*[self.r2_act.regular_repr]), inplace=True)\n",
        "        out_type = activation2.in_type\n",
        "        self.block2 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation2\n",
        "        )\n",
        "        self.pool1 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 3\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block2.out_type\n",
        "        # the output type of the third convolution layer are 32 regular feature fields\n",
        "        activation3 = nn.ELU(nn.FieldType(self.r2_act, 32*[self.r2_act.regular_repr]), inplace=True)\n",
        "        out_type = activation3.in_type\n",
        "        self.block3 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation3\n",
        "        )\n",
        "\n",
        "        # convolution 4\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block3.out_type\n",
        "        # the output type of the fourth convolution layer are 32 regular feature fields\n",
        "        activation4 = nn.ELU(nn.FieldType(self.r2_act, 32*[self.r2_act.regular_repr]), inplace=True)\n",
        "        out_type = activation4.in_type\n",
        "        self.block4 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation4\n",
        "        )\n",
        "        self.pool2 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 5\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block4.out_type\n",
        "        # the output type of the fifth convolution layer are 64 regular feature fields\n",
        "        activation5 = nn.ELU(nn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr]), inplace=True)\n",
        "        out_type = activation5.in_type\n",
        "        self.block5 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation5\n",
        "        )\n",
        "\n",
        "        # convolution 6\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block5.out_type\n",
        "        # the output type of the sixth convolution layer are 64 regular feature fields\n",
        "        activation6 = nn.ELU(nn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr]), inplace=True)\n",
        "        out_type = activation6.in_type\n",
        "        self.block6 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
        "            nn.IIDBatchNorm2d(out_type),\n",
        "            activation6\n",
        "        )\n",
        "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
        "\n",
        "        # number of output invariant channels\n",
        "        c = 64\n",
        "\n",
        "        output_invariant_type = nn.FieldType(self.r2_act, c*[self.r2_act.trivial_repr])\n",
        "        self.invariant_map = nn.R2Conv(out_type, output_invariant_type, kernel_size=1, bias=False)\n",
        "\n",
        "\n",
        "        # Fully Connected classifier\n",
        "        self.fully_net = torch.nn.Sequential(\n",
        "            torch.nn.BatchNorm1d(c),\n",
        "            torch.nn.ELU(inplace=True),\n",
        "            torch.nn.Linear(c, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor):\n",
        "        # wrap the input tensor in a GeometricTensor\n",
        "        # (associate it with the input type)\n",
        "        x = self.input_type(input)\n",
        "\n",
        "        # mask out the corners of the input image\n",
        "        x = self.mask(x)\n",
        "\n",
        "        # apply each equivariant block\n",
        "\n",
        "        # Each layer has an input and an output type\n",
        "        # A layer takes a GeometricTensor in input.\n",
        "        # This tensor needs to be associated with the same representation of the layer's input type\n",
        "        #\n",
        "        # Each layer outputs a new GeometricTensor, associated with the layer's output type.\n",
        "        # As a result, consecutive layers need to have matching input/output types\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "\n",
        "        # pool over the spatial dimensions\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # extract invariant features\n",
        "        x = self.invariant_map(x)\n",
        "\n",
        "        # unwrap the output GeometricTensor\n",
        "        # (take the Pytorch tensor and discard the associated representation)\n",
        "        x = x.tensor\n",
        "\n",
        "        # classify with the final fully connected layer\n",
        "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsF8NPOH5RPK"
      },
      "source": [
        "Instantiate and train the $C_4$ equivariant model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "E1UoNiz_5RPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a1b985-981b-40df-bf9c-412c87be6dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-95-9e1816a8ca25>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 93.84400000000001\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "model_c4 = CNSteerableCNN().to(device)\n",
        "train(model_c4, checkpoint_path=\"steerable_c4-pretrained.ckpt\")\n",
        "\n",
        "accuracy = test(model_c4)\n",
        "print(f\"Test accuracy: {accuracy}\")\n",
        "\n",
        "accs_c4 = test_model_rotations(model_c4, 16, 10000, checkpoint_path=\"steerable_c4-accuracies.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5luJIPK5RPL"
      },
      "source": [
        "Finally, let's compare the performance of both models on the rotated test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIq620ZT5RPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "1ab1513b-14fe-447e-8049-b1cb9c0ed6c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"636.154687pt\" height=\"413.110312pt\" viewBox=\"0 0 636.154687 413.110312\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-01-09T12:23:34.817101</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 413.110312 \nL 636.154687 413.110312 \nL 636.154687 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 70.954688 361.036875 \nL 628.954687 361.036875 \nL 628.954687 28.396875 \nL 70.954688 28.396875 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mc4111c3882\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"96.318324\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(91.546449 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"177.053286\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(172.281411 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"257.788248\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(253.016373 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"338.52321\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(333.751335 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"419.258172\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(414.486297 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"499.993134\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <g transform=\"translate(495.221259 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#mc4111c3882\" x=\"580.728096\" y=\"361.036875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(575.956221 379.434531) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Test rotation ($\\theta \\in [0, 2\\pi)$) -->\n     <g transform=\"translate(224.554687 401.750937) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-Oblique-3b8\" d=\"M 2913 2219 \nL 925 2219 \nQ 791 1284 928 888 \nQ 1100 400 1566 400 \nQ 2034 400 2391 891 \nQ 2703 1322 2913 2219 \nz\nM 3009 2750 \nQ 3094 3638 2984 3950 \nQ 2813 4444 2353 4444 \nQ 1875 4444 1525 3956 \nQ 1250 3563 1034 2750 \nL 3009 2750 \nz\nM 2444 4913 \nQ 3194 4913 3494 4250 \nQ 3794 3591 3566 2422 \nQ 3341 1256 2781 594 \nQ 2225 -72 1475 -72 \nQ 722 -72 425 594 \nQ 128 1256 353 2422 \nQ 581 3591 1134 4250 \nQ 1691 4913 2444 4913 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2208\" d=\"M 1072 1959 \nQ 1094 1728 1291 1353 \nQ 1522 919 1959 675 \nQ 2388 438 2850 434 \nL 5028 434 \nL 5028 -63 \nL 2850 -63 \nQ 2250 -63 1695 246 \nQ 1141 556 844 1106 \nQ 547 1656 547 2241 \nQ 547 2819 844 3369 \nQ 1141 3919 1695 4231 \nQ 2250 4544 2850 4544 \nL 5028 4544 \nL 5028 4047 \nL 2850 4047 \nQ 2388 4044 1959 3803 \nQ 1525 3556 1291 3125 \nQ 1091 2750 1063 2459 \nL 5028 2459 \nL 5028 1959 \nL 1072 1959 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \nL 1875 4863 \nL 1875 4416 \nL 1125 4416 \nL 1125 -397 \nL 1875 -397 \nL 1875 -844 \nL 550 -844 \nL 550 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \nL 1409 794 \nL 1409 256 \nL 897 -744 \nL 494 -744 \nL 750 256 \nL 750 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-Oblique-3c0\" d=\"M 584 3500 \nL 3938 3500 \nL 3825 2925 \nL 3384 2925 \nL 2966 775 \nQ 2922 550 2981 450 \nQ 3038 353 3209 353 \nQ 3256 353 3325 363 \nQ 3397 369 3419 372 \nL 3338 -44 \nQ 3222 -84 3103 -103 \nQ 2981 -122 2866 -122 \nQ 2491 -122 2388 81 \nQ 2284 288 2391 838 \nL 2797 2925 \nL 1506 2925 \nL 938 0 \nL 350 0 \nL 919 2925 \nL 472 2925 \nL 584 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\" transform=\"translate(0 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(61.083984 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(122.607422 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(174.707031 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(213.916016 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(245.703125 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(286.816406 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(347.998047 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(387.207031 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(448.486328 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(487.695312 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(515.478516 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(576.660156 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(640.039062 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(671.826172 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(710.839844 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-2208\" transform=\"translate(791.503906 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-5b\" transform=\"translate(898.095703 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(937.109375 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(1000.732422 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(1052.001953 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-3c0\" transform=\"translate(1115.625 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(1175.830078 0.234375)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(1214.84375 0.234375)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"mbdf8200426\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"325.256005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 94.0 -->\n      <g transform=\"translate(30.55625 330.954834) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"287.690788\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 94.2 -->\n      <g transform=\"translate(30.55625 293.389616) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"250.125571\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 94.4 -->\n      <g transform=\"translate(30.55625 255.824399) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"212.560353\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 94.6 -->\n      <g transform=\"translate(30.55625 218.259181) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"174.995136\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 94.8 -->\n      <g transform=\"translate(30.55625 180.693964) scale(0.15 -0.15)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-38\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"137.429918\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 95.0 -->\n      <g transform=\"translate(30.55625 143.128747) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"99.864701\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 95.2 -->\n      <g transform=\"translate(30.55625 105.563529) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#mbdf8200426\" x=\"70.954688\" y=\"62.299484\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 95.4 -->\n      <g transform=\"translate(30.55625 67.998312) scale(0.15 -0.15)\">\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(127.246094 0)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(159.033203 0)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Accuracy -->\n     <g transform=\"translate(22.396875 240.373125) rotate(-90) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(66.658203 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(121.638672 0)\"/>\n      <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(176.619141 0)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(239.998047 0)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(281.111328 0)\"/>\n      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(342.390625 0)\"/>\n      <use xlink:href=\"#DejaVuSans-79\" transform=\"translate(397.371094 0)\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 96.318324 52.908179 \nL 128.022869 97.98644 \nL 159.727415 97.98644 \nL 191.43196 43.516875 \nL 223.136506 52.908179 \nL 254.841051 97.98644 \nL 286.545597 97.98644 \nL 318.250142 43.516875 \nL 349.954687 52.908179 \nL 381.659233 99.864701 \nL 413.363778 97.98644 \nL 445.068324 43.516875 \nL 476.772869 52.908179 \nL 508.477415 97.98644 \nL 540.18196 97.98644 \nL 571.886506 43.516875 \nL 603.591051 52.908179 \n\" clip-path=\"url(#p161788a1d3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 96.318324 293.325571 \nL 128.022869 345.916875 \nL 159.727415 276.421223 \nL 191.43196 201.290788 \nL 223.136506 293.325571 \nL 254.841051 345.916875 \nL 286.545597 276.421223 \nL 318.250142 203.169049 \nL 349.954687 293.325571 \nL 381.659233 345.916875 \nL 413.363778 276.421223 \nL 445.068324 201.290788 \nL 476.772869 293.325571 \nL 508.477415 345.916875 \nL 540.18196 276.421223 \nL 571.886506 203.169049 \nL 603.591051 293.325571 \n\" clip-path=\"url(#p161788a1d3)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 70.954688 361.036875 \nL 70.954688 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 628.954687 361.036875 \nL 628.954687 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 70.954688 361.036875 \nL 628.954687 361.036875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 70.954688 28.396875 \nL 628.954687 28.396875 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- $C_4$ vs $SO(2)$ Steerable CNNs -->\n    <g transform=\"translate(210.754687 22.396875) scale(0.2 -0.2)\">\n     <defs>\n      <path id=\"DejaVuSans-Oblique-43\" d=\"M 4447 4306 \nL 4319 3641 \nQ 4019 3944 3683 4091 \nQ 3347 4238 2956 4238 \nQ 2422 4238 2017 3981 \nQ 1613 3725 1319 3200 \nQ 1131 2863 1032 2486 \nQ 934 2109 934 1728 \nQ 934 1091 1264 756 \nQ 1594 422 2222 422 \nQ 2656 422 3056 561 \nQ 3456 700 3834 978 \nL 3688 231 \nQ 3316 72 2936 -9 \nQ 2556 -91 2175 -91 \nQ 1278 -91 773 396 \nQ 269 884 269 1753 \nQ 269 2309 461 2846 \nQ 653 3384 1013 3828 \nQ 1394 4300 1883 4525 \nQ 2372 4750 3022 4750 \nQ 3422 4750 3780 4639 \nQ 4138 4528 4447 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-Oblique-53\" d=\"M 3859 4513 \nL 3738 3897 \nQ 3422 4066 3111 4152 \nQ 2800 4238 2509 4238 \nQ 1944 4238 1609 3991 \nQ 1275 3744 1275 3334 \nQ 1275 3109 1398 2989 \nQ 1522 2869 2034 2731 \nL 2413 2638 \nQ 3053 2472 3303 2217 \nQ 3553 1963 3553 1503 \nQ 3553 797 2998 353 \nQ 2444 -91 1538 -91 \nQ 1166 -91 791 -17 \nQ 416 56 38 206 \nL 166 856 \nQ 513 641 861 531 \nQ 1209 422 1556 422 \nQ 2147 422 2503 684 \nQ 2859 947 2859 1369 \nQ 2859 1650 2717 1795 \nQ 2575 1941 2106 2059 \nL 1728 2156 \nQ 1081 2325 845 2545 \nQ 609 2766 609 3163 \nQ 609 3859 1145 4304 \nQ 1681 4750 2541 4750 \nQ 2875 4750 3203 4690 \nQ 3531 4631 3859 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-Oblique-4f\" d=\"M 2919 4238 \nQ 2400 4238 2003 3986 \nQ 1606 3734 1313 3219 \nQ 1125 2891 1026 2522 \nQ 928 2153 928 1778 \nQ 928 1128 1239 775 \nQ 1550 422 2119 422 \nQ 2631 422 3032 676 \nQ 3434 931 3719 1434 \nQ 3909 1772 4009 2142 \nQ 4109 2513 4109 2881 \nQ 4109 3528 3796 3883 \nQ 3484 4238 2919 4238 \nz\nM 2100 -91 \nQ 1241 -91 748 418 \nQ 256 928 256 1813 \nQ 256 2319 448 2847 \nQ 641 3375 978 3788 \nQ 1375 4272 1862 4511 \nQ 2350 4750 2938 4750 \nQ 3794 4750 4287 4245 \nQ 4781 3741 4781 2869 \nQ 4781 2331 4593 1812 \nQ 4406 1294 4056 872 \nQ 3656 384 3173 146 \nQ 2691 -91 2100 -91 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-Oblique-43\" transform=\"translate(0 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(69.824219 -16.390625) scale(0.7)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(117.094727 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(148.881836 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(208.061523 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(260.161133 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-Oblique-53\" transform=\"translate(291.948242 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-Oblique-4f\" transform=\"translate(355.424805 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(434.135742 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(473.149414 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(536.772461 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(575.786133 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-53\" transform=\"translate(607.573242 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(671.049805 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(710.258789 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(771.782227 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(833.305664 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(874.418945 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(935.698242 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(999.174805 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(1026.958008 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1088.481445 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(1120.268555 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(1190.092773 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(1264.897461 0.015625)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1339.702148 0.015625)\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 340.354687 227.073125 \nL 614.954687 227.073125 \nQ 618.954687 227.073125 618.954687 223.073125 \nL 618.954687 166.360625 \nQ 618.954687 162.360625 614.954687 162.360625 \nL 340.354687 162.360625 \nQ 336.354687 162.360625 336.354687 166.360625 \nL 336.354687 223.073125 \nQ 336.354687 227.073125 340.354687 227.073125 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 344.354687 178.5575 \nL 364.354687 178.5575 \nL 384.354687 178.5575 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- $SO(2)$-Steerable CNN -->\n     <g transform=\"translate(400.354687 185.5575) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-Oblique-53\" transform=\"translate(0 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-Oblique-4f\" transform=\"translate(63.476562 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(142.1875 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(181.201172 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(244.824219 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" transform=\"translate(283.837891 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-53\" transform=\"translate(319.921875 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(383.398438 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(422.607422 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(484.130859 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(545.654297 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(586.767578 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(648.046875 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(711.523438 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(739.306641 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(800.830078 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(832.617188 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(902.441406 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(977.246094 0.015625)\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 344.354687 207.91375 \nL 364.354687 207.91375 \nL 384.354687 207.91375 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- $C_4$-Steerable CNN -->\n     <g transform=\"translate(400.354687 214.91375) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-Oblique-43\" transform=\"translate(0 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(69.824219 -16.390625) scale(0.7)\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" transform=\"translate(117.094727 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-53\" transform=\"translate(153.178711 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(216.655273 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(255.864258 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(317.387695 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(378.911133 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(420.024414 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(481.303711 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(544.780273 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(572.563477 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(634.086914 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(665.874023 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(735.698242 0.015625)\"/>\n      <use xlink:href=\"#DejaVuSans-4e\" transform=\"translate(810.50293 0.015625)\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p161788a1d3\">\n   <rect x=\"70.954688\" y=\"28.396875\" width=\"558\" height=\"332.64\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot the accuracy of as a function of the rotation angle theta applied to the test set\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "N=16\n",
        "\n",
        "xs = [i*2*np.pi / N for i in range(N+1)]\n",
        "plt.plot(xs, accs_so2 + [accs_so2[0]], label=r'$SO(2)$-Steerable CNN')\n",
        "plt.plot(xs, accs_c4 + [accs_c4[0]], label=r'$C_4$-Steerable CNN')\n",
        "plt.title(r'$C_4$ vs $SO(2)$ Steerable CNNs', fontsize=20)\n",
        "\n",
        "plt.xlabel(r'Test rotation ($\\theta \\in [0, 2\\pi)$)', fontsize=20)\n",
        "plt.ylabel('Accuracy', fontsize=20)\n",
        "ax.tick_params(axis='both', which='major', labelsize=15)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxUALHL35RPL"
      },
      "source": [
        "While perfect equivariance to $SO(2)$ is not achievable due to the discretizations, the $SO(2)$ equivariant architecture is more stable over the rotations of the test set than the $C_4$ model.\n",
        "Moreover, since $C_4$ is the only perfect symmetry of the pixel grid and since $C_4 < SO(2)$, the $SO(2)$ equivariant architecture is also perfectly equivariant to rotations by multiples of $\\pi/2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEq1glwA5RPL"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, you first leart about *group representation theory* and the *Fourier Transform* over compact groups.\n",
        "These are the mathematical tools used to formalize Steerable CNNs.\n",
        "\n",
        "In the second part of this tutorial, you learnt about *steerable feature fields* and *steerable CNNs*.\n",
        "In particular, the previously defined  Fourier transform allowed us to build a steerable CNN which is equivalent to a Group-Convolutional Neural Network (GCNN) equivariant to translations and the continuous group $G=SO(2)$ of rotations.\n",
        "\n",
        "In our steerable CNNs, we mostly leveraged the *regular representation* of the group $G$, but the framework of steerable CNNs allows for a variety of representations.\n",
        "If you are interested in knowing more about steerable CNNs, this is a (non-exhaustive) list of relevant works you can check out:\n",
        "\n",
        "- [Steerable CNNs](https://arxiv.org/abs/1612.08498)\n",
        "- [Harmonic Networks: Deep Translation and Rotation Equivariance](https://arxiv.org/abs/1612.04642)\n",
        "- [3D Steerable CNNs](https://arxiv.org/abs/1807.02547)\n",
        "- [Tensor Field Networks](https://arxiv.org/abs/1802.08219)\n",
        "- [A General Theory of Equivariant CNNs on Homogeneous Spaces](https://arxiv.org/abs/1811.02017)\n",
        "- [Cormorant: Covariant Molecular Neural Networks](https://arxiv.org/abs/1906.04015)\n",
        "- [General E(2)-Equivariant Steerable CNNs](https://arxiv.org/abs/1911.08251)\n",
        "- [A Program to Build E(N)-Equivariant Steerable CNNs](https://openreview.net/forum?id=WE4qe9xlnQw)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JNMR5pQGcQLf",
        "rC2C598ScQLi",
        "GJ-VvAUmcQLr"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d365a9a40ece474d90afe8bc1fe3761c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a12471c29ecd43c0a3e2e657fa05104c",
              "IPY_MODEL_cf6c09575b6140d0a38cfa029bc1a666",
              "IPY_MODEL_31fe5b2895504e90b15f08d2c74a5746"
            ],
            "layout": "IPY_MODEL_d8a199945b2249eab713edb092b0fd58"
          }
        },
        "a12471c29ecd43c0a3e2e657fa05104c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2444d2eb35984110bad40401b85bf640",
            "placeholder": "​",
            "style": "IPY_MODEL_405008bf2b3849e28572d02b8bd503ad",
            "value": " 98%"
          }
        },
        "cf6c09575b6140d0a38cfa029bc1a666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b852af6ba354a9cb1991fbf58b17256",
            "max": 12000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a75ac61a83946039ea1bc87367d2c2d",
            "value": 12000
          }
        },
        "31fe5b2895504e90b15f08d2c74a5746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a2aea488ed4abd89300e86e6872c92",
            "placeholder": "​",
            "style": "IPY_MODEL_f019215c7e804eca99130532047e2111",
            "value": " 11815/12000 [00:07&lt;00:00, 1964.44it/s]"
          }
        },
        "d8a199945b2249eab713edb092b0fd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2444d2eb35984110bad40401b85bf640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405008bf2b3849e28572d02b8bd503ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b852af6ba354a9cb1991fbf58b17256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a75ac61a83946039ea1bc87367d2c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55a2aea488ed4abd89300e86e6872c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f019215c7e804eca99130532047e2111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e539dcd2fcf41aa8618adfda993084f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e7b4b20db28460596bb228db8d6a2c1",
              "IPY_MODEL_0909b4e5376d4ccb8c648a1dc67b7fb3",
              "IPY_MODEL_29bc4706a385449a9f6fd75a781f3774"
            ],
            "layout": "IPY_MODEL_76b6772a67ca483ab4667eeffe3859db"
          }
        },
        "9e7b4b20db28460596bb228db8d6a2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ffadd40b1ff475793fe1f5408ec4331",
            "placeholder": "​",
            "style": "IPY_MODEL_058214c8b9a04a6ebc209325df7c1bc1",
            "value": "100%"
          }
        },
        "0909b4e5376d4ccb8c648a1dc67b7fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d836e4d5964c7fa3742f68508befde",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb2ef96bd7544534a1abf0de1be5cbb0",
            "value": 50000
          }
        },
        "29bc4706a385449a9f6fd75a781f3774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0235b5e57d5d4b68944dd2ba4c9e0fd7",
            "placeholder": "​",
            "style": "IPY_MODEL_7ae838986d9c459097851b5b119af937",
            "value": " 49854/50000 [00:32&lt;00:00, 1455.17it/s]"
          }
        },
        "76b6772a67ca483ab4667eeffe3859db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7ffadd40b1ff475793fe1f5408ec4331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058214c8b9a04a6ebc209325df7c1bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d836e4d5964c7fa3742f68508befde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2ef96bd7544534a1abf0de1be5cbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0235b5e57d5d4b68944dd2ba4c9e0fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae838986d9c459097851b5b119af937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}